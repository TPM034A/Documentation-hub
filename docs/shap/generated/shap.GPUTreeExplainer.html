



<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>shap.GPUTreeExplainer &mdash; SHAP latest documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=7ab3649f" />
      <link rel="stylesheet" href="../_static/css/style.css" type="text/css" />

  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=c6e86fd7"></script>
      <script src="../_static/doctools.js?v=9a2dae69"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="shap.LinearExplainer" href="shap.LinearExplainer.html" />
    <link rel="prev" title="shap.TreeExplainer" href="shap.TreeExplainer.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #343131" >

          
          
          <a href="../index.html">
            
              <img src="../_static/shap_logo_white.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../overviews.html">Topical overviews</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tabular_examples.html">Tabular examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../text_examples.html">Text examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../image_examples.html">Image examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../genomic_examples.html">Genomic examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../api.html">API reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../api.html#explanation">Explanation</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../api.html#explainers">explainers</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="shap.Explainer.html">shap.Explainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="shap.TreeExplainer.html">shap.TreeExplainer</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">shap.GPUTreeExplainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="shap.LinearExplainer.html">shap.LinearExplainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="shap.PermutationExplainer.html">shap.PermutationExplainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="shap.PartitionExplainer.html">shap.PartitionExplainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="shap.SamplingExplainer.html">shap.SamplingExplainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="shap.AdditiveExplainer.html">shap.AdditiveExplainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="shap.DeepExplainer.html">shap.DeepExplainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="shap.KernelExplainer.html">shap.KernelExplainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="shap.GradientExplainer.html">shap.GradientExplainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="shap.ExactExplainer.html">shap.ExactExplainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="shap.explainers.other.Coefficient.html">shap.explainers.other.Coefficient</a></li>
<li class="toctree-l3"><a class="reference internal" href="shap.explainers.other.Random.html">shap.explainers.other.Random</a></li>
<li class="toctree-l3"><a class="reference internal" href="shap.explainers.other.LimeTabular.html">shap.explainers.other.LimeTabular</a></li>
<li class="toctree-l3"><a class="reference internal" href="shap.explainers.other.Maple.html">shap.explainers.other.Maple</a></li>
<li class="toctree-l3"><a class="reference internal" href="shap.explainers.other.TreeMaple.html">shap.explainers.other.TreeMaple</a></li>
<li class="toctree-l3"><a class="reference internal" href="shap.explainers.other.TreeGain.html">shap.explainers.other.TreeGain</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#plots">plots</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#maskers">maskers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#models">models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#utils">utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#datasets">datasets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../api_examples.html">API examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks.html">Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Development</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../release_notes.html">Release notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing guide</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #343131" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">SHAP</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../api.html">API Reference</a></li>
      <li class="breadcrumb-item active">shap.GPUTreeExplainer</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/generated/shap.GPUTreeExplainer.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="shap-gputreeexplainer">
<h1>shap.GPUTreeExplainer<a class="headerlink" href="#shap-gputreeexplainer" title="Link to this heading"></a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="shap.GPUTreeExplainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">shap.</span></span><span class="sig-name descname"><span class="pre">GPUTreeExplainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_output='raw'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_perturbation='auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">approximate=&lt;object</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">link=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">linearize_link=None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap.GPUTreeExplainer" title="Link to this definition"></a></dt>
<dd><p>Experimental GPU accelerated version of TreeExplainer. Currently requires source build with
cuda available and ‘CUDA_PATH’ environment variable defined.</p>
<p class="rubric">Examples</p>
<p>See <a class="reference external" href="https://shap.readthedocs.io/en/latest/api_examples/explainers/GPUTreeExplainer.html">GPUTree explainer examples</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="shap.GPUTreeExplainer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_output='raw'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_perturbation='auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_names=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">approximate=&lt;object</span> <span class="pre">object&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">link=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">linearize_link=None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap.GPUTreeExplainer.__init__" title="Link to this definition"></a></dt>
<dd><p>Build a new Tree explainer for the passed model.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>model</strong><span class="classifier">model object</span></dt><dd><p>The tree based machine learning model that we want to explain.
XGBoost, LightGBM, CatBoost, Pyspark and most tree-based
scikit-learn models are supported.</p>
</dd>
<dt><strong>data</strong><span class="classifier">numpy.array or pandas.DataFrame</span></dt><dd><p>The background dataset to use for integrating out features.</p>
<p>This argument is optional when
<code class="docutils literal notranslate"><span class="pre">feature_perturbation=&quot;tree_path_dependent&quot;</span></code>, since in that case
we can use the number of training samples that went down each tree
path as our background dataset (this is recorded in the <code class="docutils literal notranslate"><span class="pre">model</span></code>
object).</p>
</dd>
<dt><strong>feature_perturbation</strong><span class="classifier">“auto” (default), “interventional” or “tree_path_dependent”</span></dt><dd><p>Since SHAP values rely on conditional expectations, we need to
decide how to handle correlated (or otherwise dependent) input
features.</p>
<ul class="simple">
<li><p>if <code class="docutils literal notranslate"><span class="pre">&quot;interventional&quot;</span></code>, a background dataset <code class="docutils literal notranslate"><span class="pre">data</span></code> is required. The
dependencies between features are handled according to the rules dictated
by causal inference <a class="reference internal" href="#rdae6f65576cb-1" id="id1">[1]</a>. The runtime scales linearly with the size of the
background dataset you use: anywhere from 100 to 1000 random background
samples are good sizes to use.</p></li>
<li><p>if <code class="docutils literal notranslate"><span class="pre">&quot;tree_path_dependent&quot;</span></code>, no background dataset is required and the
approach is to just follow the trees and use the number of training
examples that went down each leaf to represent the background
distribution.</p></li>
<li><p>if <code class="docutils literal notranslate"><span class="pre">&quot;auto&quot;</span></code>, the “interventional” approach will be used when a
background is provided, otherwise the “tree_path_dependent” approach will
be used.</p></li>
</ul>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 0.47: </span>The <cite>“auto”</cite> option was added.</p>
</div>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.47: </span>The default behaviour will change from <cite>“interventional”</cite> to <cite>“auto”</cite> in 0.47.
In the future, passing <cite>feature_pertubation=”interventional”</cite> without providing
a background dataset will raise an error.</p>
</div>
</dd>
<dt><strong>model_output</strong><span class="classifier">“raw”, “probability”, “log_loss”, or model method name</span></dt><dd><p>What output of the model should be explained.</p>
<ul class="simple">
<li><p>If “raw”, then we explain the raw output of the trees, which
varies by model. For regression models, “raw” is the standard
output. For binary classification in XGBoost, this is the log odds
ratio.</p></li>
<li><p>If “probability”, then we explain the output of the model
transformed into probability space (note that this means the SHAP
values now sum to the probability output of the model).</p></li>
<li><p>If “log_loss”, then we explain the natural logarithm of the model
loss function, so that the SHAP values sum up to the log loss of
the model for each sample. This is helpful for breaking down model
performance by feature.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">model_output</span></code> is the name of a supported prediction method
on the <code class="docutils literal notranslate"><span class="pre">model</span></code> object, then we explain the output of that model
method name. For example, <code class="docutils literal notranslate"><span class="pre">model_output=&quot;predict_proba&quot;</span></code>
explains the result of calling <code class="docutils literal notranslate"><span class="pre">model.predict_proba</span></code>.</p></li>
</ul>
<p>Currently the “probability” and “log_loss” options are only
supported when <code class="docutils literal notranslate"><span class="pre">feature_perturbation=&quot;interventional&quot;</span></code>.</p>
</dd>
<dt><strong>approximate</strong><span class="classifier">bool</span></dt><dd><p>Deprecated, will be deprecated in v0.47.0 and removed in version v0.49.0.
Please use the <code class="docutils literal notranslate"><span class="pre">approximate</span></code> argument in the <a class="reference internal" href="#shap.GPUTreeExplainer.shap_values" title="shap.GPUTreeExplainer.shap_values"><code class="xref py py-meth docutils literal notranslate"><span class="pre">shap_values()</span></code></a> or <code class="docutils literal notranslate"><span class="pre">__call__</span></code> methods instead.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rdae6f65576cb-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>Janzing, Dominik, Lenon Minorics, and Patrick Blöbaum.
“Feature relevance quantification in explainable AI: A causal problem.”
International Conference on artificial intelligence and statistics. PMLR, 2020.</p>
</div>
</div>
</dd></dl>

<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#shap.GPUTreeExplainer.__init__" title="shap.GPUTreeExplainer.__init__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">__init__</span></code></a>(model[, data, model_output, ...])</p></td>
<td><p>Build a new Tree explainer for the passed model.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">assert_additivity</span></code>(phi, model_output)</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#shap.GPUTreeExplainer.explain_row" title="shap.GPUTreeExplainer.explain_row"><code class="xref py py-obj docutils literal notranslate"><span class="pre">explain_row</span></code></a>(*row_args, max_evals, ...)</p></td>
<td><p>Explains a single row and returns the tuple (row_values, row_expected_values, row_mask_shapes, main_effects).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#shap.GPUTreeExplainer.load" title="shap.GPUTreeExplainer.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a>(in_file[, model_loader, masker_loader, ...])</p></td>
<td><p>Load an Explainer from the given file stream.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#shap.GPUTreeExplainer.save" title="shap.GPUTreeExplainer.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a>(out_file[, model_saver, masker_saver])</p></td>
<td><p>Write the explainer to the given file stream.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#shap.GPUTreeExplainer.shap_interaction_values" title="shap.GPUTreeExplainer.shap_interaction_values"><code class="xref py py-obj docutils literal notranslate"><span class="pre">shap_interaction_values</span></code></a>(X[, y, tree_limit])</p></td>
<td><p>Estimate the SHAP interaction values for a set of samples.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#shap.GPUTreeExplainer.shap_values" title="shap.GPUTreeExplainer.shap_values"><code class="xref py py-obj docutils literal notranslate"><span class="pre">shap_values</span></code></a>(X[, y, tree_limit, approximate, ...])</p></td>
<td><p>Estimate the SHAP values for a set of samples.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#shap.GPUTreeExplainer.supports_model_with_masker" title="shap.GPUTreeExplainer.supports_model_with_masker"><code class="xref py py-obj docutils literal notranslate"><span class="pre">supports_model_with_masker</span></code></a>(model, masker)</p></td>
<td><p>Determines if this explainer can handle the given model.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="shap.GPUTreeExplainer.explain_row">
<span class="sig-name descname"><span class="pre">explain_row</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">row_args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_evals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">main_effects</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">error_bounds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">silent</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap.GPUTreeExplainer.explain_row" title="Link to this definition"></a></dt>
<dd><p>Explains a single row and returns the tuple (row_values, row_expected_values, row_mask_shapes, main_effects).</p>
<p>This is an abstract method meant to be implemented by each subclass.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>tuple</dt><dd><p>A tuple of (row_values, row_expected_values, row_mask_shapes), where row_values is an array of the
attribution values for each sample, row_expected_values is an array (or single value) representing
the expected value of the model for each sample (which is the same for all samples unless there
are fixed inputs present, like labels when explaining the loss), and row_mask_shapes is a list
of all the input shapes (since the row_values is always flattened),</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap.GPUTreeExplainer.load">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_file</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_loader=&lt;bound</span> <span class="pre">method</span> <span class="pre">Model.load</span> <span class="pre">of</span> <span class="pre">&lt;class</span> <span class="pre">'shap.models._model.Model'&gt;&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masker_loader=&lt;bound</span> <span class="pre">method</span> <span class="pre">Serializable.load</span> <span class="pre">of</span> <span class="pre">&lt;class</span> <span class="pre">'shap.maskers._masker.Masker'&gt;&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">instantiate=True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap.GPUTreeExplainer.load" title="Link to this definition"></a></dt>
<dd><p>Load an Explainer from the given file stream.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>in_file</strong><span class="classifier">The file stream to load objects from.</span></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap.GPUTreeExplainer.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">out_file</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_saver</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'.save'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masker_saver</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'.save'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap.GPUTreeExplainer.save" title="Link to this definition"></a></dt>
<dd><p>Write the explainer to the given file stream.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap.GPUTreeExplainer.shap_interaction_values">
<span class="sig-name descname"><span class="pre">shap_interaction_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap.GPUTreeExplainer.shap_interaction_values" title="Link to this definition"></a></dt>
<dd><p>Estimate the SHAP interaction values for a set of samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">numpy.array, pandas.DataFrame or catboost.Pool (for catboost)</span></dt><dd><p>A matrix of samples (# samples x # features) on which to explain the model’s output.</p>
</dd>
<dt><strong>y</strong><span class="classifier">numpy.array</span></dt><dd><p>An array of label values for each sample. Used when explaining loss functions (not
yet supported).</p>
</dd>
<dt><strong>tree_limit</strong><span class="classifier">None (default) or int</span></dt><dd><p>Limit the number of trees used by the model. By default None means no use the limit
of the
original model, and -1 means no limit.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>array or list</dt><dd><p>For models with a single output this returns a tensor of SHAP values
(# samples x # features x # features). The matrix (# features x # features) for each
sample sums
to the difference between the model output for that sample and the expected value of
the model output
(which is stored in the expected_value attribute of the explainer). Each row of this
matrix sums to the
SHAP value for that feature for that sample. The diagonal entries of the matrix
represent the
“main effect” of that feature on the prediction and the symmetric off-diagonal
entries represent the
interaction effects between all pairs of features for that sample. For models with
vector outputs
this returns a list of tensors, one for each output.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap.GPUTreeExplainer.shap_values">
<span class="sig-name descname"><span class="pre">shap_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tree_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">approximate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_additivity</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">from_call</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap.GPUTreeExplainer.shap_values" title="Link to this definition"></a></dt>
<dd><p>Estimate the SHAP values for a set of samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">numpy.array, pandas.DataFrame or catboost.Pool (for catboost)</span></dt><dd><p>A matrix of samples (# samples x # features) on which to explain the model’s output.</p>
</dd>
<dt><strong>y</strong><span class="classifier">numpy.array</span></dt><dd><p>An array of label values for each sample. Used when explaining loss functions.</p>
</dd>
<dt><strong>tree_limit</strong><span class="classifier">None (default) or int</span></dt><dd><p>Limit the number of trees used by the model. By default None means no use the limit
of the
original model, and -1 means no limit.</p>
</dd>
<dt><strong>approximate</strong><span class="classifier">bool</span></dt><dd><p>Not supported.</p>
</dd>
<dt><strong>check_additivity</strong><span class="classifier">bool</span></dt><dd><p>Run a validation check that the sum of the SHAP values equals the output of the
model. This
check takes only a small amount of time, and will catch potential unforeseen errors.
Note that this check only runs right now when explaining the margin of the model.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt>array or list</dt><dd><p>For models with a single output this returns a matrix of SHAP values
(# samples x # features). Each row sums to the difference between the model output
for that
sample and the expected value of the model output (which is stored in the expected_value
attribute of the explainer when it is constant). For models with vector outputs this
returns
a list of such matrices, one for each output.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="shap.GPUTreeExplainer.supports_model_with_masker">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">supports_model_with_masker</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masker</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#shap.GPUTreeExplainer.supports_model_with_masker" title="Link to this definition"></a></dt>
<dd><p>Determines if this explainer can handle the given model.</p>
<p>This is an abstract static method meant to be implemented by each subclass.</p>
</dd></dl>

</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="shap.TreeExplainer.html" class="btn btn-neutral float-left" title="shap.TreeExplainer" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="shap.LinearExplainer.html" class="btn btn-neutral float-right" title="shap.LinearExplainer" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2018, Scott Lundberg.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>