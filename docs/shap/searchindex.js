Search.setIndex({"alltitles": {"A longer run with many evaluations": [[29, "A-longer-run-with-many-evaluations"], [33, "A-longer-run-with-many-evaluations"]], "A more complete picture using partial dependence plots": [[38, "A-more-complete-picture-using-partial-dependence-plots"]], "A quick run with a few evaluations": [[29, "A-quick-run-with-a-few-evaluations"], [33, "A-quick-run-with-a-few-evaluations"]], "A simple beeswarm summary plot": [[10, "A-simple-beeswarm-summary-plot"]], "A simple violin summary plot": [[16, "A-simple-violin-summary-plot"]], "A subscriber retention example": [[39, "A-subscriber-retention-example"]], "API": [[74, "API"]], "API Examples": [[1, null]], "API Reference": [[0, null]], "API details": [[26, "API-details"]], "Add x-jitter to points": [[14, "Add-x-jitter-to-points"]], "An introduction to explainable AI with Shapley values": [[38, null]], "Another example\u2026": [[76, "Another-example..."]], "Azure COGS CV image requirements:": [[26, "Azure-COGS-CV-image-requirements:"]], "Bar chart of mean importance": [[55, "Bar-chart-of-mean-importance"]], "Basic SHAP Interaction Value Example in XGBoost": [[52, null]], "Basic decision plot features": [[11, "Basic-decision-plot-features"]], "Be careful when interpreting predictive models in search of causal\u00a0insights": [[39, null]], "Benchmark Explainer": [[18, "Benchmark-Explainer"], [21, "Benchmark-Explainer"], [22, "Benchmark-Explainer"], [23, "Benchmark-Explainer"], [24, "Benchmark-Explainer"]], "Benchmark XGBoost explanations": [[20, null]], "Benchmark explainers on an XGBoost classification model of census reported income": [[20, "Benchmark-explainers-on-an-XGBoost-classification-model-of-census-reported-income"]], "Benchmark explainers on an XGBoost regression model of California housing": [[20, "Benchmark-explainers-on-an-XGBoost-regression-model-of-California-housing"]], "Benchmarking": [[75, "Benchmarking"]], "Benchmarks": [[2, null]], "Brute Force Kernel SHAP": [[49, "Brute-Force-Kernel-SHAP"]], "Build a Text masker explicitly": [[72, "Build-a-Text-masker-explicitly"]], "Build a linear model that uses standardized features": [[41, "Build-a-linear-model-that-uses-standardized-features"]], "Build a simulated dataset with binary labels": [[59, "Build-a-simulated-dataset-with-binary-labels"]], "Build a transformers pipline": [[70, "Build-a-transformers-pipline"]], "Build an XGBoost regressor": [[59, "Build-an-XGBoost-regressor"]], "Build the model and explanations": [[20, "Build-the-model-and-explanations"], [20, "id1"]], "Building the docs locally": [[3, "building-the-docs-locally"]], "Calculate SHAP values": [[11, "Calculate-SHAP-values"]], "Calculating explanations": [[8, "Calculating-explanations"]], "Catboost tutorial": [[53, null]], "Census income classification with Keras": [[51, null]], "Census income classification with LightGBM": [[54, null]], "Census income classification with XGBoost": [[55, null]], "Census income classification with scikit-learn": [[44, null]], "Change point size": [[14, "Change-point-size"]], "Change title and tick label": [[14, "Change-title-and-tick-label"]], "Changing sort order and global feature importance values": [[12, "Changing-sort-order-and-global-feature-importance-values"]], "Changing the SHAP base value": [[11, "Changing-the-SHAP-base-value"]], "Check Performance": [[63, "Check-Performance"]], "Checklist for publishing PRs": [[3, "checklist-for-publishing-prs"]], "Class Label Mapping": [[18, "Class-Label-Mapping"], [24, "Class-Label-Mapping"]], "Classic feature attributions": [[55, "Classic-feature-attributions"]], "Code checks with precommit": [[3, "code-checks-with-precommit"]], "Cohort bar plot": [[9, "Cohort-bar-plot"]], "Compare and contrast predictions for several models": [[11, "Compare-and-contrast-predictions-for-several-models"]], "Compare runtime of XGBoost Tree SHAP\u2026": [[65, "Compare-runtime-of-XGBoost-Tree-SHAP..."]], "Compare to Tree SHAP": [[48, "Compare-to-Tree-SHAP"]], "Compute SHAP Interaction Values": [[63, "Compute-SHAP-Interaction-Values"]], "Compute SHAP values": [[68, "Compute-SHAP-values"], [70, "Compute-SHAP-values"], [73, "Compute-SHAP-values"]], "Compute a hierarchical clustering of the input features": [[48, "Compute-a-hierarchical-clustering-of-the-input-features"]], "Compute importance scores": [[25, "Compute-importance-scores"]], "Compute shap values": [[74, "Compute-shap-values"], [74, "id1"]], "Conclusion": [[40, "Conclusion"]], "Contributing guidelines": [[3, null]], "Control outliers": [[14, "Control-outliers"]], "Convert the explanation to the original feature space": [[41, "Convert-the-explanation-to-the-original-feature-space"]], "Create Data": [[47, "Create-Data"]], "Create Explainer Object": [[18, "Create-Explainer-Object"], [21, "Create-Explainer-Object"], [22, "Create-Explainer-Object"], [23, "Create-Explainer-Object"], [24, "Create-Explainer-Object"]], "Create Model": [[47, "Create-Model"]], "Create Multi-Output Regression Model": [[47, "Create-Multi-Output-Regression-Model"]], "Create XGBoost data objects": [[63, "Create-XGBoost-data-objects"]], "Create a TransformersPipeline wrapper": [[72, "Create-a-TransformersPipeline-wrapper"]], "Create a dataset following an OR function": [[57, "Create-a-dataset-following-an-OR-function"]], "Create a list of SHAP Trees": [[56, "Create-a-list-of-SHAP-Trees"]], "Create an explainer": [[73, "Create-an-explainer"]], "Create an explainer for the pipeline": [[70, "Create-an-explainer-for-the-pipeline"]], "Create an explainer object": [[74, "Create-an-explainer-object"]], "Create an explainer object and compute the SHAP values": [[76, "Create-an-explainer-object-and-compute-the-SHAP-values"]], "Create an explainer object using wrapped model and Text masker": [[74, "Create-an-explainer-object-using-wrapped-model-and-Text-masker"]], "Create an explainer object using wrapped model and image masker": [[26, "Create-an-explainer-object-using-wrapped-model-and-image-masker"], [27, "Create-an-explainer-object-using-wrapped-model-and-image-masker"]], "Create explainer object": [[68, "Create-explainer-object"]], "Creating a python environment": [[3, "creating-a-python-environment"]], "Custom colormap": [[14, "Custom-colormap"]], "Custom colors": [[10, "Custom-colors"]], "Custom text generation and debugging biased outputs": [[76, "Custom-text-generation-and-debugging-biased-outputs"]], "Customizing the figure properties": [[14, "Customizing-the-figure-properties"]], "Dealing with correlated features": [[38, "Dealing-with-correlated-features"]], "Decision tree": [[46, "Decision-tree"]], "Decision tree regressor": [[45, "Decision-tree-regressor"]], "DeepExplainer Genomics Example": [[25, null]], "Define Explainer Masker": [[21, "Define-Explainer-Masker"]], "Define Image Masker": [[18, "Define-Image-Masker"]], "Define Metrics (Sort Order & Perturbation Method)": [[18, "Define-Metrics-(Sort-Order-&-Perturbation-Method)"], [21, "Define-Metrics-(Sort-Order-&-Perturbation-Method)"], [22, "Define-Metrics-(Sort-Order-&-Perturbation-Method)"], [23, "Define-Metrics-(Sort-Order-&-Perturbation-Method)"], [24, "Define-Metrics-(Sort-Order-&-Perturbation-Method)"]], "Define Score Function": [[18, "Define-Score-Function"], [24, "Define-Score-Function"]], "Define data": [[68, "Define-data"]], "Define initial text": [[76, "Define-initial-text"]], "Define our model": [[73, "Define-our-model"]], "Development": [[158, null]], "Diabetes regression with scikit-learn": [[45, null]], "Display the cumulative effect of interactions": [[11, "Display-the-cumulative-effect-of-interactions"]], "Documentation": [[3, "documentation"]], "Dot plot": [[66, "Dot-plot"]], "Emotion classification multiclass example": [[70, null]], "English to French": [[77, "English-to-French"]], "English to Spanish model": [[77, "English-to-Spanish-model"]], "Estimating the sampling error": [[36, "Estimating-the-sampling-error"]], "Etiquette for creating PRs": [[3, "etiquette-for-creating-prs"]], "Exact explainer": [[4, null]], "Examine how changes in a feature change the model\u2019s prediction": [[62, "Examine-how-changes-in-a-feature-change-the-model's-prediction"]], "Examining the model coefficients": [[38, "Examining-the-model-coefficients"]], "Example of loading a custom tree model into SHAP": [[56, null]], "Examples": [[158, null]], "Explain PyTorch MobileNetV2 using the Partition explainer": [[28, null]], "Explain ResNet50 ImageNet classification using Partition explainer": [[33, null]], "Explain ResNet50 using the Partition explainer": [[29, null]], "Explain a linear function with no interactions": [[52, "Explain-a-linear-function-with-no-interactions"]], "Explain a linear model with one interaction": [[52, "Explain-a-linear-model-with-one-interaction"]], "Explain a matching function": [[69, "Explain-a-matching-function"]], "Explain a single player\u2019s chances of winning a particular match": [[62, "Explain-a-single-player's-chances-of-winning-a-particular-match"]], "Explain a single prediction": [[51, "Explain-a-single-prediction"]], "Explain a single prediction from the test set": [[45, "Explain-a-single-prediction-from-the-test-set"], [46, "Explain-a-single-prediction-from-the-test-set"]], "Explain all the predictions in the test set": [[45, "Explain-all-the-predictions-in-the-test-set"], [46, "Explain-all-the-predictions-in-the-test-set"]], "Explain an Intermediate Layer of VGG16 on ImageNet": [[30, null]], "Explain an Intermediate Layer of VGG16 on ImageNet (PyTorch)": [[31, null]], "Explain many predictions": [[51, "Explain-many-predictions"]], "Explain multiple images": [[28, "Explain-multiple-images"]], "Explain one image": [[28, "Explain-one-image"]], "Explain predictions": [[44, "Explain-predictions"], [44, "id1"], [51, "Explain-predictions"], [54, "Explain-predictions"], [55, "Explain-predictions"]], "Explain the Log-Loss of the Model with TreeExplainer": [[58, "Explain-the-Log-Loss-of-the-Model-with-TreeExplainer"]], "Explain the XGBoost model": [[62, "Explain-the-XGBoost-model"]], "Explain the custom model": [[56, "Explain-the-custom-model"]], "Explain the depth 1 model": [[59, "Explain-the-depth-1-model"]], "Explain the depth 3 model": [[59, "Explain-the-depth-3-model"]], "Explain the ending positions": [[69, "Explain-the-ending-positions"]], "Explain the first review\u2019s sentiment prediction": [[43, "Explain-the-first-review's-sentiment-prediction"]], "Explain the instance": [[48, "Explain-the-instance"]], "Explain the linear model": [[43, "Explain-the-linear-model"]], "Explain the log odds instead of the probabilities": [[70, "Explain-the-log-odds-instead-of-the-probabilities"]], "Explain the model": [[67, "Explain-the-model"]], "Explain the model with DeepExplainer and visualize the first prediction": [[71, "Explain-the-model-with-DeepExplainer-and-visualize-the-first-prediction"]], "Explain the model\u2019s predictions": [[77, "Explain-the-model's-predictions"]], "Explain the model\u2019s predictions on the entire dataset": [[63, "Explain-the-model's-predictions-on-the-entire-dataset"]], "Explain the prediction for a young boy": [[57, "Explain-the-prediction-for-a-young-boy"]], "Explain the predictions made by the model using GradientExplainer": [[36, "Explain-the-predictions-made-by-the-model-using-GradientExplainer"]], "Explain the second review\u2019s sentiment prediction": [[43, "Explain-the-second-review's-sentiment-prediction"]], "Explain the sentiment analysis pipeline": [[72, "Explain-the-sentiment-analysis-pipeline"]], "Explain the starting positions": [[69, "Explain-the-starting-positions"]], "Explain the third review\u2019s sentiment prediction": [[43, "Explain-the-third-review's-sentiment-prediction"]], "Explain with local smoothing": [[30, "Explain-with-local-smoothing"], [31, "Explain-with-local-smoothing"]], "Explainer options:": [[29, "Explainer-options:"], [33, "Explainer-options:"]], "Explaining Image Captioning (Image to Text) using Azure Cognitive Services and Partition Explainer": [[26, null]], "Explaining Image Captioning (Image to Text) using Open Source Image Captioning Model and Partition Explainer": [[27, null]], "Explaining a Question Answering Transformers Model": [[69, null]], "Explaining a linear logistic regression model": [[38, "Explaining-a-linear-logistic-regression-model"]], "Explaining a linear regression model": [[38, "Explaining-a-linear-regression-model"]], "Explaining a model that uses standardized features": [[41, null]], "Explaining a non-additive boosted tree logistic regression model": [[38, "Explaining-a-non-additive-boosted-tree-logistic-regression-model"]], "Explaining a non-additive boosted tree model": [[38, "Explaining-a-non-additive-boosted-tree-model"]], "Explaining a simple OR function": [[57, null]], "Explaining a transformers NLP model": [[38, "Explaining-a-transformers-NLP-model"]], "Explaining an additive regression model": [[38, "Explaining-an-additive-regression-model"]], "Explaining quantitative measures of fairness": [[40, null]], "Explaining the Loss of a Tree Model": [[58, null]], "Explaining the model": [[67, "Explaining-the-model"], [67, "id1"], [67, "id2"], [67, "id3"]], "Explanation": [[0, "explanation"]], "Explanation Visualization": [[75, "Explanation-Visualization"]], "Explore feature effects for a range of feature values": [[11, "Explore-feature-effects-for-a-range-of-feature-values"]], "Explore how the Text masker works": [[72, "Explore-how-the-Text-masker-works"]], "Exploring different interaction colorings": [[14, "Exploring-different-interaction-colorings"]], "Feature ordering": [[10, "Feature-ordering"]], "Fit a linear logistic regression model": [[43, "Fit-a-linear-logistic-regression-model"]], "Fitting a Linear Simulation with XGBoost": [[59, null]], "Force Plot Colors": [[60, null]], "Fork the repository": [[3, "fork-the-repository"]], "Front Page DeepExplainer MNIST Example": [[32, null]], "Front page example (XGBoost)": [[61, null]], "GPUTree explainer": [[5, null]], "General Benchmarking Debugging Tool": [[19, null]], "General Jupyter guidelines": [[3, "general-jupyter-guidelines"]], "Genomic examples": [[156, null]], "Get Output Class Indices": [[18, "Get-Output-Class-Indices"]], "Get SHAP Values and Plots": [[47, "Get-SHAP-Values-and-Plots"]], "Getting captions using open source model": [[27, "Getting-captions-using-open-source-model"]], "Global bar plot": [[9, "Global-bar-plot"]], "How SHAP can be used to explain various measures of model fairness": [[40, "How-SHAP-can-be-used-to-explain-various-measures-of-model-fairness"]], "How a squashing function can effect feature importance": [[50, null]], "How introducing a protected feature can help distinguish between label bias and feature bias": [[40, "How-introducing-a-protected-feature-can-help-distinguish-between-label-bias-and-feature-bias"]], "Identify outliers": [[11, "Identify-outliers"]], "Identify typical prediction paths": [[11, "Identify-typical-prediction-paths"]], "Image": [[2, "image"]], "Image Data Explanation Benchmarking: Image Multiclass Classification": [[18, null]], "Image Example (Multi-class)": [[19, "Image-Example-(Multi-class)"]], "Image captioning": [[157, "image-captioning"]], "Image classification": [[157, "image-classification"]], "Image examples": [[157, null]], "Input Partition Tree - Dendrogram": [[75, "Input-Partition-Tree---Dendrogram"]], "Install": [[158, "install"]], "Installing from source": [[3, "installing-from-source"]], "Installing the latest version": [[3, "installing-the-latest-version"]], "Interaction values": [[5, "Interaction-values"]], "Interpretation of SHAP output explanation:": [[29, "Interpretation-of-SHAP-output-explanation:"], [33, "Interpretation-of-SHAP-output-explanation:"]], "Introduction": [[3, "introduction"], [158, null]], "Iris classification with scikit-learn": [[46, null]], "Issue triage": [[3, "issue-triage"]], "Jupyter notebook style guide": [[3, "jupyter-notebook-style-guide"]], "K-nearest neighbors": [[46, "K-nearest-neighbors"]], "Keras LSTM for IMDB Sentiment Classification": [[71, null]], "Language modelling": [[162, "language-modelling"]], "Layered violin plot": [[66, "Layered-violin-plot"]], "League of Legends Win Prediction with XGBoost": [[62, null]], "Limitations": [[26, "Limitations"], [27, "Limitations"]], "Linear models": [[161, "linear-models"]], "Linear regression": [[45, "Linear-regression"]], "Links / Cross-references": [[3, "links-cross-references"]], "Load California dataset": [[65, "Load-California-dataset"]], "Load Data and Model": [[18, "Load-Data-and-Model"], [21, "Load-Data-and-Model"], [22, "Load-Data-and-Model"], [23, "Load-Data-and-Model"], [24, "Load-Data-and-Model"]], "Load and run a sentiment analysis pipeline": [[72, "Load-and-run-a-sentiment-analysis-pipeline"]], "Load data": [[26, "Load-data"], [27, "Load-data"], [45, "Load-data"], [74, "Load-data"]], "Load dataset": [[51, "Load-dataset"], [54, "Load-dataset"], [55, "Load-dataset"]], "Load language model and tokenizer": [[26, "Load-language-model-and-tokenizer"], [27, "Load-language-model-and-tokenizer"]], "Load model and tokenizer": [[68, "Load-model-and-tokenizer"], [74, "Load-model-and-tokenizer"], [75, "Load-model-and-tokenizer"], [76, "Load-model-and-tokenizer"]], "Load sample data": [[27, "Load-sample-data"]], "Load the IMDB dataset": [[43, "Load-the-IMDB-dataset"]], "Load the IMDB movie review dataset": [[72, "Load-the-IMDB-movie-review-dataset"]], "Load the census data": [[44, "Load-the-census-data"]], "Load the data": [[46, "Load-the-data"]], "Load the dataset": [[62, "Load-the-dataset"]], "Load the dataset and train the model": [[11, "Load-the-dataset-and-train-the-model"]], "Loading Model and Data": [[28, "Loading-Model-and-Data"], [29, "Loading-Model-and-Data"], [33, "Loading-Model-and-Data"]], "Local bar plot": [[9, "Local-bar-plot"]], "Logistic regression": [[46, "Logistic-regression"]], "Machine Translation Explanations": [[77, null]], "Maintainer guide": [[3, "maintainer-guide"]], "Making releases": [[3, "making-releases"]], "Margin space explaination": [[50, "Margin-space-explaination"]], "Math behind LinearExplainer with correlation feature perturbation": [[42, null]], "Migrating to the new \u201cExplanation\u201d API": [[8, null]], "Minimum supported dependencies": [[3, "minimum-supported-dependencies"]], "Model Prediction": [[47, "Model-Prediction"]], "Model agnostic": [[161, "model-agnostic"]], "Multi-Input Text Explanation: Textual Entailment with Facebook BART": [[75, null]], "Multi-class ResNet50 on ImageNet (TensorFlow)": [[34, null], [35, null]], "Multi-input Gradient Explainer MNIST Example": [[36, null]], "Multiple instance text plot": [[15, "Multiple-instance-text-plot"]], "NHANES I Survival Model": [[63, null]], "Neural network": [[45, "Neural-network"], [46, "Neural-network"]], "Neural networks": [[161, "neural-networks"]], "New style": [[8, "New-style"]], "Non-confounding redundancy": [[39, "Non-confounding-redundancy"]], "Normalize the data before training the model": [[44, "Normalize-the-data-before-training-the-model"]], "Note: It is important to follow set up instructions exactly as given below to ensure notebook runs.": [[27, "Note:-It-is-important-to-follow-set-up-instructions-exactly-as-given-below-to-ensure-notebook-runs."]], "Note: Replace or add images that you would like to be explained(tested) in the \u2018./test_images/\u2019 folder.": [[27, "Note:-Replace-or-add-images-that-you-would-like-to-be-explained(tested)-in-the-'./test_images/'-folder."]], "Note: Replace or add images that you would like to be explained(tested) in the \u2018./test_images/\u2019 folder.**": [[26, "Note:-Replace-or-add-images-that-you-would-like-to-be-explained(tested)-in-the-'./test_images/'-folder.**"]], "Notebook linting and formatting": [[3, "notebook-linting-and-formatting"]], "Observational Causal Inference": [[39, "Observational-Causal-Inference"]], "Observed confounding": [[39, "Observed-confounding"]], "Obtain data and keras model": [[25, "Obtain-data-and-keras-model"]], "Old style": [[8, "Old-style"]], "Opacity of the points": [[14, "Opacity-of-the-points"]], "Open Ended GPT2 Text Generation Explanations": [[76, null]], "Other customizations": [[14, "Other-customizations"]], "Others": [[2, "others"]], "PR triage": [[3, "pr-triage"]], "Parameters": [[64, "Parameters"]], "Pass a tokenizer as the masker object": [[72, "Pass-a-tokenizer-as-the-masker-object"]], "Permutation explainer": [[6, null]], "Plot SHAP Explanation": [[18, "Plot-SHAP-Explanation"]], "Plot Size": [[16, "Plot-Size"]], "Plot a global summary": [[4, "Plot-a-global-summary"], [4, "id1"], [5, "Plot-a-global-summary"], [6, "Plot-a-global-summary"], [6, "id1"]], "Plot a single instance": [[4, "Plot-a-single-instance"], [4, "id2"], [5, "Plot-a-single-instance"], [6, "Plot-a-single-instance"], [6, "id2"]], "Plot summary statistics and bar charts": [[72, "Plot-summary-statistics-and-bar-charts"]], "Plots to explain the instance": [[48, "Plots-to-explain-the-instance"]], "Plotting the top words impacting a specific class": [[70, "Plotting-the-top-words-impacting-a-specific-class"]], "Positive vs. Negative Sentiment Classification": [[72, null]], "Prediction tasks versus causal\u00a0tasks": [[39, "Prediction-tasks-versus-causal\u00a0tasks"]], "Preserving order and scale between plots": [[11, "Preserving-order-and-scale-between-plots"]], "Previewing changes on Pull Requests": [[3, "previewing-changes-on-pull-requests"]], "Probability space explaination": [[50, "Probability-space-explaination"]], "Pull Requests (PRs)": [[3, "pull-requests-prs"]], "Pull the info of the first tree": [[56, "Pull-the-info-of-the-first-tree"]], "Pull the info of the second tree": [[56, "Pull-the-info-of-the-second-tree"]], "PyTorch Deep Explainer MNIST example": [[37, null]], "Python TreeExplainer": [[65, "Python-TreeExplainer"]], "Python Version of Tree SHAP": [[65, null]], "Question Answering": [[162, "question-answering"]], "Random forest": [[45, "Random-forest"], [46, "Random-forest"]], "Reading SHAP values from partial dependence plots": [[38, "Reading-SHAP-values-from-partial-dependence-plots"]], "Reference": [[47, "Reference"], [158, null]], "Release notes": [[160, null]], "Release notes from PR labels": [[3, "release-notes-from-pr-labels"]], "Run SHAP Explanation": [[18, "Run-SHAP-Explanation"], [21, "Run-SHAP-Explanation"], [22, "Run-SHAP-Explanation"], [23, "Run-SHAP-Explanation"], [24, "Run-SHAP-Explanation"]], "Run shap values": [[75, "Run-shap-values"]], "Run the benchmarks": [[20, "Run-the-benchmarks"], [20, "id2"]], "SHAP Decision Plots": [[11, "SHAP-Decision-Plots"]], "SHAP Dependence Plots": [[54, "SHAP-Dependence-Plots"], [55, "SHAP-Dependence-Plots"], [63, "SHAP-Dependence-Plots"]], "SHAP Interaction Value Dependence Plots": [[63, "SHAP-Interaction-Value-Dependence-Plots"]], "SHAP Interaction Value Summary Plot": [[63, "SHAP-Interaction-Value-Summary-Plot"]], "SHAP ResNet50 model explanation for images": [[29, "SHAP-ResNet50-model-explanation-for-images"], [33, "SHAP-ResNet50-model-explanation-for-images"]], "SHAP Summary Plot": [[54, "SHAP-Summary-Plot"], [55, "SHAP-Summary-Plot"], [63, "SHAP-Summary-Plot"]], "SHAP Values for Multi-Output Regression Models": [[47, null]], "SHAP explanation for test images": [[26, "SHAP-explanation-for-test-images"], [27, "SHAP-explanation-for-test-images"]], "SHAP interaction values": [[11, "SHAP-interaction-values"], [52, "SHAP-interaction-values"], [52, "id2"]], "SHAP values": [[52, "SHAP-values"], [52, "id1"]], "Scatter Density vs. Violin Plot": [[66, null]], "Scenario A: No reporting errors": [[40, "Scenario-A:-No-reporting-errors"]], "Scenario B: An under-reporting bias for women\u2019s income": [[40, "Scenario-B:-An-under-reporting-bias-for-women's-income"]], "Scenario C: An under-reporting bias for women\u2019s late payments": [[40, "Scenario-C:-An-under-reporting-bias-for-women's-late-payments"]], "Scenario D: An under-reporting bias for women\u2019s default rates": [[40, "Scenario-D:-An-under-reporting-bias-for-women's-default-rates"]], "Scenario E: An under-reporting bias for women\u2019s default rates, take 2": [[40, "Scenario-E:-An-under-reporting-bias-for-women's-default-rates,-take-2"]], "Scenario F: Teasing apart multiple under-reporting biases": [[40, "Scenario-F:-Teasing-apart-multiple-under-reporting-biases"]], "Selecting features for display": [[11, "Selecting-features-for-display"]], "Sentiment Analysis with Logistic Regression": [[43, null]], "Sentiment analysis": [[162, "sentiment-analysis"]], "Setting up a local development environment": [[3, "setting-up-a-local-development-environment"]], "Setting up open source model": [[27, "Setting-up-open-source-model"]], "Show a large number of feature effects clearly": [[11, "Show-a-large-number-of-feature-effects-clearly"]], "Show an overall area-under-curve score across all metrics for all explainers": [[20, "Show-an-overall-area-under-curve-score-across-all-metrics-for-all-explainers"]], "Show detail plots of each metric type": [[20, "Show-detail-plots-of-each-metric-type"], [20, "id4"]], "Show overall performance again but without Random": [[20, "Show-overall-performance-again-but-without-Random"], [20, "id3"]], "Show scores across all metrics for all explainers": [[20, "Show-scores-across-all-metrics-for-all-explainers"]], "Simple California Demo 2.0": [[48, null]], "Simple GBM classification model (with 2 trees)": [[56, "Simple-GBM-classification-model-(with-2-trees)"]], "Simple Kernel SHAP": [[49, null]], "Simple dependence scatter plot": [[14, "Simple-dependence-scatter-plot"]], "Simple regression tree model": [[56, "Simple-regression-tree-model"]], "Simple supervised clustering": [[55, "Simple-supervised-clustering"]], "Single instance text plot": [[15, "Single-instance-text-plot"]], "Single split example": [[67, "Single-split-example"]], "Speed comparison of gradient boosting libraries for shap values calculations": [[64, null]], "Summarization": [[162, "summarization"]], "Summarize the effect of all the features": [[43, "Summarize-the-effect-of-all-the-features"]], "Summarize the impact of all features over the entire dataset": [[62, "Summarize-the-impact-of-all-features-over-the-entire-dataset"]], "Summarizing text explanations": [[15, "Summarizing-text-explanations"]], "Summary": [[39, "Summary"]], "Summary bar plot shows the global importance of each feature": [[59, "Summary-bar-plot-shows-the-global-importance-of-each-feature"]], "Summary bee-swarm plot shows the global importance of each feature and the distribution of effect sizes": [[59, "Summary-bee-swarm-plot-shows-the-global-importance-of-each-feature-and-the-distribution-of-effect-sizes"]], "Support vector machine with a linear kernel": [[46, "Support-vector-machine-with-a-linear-kernel"]], "Support vector machine with a radial basis function kernel": [[46, "Support-vector-machine-with-a-radial-basis-function-kernel"]], "Tabular": [[2, "tabular"]], "Tabular Data Explanation Benchmarking: Xgboost Regression": [[21, null]], "Tabular data with independent (Shapley value) masking": [[4, "Tabular-data-with-independent-(Shapley-value)-masking"], [5, "Tabular-data-with-independent-(Shapley-value)-masking"], [6, "Tabular-data-with-independent-(Shapley-value)-masking"]], "Tabular data with partition (Owen value) masking": [[4, "Tabular-data-with-partition-(Owen-value)-masking"], [6, "Tabular-data-with-partition-(Owen-value)-masking"]], "Tabular examples": [[161, null]], "Text": [[2, "text"]], "Text Data Explanation Benchmarking: Abstractive Summarization": [[22, null]], "Text Data Explanation Benchmarking: Emotion Multiclass Classification": [[24, null]], "Text Data Explanation Benchmarking: Machine Translation": [[23, null]], "Text Example (Summarization)": [[19, "Text-Example-(Summarization)"]], "Text entailment": [[162, "text-entailment"]], "Text examples": [[162, null]], "Text generation": [[162, "text-generation"]], "Text to Multiclass Explanation: Language Modeling Example": [[68, null]], "Text to Text Explanation: Abstractive Summarization Example": [[74, null]], "Text-To-Text Visualization": [[15, "Text-To-Text-Visualization"]], "The additive nature of Shapley values": [[38, "The-additive-nature-of-Shapley-values"]], "The challenges of estimating causal\u00a0effects": [[39, "The-challenges-of-estimating-causal\u00a0effects"]], "The dependence plot for the top feature shows that XGBoost captured most the linear relationship": [[59, "The-dependence-plot-for-the-top-feature-shows-that-XGBoost-captured-most-the-linear-relationship"]], "The layered Violin Summary Plot": [[16, "The-layered-Violin-Summary-Plot"]], "Topical Overviews": [[159, null]], "Train Keras model": [[51, "Train-Keras-model"]], "Train Model": [[47, "Train-Model"]], "Train XGBoost model": [[63, "Train-XGBoost-model"], [65, "Train-XGBoost-model"]], "Train a depth 1 model": [[59, "Train-a-depth-1-model"]], "Train a depth 3 model": [[59, "Train-a-depth-3-model"]], "Train a k-nearest neighbors classifier": [[44, "Train-a-k-nearest-neighbors-classifier"]], "Train a model": [[48, "Train-a-model"]], "Train a model with only two leaves per tree and hence no interaction terms between features": [[54, "Train-a-model-with-only-two-leaves-per-tree-and-hence-no-interaction-terms-between-features"], [55, "Train-a-model-with-only-two-leaves-per-tree-and-hence-no-interaction-terms-between-features"]], "Train an XGBoost Classifier": [[58, "Train-an-XGBoost-Classifier"]], "Train an XGBoost model to mimic this OR function": [[57, "Train-an-XGBoost-model-to-mimic-this-OR-function"]], "Train sklearn random forest": [[65, "Train-sklearn-random-forest"]], "Train the XGBoost model": [[62, "Train-the-XGBoost-model"]], "Train the model": [[54, "Train-the-model"], [55, "Train-the-model"]], "Translation": [[162, "translation"]], "Tree-based models": [[161, "tree-based-models"]], "Two feature XOR example": [[67, "Two-feature-XOR-example"]], "Two features AND + feature boost example": [[67, "Two-features-AND-+-feature-boost-example"]], "Two features AND example": [[67, "Two-features-AND-example"]], "Two features OR example": [[67, "Two-features-OR-example"]], "Understanding Tree SHAP for Simple Models": [[67, null]], "Unit tests with pytest": [[3, "unit-tests-with-pytest"]], "Useful transforms": [[10, "Useful-transforms"]], "Using KernelExplainer": [[49, "Using-KernelExplainer"]], "Using a custom masker": [[7, null]], "Using color to highlight interaction effects": [[14, "Using-color-to-highlight-interaction-effects"]], "Using custom functions and tokenizers": [[73, null]], "Using feature clustering": [[9, "Using-feature-clustering"]], "Using global feature importance orderings": [[14, "Using-global-feature-importance-orderings"]], "Using only negative examples for the background distribution": [[57, "Using-only-negative-examples-for-the-background-distribution"]], "Using only positive examples for the background distribution": [[57, "Using-only-positive-examples-for-the-background-distribution"]], "Using the training set for the background distribution": [[57, "Using-the-training-set-for-the-background-distribution"]], "Using young women for the background distribution": [[57, "Using-young-women-for-the-background-distribution"]], "Versioning": [[3, "versioning"]], "Versus the Python (numba) Tree SHAP\u2026": [[65, "Versus-the-Python-(numba)-Tree-SHAP..."]], "Violin plot": [[66, "Violin-plot"]], "Visualize a single prediction": [[55, "Visualize-a-single-prediction"], [59, "Visualize-a-single-prediction"]], "Visualize many predictions": [[54, "Visualize-many-predictions"], [55, "Visualize-many-predictions"]], "Visualize multioutput predictions": [[11, "Visualize-multioutput-predictions"]], "Visualize one prediction": [[54, "Visualize-one-prediction"]], "Visualize scores on individual sequences": [[25, "Visualize-scores-on-individual-sequences"]], "Visualize shap explanations": [[74, "Visualize-shap-explanations"], [74, "id2"], [76, "Visualize-shap-explanations"], [77, "Visualize-shap-explanations"]], "Visualize the SHAP values across the input sentence for the top-k next words": [[68, "Visualize-the-SHAP-values-across-the-input-sentence-for-the-top-k-next-words"]], "Visualize the impact on a single class": [[70, "Visualize-the-impact-on-a-single-class"]], "Visualize the impact on all the output classes": [[70, "Visualize-the-impact-on-all-the-output-classes"], [73, "Visualize-the-impact-on-all-the-output-classes"]], "Visualizing SHAP values output": [[29, "Visualizing-SHAP-values-output"], [33, "Visualizing-SHAP-values-output"]], "Welcome to the SHAP documentation": [[158, null]], "What SHAP fairness explanations look like in various simulated scenarios": [[40, "What-SHAP-fairness-explanations-look-like-in-various-simulated-scenarios"]], "When is a decision plot helpful?": [[11, "When-is-a-decision-plot-helpful?"]], "When neither predictive models nor unconfounding methods can answer causal questions": [[39, "When-neither-predictive-models-nor-unconfounding-methods-can-answer-causal-questions"]], "When predictive models can answer causal questions": [[39, "When-predictive-models-can-answer-causal-questions"]], "When predictive models cannot answer causal questions but causal inference methods can\u00a0help": [[39, "When-predictive-models-cannot-answer-causal-questions-but-causal-inference-methods-can\u00a0help"]], "Wrap the pipeline manually": [[72, "Wrap-the-pipeline-manually"]], "Writing helpful bug reports": [[3, "writing-helpful-bug-reports"]], "bar plot": [[9, null]], "beeswarm plot": [[10, null]], "datasets": [[0, "datasets"]], "decision plot": [[11, null]], "explainers": [[0, "explainers"], [1, "explainers"]], "heatmap plot": [[12, null]], "image plot": [[13, null]], "maskers": [[0, "maskers"], [1, "maskers"]], "models": [[0, "models"], [1, "models"]], "plots": [[0, "plots"], [1, "plots"]], "scatter plot": [[14, null]], "shap.AdditiveExplainer": [[78, null]], "shap.Cohorts": [[79, null]], "shap.DeepExplainer": [[80, null]], "shap.ExactExplainer": [[81, null]], "shap.Explainer": [[82, null]], "shap.Explanation": [[83, null]], "shap.GPUTreeExplainer": [[84, null]], "shap.GradientExplainer": [[85, null]], "shap.KernelExplainer": [[86, null]], "shap.LinearExplainer": [[87, null]], "shap.PartitionExplainer": [[88, null]], "shap.PermutationExplainer": [[89, null]], "shap.SamplingExplainer": [[90, null]], "shap.TreeExplainer": [[91, null]], "shap.datasets.a1a": [[92, null]], "shap.datasets.adult": [[93, null]], "shap.datasets.california": [[94, null]], "shap.datasets.communitiesandcrime": [[95, null]], "shap.datasets.corrgroups60": [[96, null]], "shap.datasets.diabetes": [[97, null]], "shap.datasets.imagenet50": [[98, null]], "shap.datasets.imdb": [[99, null]], "shap.datasets.independentlinear60": [[100, null]], "shap.datasets.iris": [[101, null]], "shap.datasets.linnerud": [[102, null]], "shap.datasets.nhanesi": [[103, null]], "shap.datasets.rank": [[104, null]], "shap.explainers.other.Coefficient": [[105, null]], "shap.explainers.other.LimeTabular": [[106, null]], "shap.explainers.other.Maple": [[107, null]], "shap.explainers.other.Random": [[108, null]], "shap.explainers.other.TreeGain": [[109, null]], "shap.explainers.other.TreeMaple": [[110, null]], "shap.maskers.Composite": [[111, null]], "shap.maskers.Fixed": [[112, null]], "shap.maskers.FixedComposite": [[113, null]], "shap.maskers.Image": [[114, null]], "shap.maskers.Impute": [[115, null]], "shap.maskers.Independent": [[116, null]], "shap.maskers.Masker": [[117, null]], "shap.maskers.OutputComposite": [[118, null]], "shap.maskers.Partition": [[119, null]], "shap.maskers.Text": [[120, null]], "shap.models.Model": [[121, null]], "shap.models.TeacherForcing": [[122, null]], "shap.models.TextGeneration": [[123, null]], "shap.models.TopKLM": [[124, null]], "shap.models.TransformersPipeline": [[125, null]], "shap.plots.bar": [[126, null]], "shap.plots.beeswarm": [[127, null]], "shap.plots.decision": [[128, null]], "shap.plots.embedding": [[129, null]], "shap.plots.force": [[130, null]], "shap.plots.group_difference": [[131, null]], "shap.plots.heatmap": [[132, null]], "shap.plots.image": [[133, null]], "shap.plots.image_to_text": [[134, null]], "shap.plots.initjs": [[135, null]], "shap.plots.monitoring": [[136, null]], "shap.plots.partial_dependence": [[137, null]], "shap.plots.scatter": [[138, null]], "shap.plots.text": [[139, null]], "shap.plots.violin": [[140, null]], "shap.plots.waterfall": [[141, null]], "shap.utils.MaskedModel": [[142, null]], "shap.utils.OpChain": [[143, null]], "shap.utils.approximate_interactions": [[144, null]], "shap.utils.convert_name": [[145, null]], "shap.utils.delta_minimization_order": [[146, null]], "shap.utils.hclust": [[147, null]], "shap.utils.hclust_ordering": [[148, null]], "shap.utils.make_masks": [[149, null]], "shap.utils.partition_tree": [[150, null]], "shap.utils.partition_tree_shuffle": [[151, null]], "shap.utils.potential_interactions": [[152, null]], "shap.utils.sample": [[153, null]], "shap.utils.shapley_coefficients": [[154, null]], "shap.utils.show_progress": [[155, null]], "text plot": [[15, null]], "utils": [[0, "utils"]], "violin summary plot": [[16, null]], "waterfall plot": [[17, null]], "\u2026about a hundred times slower in python, even with numba": [[65, "...about-a-hundred-times-slower-in-python,-even-with-numba"]]}, "docnames": ["api", "api_examples", "benchmarks", "contributing", "example_notebooks/api_examples/explainers/Exact", "example_notebooks/api_examples/explainers/GPUTree", "example_notebooks/api_examples/explainers/Permutation", "example_notebooks/api_examples/maskers/custom", "example_notebooks/api_examples/migrating-to-new-api", "example_notebooks/api_examples/plots/bar", "example_notebooks/api_examples/plots/beeswarm", "example_notebooks/api_examples/plots/decision_plot", "example_notebooks/api_examples/plots/heatmap", "example_notebooks/api_examples/plots/image", "example_notebooks/api_examples/plots/scatter", "example_notebooks/api_examples/plots/text", "example_notebooks/api_examples/plots/violin", "example_notebooks/api_examples/plots/waterfall", "example_notebooks/benchmarks/image/Image Multiclass Classification Benchmark Demo", "example_notebooks/benchmarks/others/Benchmark Debug Mode", "example_notebooks/benchmarks/tabular/Benchmark XGBoost explanations", "example_notebooks/benchmarks/tabular/Tabular Prediction Benchmark Demo", "example_notebooks/benchmarks/text/Abstractive Summarization Benchmark Demo", "example_notebooks/benchmarks/text/Machine Translation Benchmark Demo", "example_notebooks/benchmarks/text/Text Emotion Multiclass Classification Benchmark Demo", "example_notebooks/genomic_examples/DeepExplainer Genomics Example", "example_notebooks/image_examples/image_captioning/Image Captioning using Azure Cognitive Services", "example_notebooks/image_examples/image_captioning/Image Captioning using Open Source", "example_notebooks/image_examples/image_classification/Explain MobilenetV2 using the Partition explainer (PyTorch)", "example_notebooks/image_examples/image_classification/Explain ResNet50 using the Partition explainer", "example_notebooks/image_examples/image_classification/Explain an Intermediate Layer of VGG16 on ImageNet", "example_notebooks/image_examples/image_classification/Explain an Intermediate Layer of VGG16 on ImageNet (PyTorch)", "example_notebooks/image_examples/image_classification/Front Page DeepExplainer MNIST Example", "example_notebooks/image_examples/image_classification/Image Multi Class", "example_notebooks/image_examples/image_classification/Multi-class ResNet50 on ImageNet (TensorFlow)", "example_notebooks/image_examples/image_classification/Multi-class ResNet50 on ImageNet (TensorFlow)-checkpoint", "example_notebooks/image_examples/image_classification/Multi-input Gradient Explainer MNIST Example", "example_notebooks/image_examples/image_classification/PyTorch Deep Explainer MNIST example", "example_notebooks/overviews/An introduction to explainable AI with Shapley values", "example_notebooks/overviews/Be careful when interpreting predictive models in search of causal insights", "example_notebooks/overviews/Explaining quantitative measures of fairness", "example_notebooks/tabular_examples/linear_models/Explaining a model that uses standardized features", "example_notebooks/tabular_examples/linear_models/Math behind LinearExplainer with correlation feature perturbation", "example_notebooks/tabular_examples/linear_models/Sentiment Analysis with Logistic Regression", "example_notebooks/tabular_examples/model_agnostic/Census income classification with scikit-learn", "example_notebooks/tabular_examples/model_agnostic/Diabetes regression", "example_notebooks/tabular_examples/model_agnostic/Iris classification with scikit-learn", "example_notebooks/tabular_examples/model_agnostic/Multioutput Regression SHAP", "example_notebooks/tabular_examples/model_agnostic/Simple California Demo", "example_notebooks/tabular_examples/model_agnostic/Simple Kernel SHAP", "example_notebooks/tabular_examples/model_agnostic/Squashing Effect", "example_notebooks/tabular_examples/neural_networks/Census income classification with Keras", "example_notebooks/tabular_examples/tree_based_models/Basic SHAP Interaction Value Example in XGBoost", "example_notebooks/tabular_examples/tree_based_models/Catboost tutorial", "example_notebooks/tabular_examples/tree_based_models/Census income classification with LightGBM", "example_notebooks/tabular_examples/tree_based_models/Census income classification with XGBoost", "example_notebooks/tabular_examples/tree_based_models/Example of loading a custom tree model into SHAP", "example_notebooks/tabular_examples/tree_based_models/Explaining a simple OR function", "example_notebooks/tabular_examples/tree_based_models/Explaining the Loss of a Model", "example_notebooks/tabular_examples/tree_based_models/Fitting a Linear Simulation with XGBoost", "example_notebooks/tabular_examples/tree_based_models/Force Plot Colors", "example_notebooks/tabular_examples/tree_based_models/Front page example (XGBoost)", "example_notebooks/tabular_examples/tree_based_models/League of Legends Win Prediction with XGBoost", "example_notebooks/tabular_examples/tree_based_models/NHANES I Survival Model", "example_notebooks/tabular_examples/tree_based_models/Perfomance Comparison", "example_notebooks/tabular_examples/tree_based_models/Python Version of Tree SHAP", "example_notebooks/tabular_examples/tree_based_models/Scatter Density vs. Violin Plot Comparison", "example_notebooks/tabular_examples/tree_based_models/Understanding Tree SHAP for Simple Models", "example_notebooks/text_examples/language_modelling/Language Modeling Explanation Demo", "example_notebooks/text_examples/question_answering/Explaining a Question Answering Transformers Model", "example_notebooks/text_examples/sentiment_analysis/Emotion classification multiclass example", "example_notebooks/text_examples/sentiment_analysis/Keras LSTM for IMDB Sentiment Classification", "example_notebooks/text_examples/sentiment_analysis/Positive vs. Negative Sentiment Classification", "example_notebooks/text_examples/sentiment_analysis/Using custom functions and tokenizers", "example_notebooks/text_examples/summarization/Abstractive Summarization Explanation Demo", "example_notebooks/text_examples/text_entailment/Textual Entailment Explanation Demo", "example_notebooks/text_examples/text_generation/Open Ended GPT2 Text Generation Explanations", "example_notebooks/text_examples/translation/Machine Translation Explanations", "generated/shap.AdditiveExplainer", "generated/shap.Cohorts", "generated/shap.DeepExplainer", "generated/shap.ExactExplainer", "generated/shap.Explainer", "generated/shap.Explanation", "generated/shap.GPUTreeExplainer", "generated/shap.GradientExplainer", "generated/shap.KernelExplainer", "generated/shap.LinearExplainer", "generated/shap.PartitionExplainer", "generated/shap.PermutationExplainer", "generated/shap.SamplingExplainer", "generated/shap.TreeExplainer", "generated/shap.datasets.a1a", "generated/shap.datasets.adult", "generated/shap.datasets.california", "generated/shap.datasets.communitiesandcrime", "generated/shap.datasets.corrgroups60", "generated/shap.datasets.diabetes", "generated/shap.datasets.imagenet50", "generated/shap.datasets.imdb", "generated/shap.datasets.independentlinear60", "generated/shap.datasets.iris", "generated/shap.datasets.linnerud", "generated/shap.datasets.nhanesi", "generated/shap.datasets.rank", "generated/shap.explainers.other.Coefficient", "generated/shap.explainers.other.LimeTabular", "generated/shap.explainers.other.Maple", "generated/shap.explainers.other.Random", "generated/shap.explainers.other.TreeGain", "generated/shap.explainers.other.TreeMaple", "generated/shap.maskers.Composite", "generated/shap.maskers.Fixed", "generated/shap.maskers.FixedComposite", "generated/shap.maskers.Image", "generated/shap.maskers.Impute", "generated/shap.maskers.Independent", "generated/shap.maskers.Masker", "generated/shap.maskers.OutputComposite", "generated/shap.maskers.Partition", "generated/shap.maskers.Text", "generated/shap.models.Model", "generated/shap.models.TeacherForcing", "generated/shap.models.TextGeneration", "generated/shap.models.TopKLM", "generated/shap.models.TransformersPipeline", "generated/shap.plots.bar", "generated/shap.plots.beeswarm", "generated/shap.plots.decision", "generated/shap.plots.embedding", "generated/shap.plots.force", "generated/shap.plots.group_difference", "generated/shap.plots.heatmap", "generated/shap.plots.image", "generated/shap.plots.image_to_text", "generated/shap.plots.initjs", "generated/shap.plots.monitoring", "generated/shap.plots.partial_dependence", "generated/shap.plots.scatter", "generated/shap.plots.text", "generated/shap.plots.violin", "generated/shap.plots.waterfall", "generated/shap.utils.MaskedModel", "generated/shap.utils.OpChain", "generated/shap.utils.approximate_interactions", "generated/shap.utils.convert_name", "generated/shap.utils.delta_minimization_order", "generated/shap.utils.hclust", "generated/shap.utils.hclust_ordering", "generated/shap.utils.make_masks", "generated/shap.utils.partition_tree", "generated/shap.utils.partition_tree_shuffle", "generated/shap.utils.potential_interactions", "generated/shap.utils.sample", "generated/shap.utils.shapley_coefficients", "generated/shap.utils.show_progress", "genomic_examples", "image_examples", "index", "overviews", "release_notes", "tabular_examples", "text_examples"], "envversion": {"nbsphinx": 4, "sphinx": 63, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["api.rst", "api_examples.rst", "benchmarks.rst", "contributing.rst", "example_notebooks/api_examples/explainers/Exact.ipynb", "example_notebooks/api_examples/explainers/GPUTree.ipynb", "example_notebooks/api_examples/explainers/Permutation.ipynb", "example_notebooks/api_examples/maskers/custom.ipynb", "example_notebooks/api_examples/migrating-to-new-api.ipynb", "example_notebooks/api_examples/plots/bar.ipynb", "example_notebooks/api_examples/plots/beeswarm.ipynb", "example_notebooks/api_examples/plots/decision_plot.ipynb", "example_notebooks/api_examples/plots/heatmap.ipynb", "example_notebooks/api_examples/plots/image.ipynb", "example_notebooks/api_examples/plots/scatter.ipynb", "example_notebooks/api_examples/plots/text.ipynb", "example_notebooks/api_examples/plots/violin.ipynb", "example_notebooks/api_examples/plots/waterfall.ipynb", "example_notebooks/benchmarks/image/Image Multiclass Classification Benchmark Demo.ipynb", "example_notebooks/benchmarks/others/Benchmark Debug Mode.ipynb", "example_notebooks/benchmarks/tabular/Benchmark XGBoost explanations.ipynb", "example_notebooks/benchmarks/tabular/Tabular Prediction Benchmark Demo.ipynb", "example_notebooks/benchmarks/text/Abstractive Summarization Benchmark Demo.ipynb", "example_notebooks/benchmarks/text/Machine Translation Benchmark Demo.ipynb", "example_notebooks/benchmarks/text/Text Emotion Multiclass Classification Benchmark Demo.ipynb", "example_notebooks/genomic_examples/DeepExplainer Genomics Example.ipynb", "example_notebooks/image_examples/image_captioning/Image Captioning using Azure Cognitive Services.ipynb", "example_notebooks/image_examples/image_captioning/Image Captioning using Open Source.ipynb", "example_notebooks/image_examples/image_classification/Explain MobilenetV2 using the Partition explainer (PyTorch).ipynb", "example_notebooks/image_examples/image_classification/Explain ResNet50 using the Partition explainer.ipynb", "example_notebooks/image_examples/image_classification/Explain an Intermediate Layer of VGG16 on ImageNet.ipynb", "example_notebooks/image_examples/image_classification/Explain an Intermediate Layer of VGG16 on ImageNet (PyTorch).ipynb", "example_notebooks/image_examples/image_classification/Front Page DeepExplainer MNIST Example.ipynb", "example_notebooks/image_examples/image_classification/Image Multi Class.ipynb", "example_notebooks/image_examples/image_classification/Multi-class ResNet50 on ImageNet (TensorFlow).ipynb", "example_notebooks/image_examples/image_classification/Multi-class ResNet50 on ImageNet (TensorFlow)-checkpoint.ipynb", "example_notebooks/image_examples/image_classification/Multi-input Gradient Explainer MNIST Example.ipynb", "example_notebooks/image_examples/image_classification/PyTorch Deep Explainer MNIST example.ipynb", "example_notebooks/overviews/An introduction to explainable AI with Shapley values.ipynb", "example_notebooks/overviews/Be careful when interpreting predictive models in search of causal insights.ipynb", "example_notebooks/overviews/Explaining quantitative measures of fairness.ipynb", "example_notebooks/tabular_examples/linear_models/Explaining a model that uses standardized features.ipynb", "example_notebooks/tabular_examples/linear_models/Math behind LinearExplainer with correlation feature perturbation.ipynb", "example_notebooks/tabular_examples/linear_models/Sentiment Analysis with Logistic Regression.ipynb", "example_notebooks/tabular_examples/model_agnostic/Census income classification with scikit-learn.ipynb", "example_notebooks/tabular_examples/model_agnostic/Diabetes regression.ipynb", "example_notebooks/tabular_examples/model_agnostic/Iris classification with scikit-learn.ipynb", "example_notebooks/tabular_examples/model_agnostic/Multioutput Regression SHAP.ipynb", "example_notebooks/tabular_examples/model_agnostic/Simple California Demo.ipynb", "example_notebooks/tabular_examples/model_agnostic/Simple Kernel SHAP.ipynb", "example_notebooks/tabular_examples/model_agnostic/Squashing Effect.ipynb", "example_notebooks/tabular_examples/neural_networks/Census income classification with Keras.ipynb", "example_notebooks/tabular_examples/tree_based_models/Basic SHAP Interaction Value Example in XGBoost.ipynb", "example_notebooks/tabular_examples/tree_based_models/Catboost tutorial.ipynb", "example_notebooks/tabular_examples/tree_based_models/Census income classification with LightGBM.ipynb", "example_notebooks/tabular_examples/tree_based_models/Census income classification with XGBoost.ipynb", "example_notebooks/tabular_examples/tree_based_models/Example of loading a custom tree model into SHAP.ipynb", "example_notebooks/tabular_examples/tree_based_models/Explaining a simple OR function.ipynb", "example_notebooks/tabular_examples/tree_based_models/Explaining the Loss of a Model.ipynb", "example_notebooks/tabular_examples/tree_based_models/Fitting a Linear Simulation with XGBoost.ipynb", "example_notebooks/tabular_examples/tree_based_models/Force Plot Colors.ipynb", "example_notebooks/tabular_examples/tree_based_models/Front page example (XGBoost).ipynb", "example_notebooks/tabular_examples/tree_based_models/League of Legends Win Prediction with XGBoost.ipynb", "example_notebooks/tabular_examples/tree_based_models/NHANES I Survival Model.ipynb", "example_notebooks/tabular_examples/tree_based_models/Perfomance Comparison.ipynb", "example_notebooks/tabular_examples/tree_based_models/Python Version of Tree SHAP.ipynb", "example_notebooks/tabular_examples/tree_based_models/Scatter Density vs. Violin Plot Comparison.ipynb", "example_notebooks/tabular_examples/tree_based_models/Understanding Tree SHAP for Simple Models.ipynb", "example_notebooks/text_examples/language_modelling/Language Modeling Explanation Demo.ipynb", "example_notebooks/text_examples/question_answering/Explaining a Question Answering Transformers Model.ipynb", "example_notebooks/text_examples/sentiment_analysis/Emotion classification multiclass example.ipynb", "example_notebooks/text_examples/sentiment_analysis/Keras LSTM for IMDB Sentiment Classification.ipynb", "example_notebooks/text_examples/sentiment_analysis/Positive vs. Negative Sentiment Classification.ipynb", "example_notebooks/text_examples/sentiment_analysis/Using custom functions and tokenizers.ipynb", "example_notebooks/text_examples/summarization/Abstractive Summarization Explanation Demo.ipynb", "example_notebooks/text_examples/text_entailment/Textual Entailment Explanation Demo.ipynb", "example_notebooks/text_examples/text_generation/Open Ended GPT2 Text Generation Explanations.ipynb", "example_notebooks/text_examples/translation/Machine Translation Explanations.ipynb", "generated/shap.AdditiveExplainer.rst", "generated/shap.Cohorts.rst", "generated/shap.DeepExplainer.rst", "generated/shap.ExactExplainer.rst", "generated/shap.Explainer.rst", "generated/shap.Explanation.rst", "generated/shap.GPUTreeExplainer.rst", "generated/shap.GradientExplainer.rst", "generated/shap.KernelExplainer.rst", "generated/shap.LinearExplainer.rst", "generated/shap.PartitionExplainer.rst", "generated/shap.PermutationExplainer.rst", "generated/shap.SamplingExplainer.rst", "generated/shap.TreeExplainer.rst", "generated/shap.datasets.a1a.rst", "generated/shap.datasets.adult.rst", "generated/shap.datasets.california.rst", "generated/shap.datasets.communitiesandcrime.rst", "generated/shap.datasets.corrgroups60.rst", "generated/shap.datasets.diabetes.rst", "generated/shap.datasets.imagenet50.rst", "generated/shap.datasets.imdb.rst", "generated/shap.datasets.independentlinear60.rst", "generated/shap.datasets.iris.rst", "generated/shap.datasets.linnerud.rst", "generated/shap.datasets.nhanesi.rst", "generated/shap.datasets.rank.rst", "generated/shap.explainers.other.Coefficient.rst", "generated/shap.explainers.other.LimeTabular.rst", "generated/shap.explainers.other.Maple.rst", "generated/shap.explainers.other.Random.rst", "generated/shap.explainers.other.TreeGain.rst", "generated/shap.explainers.other.TreeMaple.rst", "generated/shap.maskers.Composite.rst", "generated/shap.maskers.Fixed.rst", "generated/shap.maskers.FixedComposite.rst", "generated/shap.maskers.Image.rst", "generated/shap.maskers.Impute.rst", "generated/shap.maskers.Independent.rst", "generated/shap.maskers.Masker.rst", "generated/shap.maskers.OutputComposite.rst", "generated/shap.maskers.Partition.rst", "generated/shap.maskers.Text.rst", "generated/shap.models.Model.rst", "generated/shap.models.TeacherForcing.rst", "generated/shap.models.TextGeneration.rst", "generated/shap.models.TopKLM.rst", "generated/shap.models.TransformersPipeline.rst", "generated/shap.plots.bar.rst", "generated/shap.plots.beeswarm.rst", "generated/shap.plots.decision.rst", "generated/shap.plots.embedding.rst", "generated/shap.plots.force.rst", "generated/shap.plots.group_difference.rst", "generated/shap.plots.heatmap.rst", "generated/shap.plots.image.rst", "generated/shap.plots.image_to_text.rst", "generated/shap.plots.initjs.rst", "generated/shap.plots.monitoring.rst", "generated/shap.plots.partial_dependence.rst", "generated/shap.plots.scatter.rst", "generated/shap.plots.text.rst", "generated/shap.plots.violin.rst", "generated/shap.plots.waterfall.rst", "generated/shap.utils.MaskedModel.rst", "generated/shap.utils.OpChain.rst", "generated/shap.utils.approximate_interactions.rst", "generated/shap.utils.convert_name.rst", "generated/shap.utils.delta_minimization_order.rst", "generated/shap.utils.hclust.rst", "generated/shap.utils.hclust_ordering.rst", "generated/shap.utils.make_masks.rst", "generated/shap.utils.partition_tree.rst", "generated/shap.utils.partition_tree_shuffle.rst", "generated/shap.utils.potential_interactions.rst", "generated/shap.utils.sample.rst", "generated/shap.utils.shapley_coefficients.rst", "generated/shap.utils.show_progress.rst", "genomic_examples.rst", "image_examples.rst", "index.rst", "overviews.rst", "release_notes.rst", "tabular_examples.rst", "text_examples.rst"], "indexentries": {"__init__() (shap.additiveexplainer method)": [[78, "shap.AdditiveExplainer.__init__", false]], "__init__() (shap.cohorts method)": [[79, "shap.Cohorts.__init__", false]], "__init__() (shap.deepexplainer method)": [[80, "shap.DeepExplainer.__init__", false]], "__init__() (shap.exactexplainer method)": [[81, "shap.ExactExplainer.__init__", false]], "__init__() (shap.explainer method)": [[82, "shap.Explainer.__init__", false]], "__init__() (shap.explainers.other.coefficient method)": [[105, "shap.explainers.other.Coefficient.__init__", false]], "__init__() (shap.explainers.other.limetabular method)": [[106, "shap.explainers.other.LimeTabular.__init__", false]], "__init__() (shap.explainers.other.maple method)": [[107, "shap.explainers.other.Maple.__init__", false]], "__init__() (shap.explainers.other.random method)": [[108, "shap.explainers.other.Random.__init__", false]], "__init__() (shap.explainers.other.treegain method)": [[109, "shap.explainers.other.TreeGain.__init__", false]], "__init__() (shap.explainers.other.treemaple method)": [[110, "shap.explainers.other.TreeMaple.__init__", false]], "__init__() (shap.explanation method)": [[83, "shap.Explanation.__init__", false]], "__init__() (shap.gputreeexplainer method)": [[84, "shap.GPUTreeExplainer.__init__", false]], "__init__() (shap.gradientexplainer method)": [[85, "shap.GradientExplainer.__init__", false]], "__init__() (shap.kernelexplainer method)": [[86, "shap.KernelExplainer.__init__", false]], "__init__() (shap.linearexplainer method)": [[87, "shap.LinearExplainer.__init__", false]], "__init__() (shap.maskers.composite method)": [[111, "shap.maskers.Composite.__init__", false]], "__init__() (shap.maskers.fixed method)": [[112, "shap.maskers.Fixed.__init__", false]], "__init__() (shap.maskers.fixedcomposite method)": [[113, "shap.maskers.FixedComposite.__init__", false]], "__init__() (shap.maskers.image method)": [[114, "shap.maskers.Image.__init__", false]], "__init__() (shap.maskers.impute method)": [[115, "shap.maskers.Impute.__init__", false]], "__init__() (shap.maskers.independent method)": [[116, "shap.maskers.Independent.__init__", false]], "__init__() (shap.maskers.masker method)": [[117, "shap.maskers.Masker.__init__", false]], "__init__() (shap.maskers.outputcomposite method)": [[118, "shap.maskers.OutputComposite.__init__", false]], "__init__() (shap.maskers.partition method)": [[119, "shap.maskers.Partition.__init__", false]], "__init__() (shap.maskers.text method)": [[120, "shap.maskers.Text.__init__", false]], "__init__() (shap.models.model method)": [[121, "shap.models.Model.__init__", false]], "__init__() (shap.models.teacherforcing method)": [[122, "shap.models.TeacherForcing.__init__", false]], "__init__() (shap.models.textgeneration method)": [[123, "shap.models.TextGeneration.__init__", false]], "__init__() (shap.models.topklm method)": [[124, "shap.models.TopKLM.__init__", false]], "__init__() (shap.models.transformerspipeline method)": [[125, "shap.models.TransformersPipeline.__init__", false]], "__init__() (shap.partitionexplainer method)": [[88, "shap.PartitionExplainer.__init__", false]], "__init__() (shap.permutationexplainer method)": [[89, "shap.PermutationExplainer.__init__", false]], "__init__() (shap.samplingexplainer method)": [[90, "shap.SamplingExplainer.__init__", false]], "__init__() (shap.treeexplainer method)": [[91, "shap.TreeExplainer.__init__", false]], "__init__() (shap.utils.maskedmodel method)": [[142, "shap.utils.MaskedModel.__init__", false]], "__init__() (shap.utils.opchain method)": [[143, "shap.utils.OpChain.__init__", false]], "a1a() (in module shap.datasets)": [[92, "shap.datasets.a1a", false]], "additiveexplainer (class in shap)": [[78, "shap.AdditiveExplainer", false]], "adult() (in module shap.datasets)": [[93, "shap.datasets.adult", false]], "apply() (shap.utils.opchain method)": [[143, "shap.utils.OpChain.apply", false]], "approximate_interactions() (in module shap.utils)": [[144, "shap.utils.approximate_interactions", false]], "attributions() (shap.explainers.other.maple method)": [[107, "shap.explainers.other.Maple.attributions", false]], "attributions() (shap.explainers.other.treemaple method)": [[110, "shap.explainers.other.TreeMaple.attributions", false]], "bar() (in module shap.plots)": [[126, "shap.plots.bar", false]], "base_values (shap.explanation property)": [[83, "shap.Explanation.base_values", false]], "beeswarm() (in module shap.plots)": [[127, "shap.plots.beeswarm", false]], "build_partition_tree() (shap.maskers.image method)": [[114, "shap.maskers.Image.build_partition_tree", false]], "california() (in module shap.datasets)": [[94, "shap.datasets.california", false]], "clustering (shap.explanation property)": [[83, "shap.Explanation.clustering", false]], "clustering() (shap.maskers.text method)": [[120, "shap.maskers.Text.clustering", false]], "coefficient (class in shap.explainers.other)": [[105, "shap.explainers.other.Coefficient", false]], "cohorts (class in shap)": [[79, "shap.Cohorts", false]], "cohorts (shap.cohorts property)": [[79, "shap.Cohorts.cohorts", false]], "cohorts() (shap.explanation method)": [[83, "shap.Explanation.cohorts", false]], "communitiesandcrime() (in module shap.datasets)": [[95, "shap.datasets.communitiesandcrime", false]], "composite (class in shap.maskers)": [[111, "shap.maskers.Composite", false]], "convert_name() (in module shap.utils)": [[145, "shap.utils.convert_name", false]], "corrgroups60() (in module shap.datasets)": [[96, "shap.datasets.corrgroups60", false]], "data (shap.explanation property)": [[83, "shap.Explanation.data", false]], "data_transform() (shap.maskers.composite method)": [[111, "shap.maskers.Composite.data_transform", false]], "data_transform() (shap.maskers.text method)": [[120, "shap.maskers.Text.data_transform", false]], "decision() (in module shap.plots)": [[128, "shap.plots.decision", false]], "deepexplainer (class in shap)": [[80, "shap.DeepExplainer", false]], "delta_minimization_order() (in module shap.utils)": [[146, "shap.utils.delta_minimization_order", false]], "diabetes() (in module shap.datasets)": [[97, "shap.datasets.diabetes", false]], "display_data (shap.explanation property)": [[83, "shap.Explanation.display_data", false]], "embedding() (in module shap.plots)": [[129, "shap.plots.embedding", false]], "error_std (shap.explanation property)": [[83, "shap.Explanation.error_std", false]], "exactexplainer (class in shap)": [[81, "shap.ExactExplainer", false]], "explain_row() (shap.additiveexplainer method)": [[78, "shap.AdditiveExplainer.explain_row", false]], "explain_row() (shap.deepexplainer method)": [[80, "shap.DeepExplainer.explain_row", false]], "explain_row() (shap.exactexplainer method)": [[81, "shap.ExactExplainer.explain_row", false]], "explain_row() (shap.explainer method)": [[82, "shap.Explainer.explain_row", false]], "explain_row() (shap.explainers.other.coefficient method)": [[105, "shap.explainers.other.Coefficient.explain_row", false]], "explain_row() (shap.explainers.other.limetabular method)": [[106, "shap.explainers.other.LimeTabular.explain_row", false]], "explain_row() (shap.explainers.other.maple method)": [[107, "shap.explainers.other.Maple.explain_row", false]], "explain_row() (shap.explainers.other.random method)": [[108, "shap.explainers.other.Random.explain_row", false]], "explain_row() (shap.explainers.other.treegain method)": [[109, "shap.explainers.other.TreeGain.explain_row", false]], "explain_row() (shap.explainers.other.treemaple method)": [[110, "shap.explainers.other.TreeMaple.explain_row", false]], "explain_row() (shap.gputreeexplainer method)": [[84, "shap.GPUTreeExplainer.explain_row", false]], "explain_row() (shap.gradientexplainer method)": [[85, "shap.GradientExplainer.explain_row", false]], "explain_row() (shap.kernelexplainer method)": [[86, "shap.KernelExplainer.explain_row", false]], "explain_row() (shap.linearexplainer method)": [[87, "shap.LinearExplainer.explain_row", false]], "explain_row() (shap.partitionexplainer method)": [[88, "shap.PartitionExplainer.explain_row", false]], "explain_row() (shap.permutationexplainer method)": [[89, "shap.PermutationExplainer.explain_row", false]], "explain_row() (shap.samplingexplainer method)": [[90, "shap.SamplingExplainer.explain_row", false]], "explain_row() (shap.treeexplainer method)": [[91, "shap.TreeExplainer.explain_row", false]], "explainer (class in shap)": [[82, "shap.Explainer", false]], "explanation (class in shap)": [[83, "shap.Explanation", false]], "feature_names (shap.explanation property)": [[83, "shap.Explanation.feature_names", false]], "feature_names() (shap.maskers.text method)": [[120, "shap.maskers.Text.feature_names", false]], "fixed (class in shap.maskers)": [[112, "shap.maskers.Fixed", false]], "fixedcomposite (class in shap.maskers)": [[113, "shap.maskers.FixedComposite", false]], "force() (in module shap.plots)": [[130, "shap.plots.force", false]], "generate_topk_token_ids() (shap.models.topklm method)": [[124, "shap.models.TopKLM.generate_topk_token_ids", false]], "get_inputs() (shap.models.teacherforcing method)": [[122, "shap.models.TeacherForcing.get_inputs", false]], "get_inputs() (shap.models.textgeneration method)": [[123, "shap.models.TextGeneration.get_inputs", false]], "get_inputs() (shap.models.topklm method)": [[124, "shap.models.TopKLM.get_inputs", false]], "get_lm_logits() (shap.models.topklm method)": [[124, "shap.models.TopKLM.get_lm_logits", false]], "get_logodds() (shap.models.teacherforcing method)": [[122, "shap.models.TeacherForcing.get_logodds", false]], "get_logodds() (shap.models.topklm method)": [[124, "shap.models.TopKLM.get_logodds", false]], "get_output_names() (shap.models.teacherforcing method)": [[122, "shap.models.TeacherForcing.get_output_names", false]], "get_output_names_and_update_topk_token_ids() (shap.models.topklm method)": [[124, "shap.models.TopKLM.get_output_names_and_update_topk_token_ids", false]], "get_outputs() (shap.models.teacherforcing method)": [[122, "shap.models.TeacherForcing.get_outputs", false]], "get_teacher_forced_logits() (shap.models.teacherforcing method)": [[122, "shap.models.TeacherForcing.get_teacher_forced_logits", false]], "gputreeexplainer (class in shap)": [[84, "shap.GPUTreeExplainer", false]], "gradientexplainer (class in shap)": [[85, "shap.GradientExplainer", false]], "group_difference() (in module shap.plots)": [[131, "shap.plots.group_difference", false]], "hclust() (in module shap.utils)": [[147, "shap.utils.hclust", false]], "hclust_ordering() (in module shap.utils)": [[148, "shap.utils.hclust_ordering", false]], "heatmap() (in module shap.plots)": [[132, "shap.plots.heatmap", false]], "hierarchical_values (shap.explanation property)": [[83, "shap.Explanation.hierarchical_values", false]], "hstack() (shap.explanation method)": [[83, "shap.Explanation.hstack", false]], "image (class in shap.maskers)": [[114, "shap.maskers.Image", false]], "image() (in module shap.plots)": [[133, "shap.plots.image", false]], "image_to_text() (in module shap.plots)": [[134, "shap.plots.image_to_text", false]], "imagenet50() (in module shap.datasets)": [[98, "shap.datasets.imagenet50", false]], "imdb() (in module shap.datasets)": [[99, "shap.datasets.imdb", false]], "impute (class in shap.maskers)": [[115, "shap.maskers.Impute", false]], "independent (class in shap.maskers)": [[116, "shap.maskers.Independent", false]], "independentlinear60() (in module shap.datasets)": [[100, "shap.datasets.independentlinear60", false]], "initjs() (in module shap.plots)": [[135, "shap.plots.initjs", false]], "inpaint() (shap.maskers.image method)": [[114, "shap.maskers.Image.inpaint", false]], "instance_names (shap.explanation property)": [[83, "shap.Explanation.instance_names", false]], "invariants() (shap.maskers.independent method)": [[116, "shap.maskers.Independent.invariants", false]], "invariants() (shap.maskers.partition method)": [[119, "shap.maskers.Partition.invariants", false]], "invariants() (shap.maskers.text method)": [[120, "shap.maskers.Text.invariants", false]], "iris() (in module shap.datasets)": [[101, "shap.datasets.iris", false]], "kernelexplainer (class in shap)": [[86, "shap.KernelExplainer", false]], "limetabular (class in shap.explainers.other)": [[106, "shap.explainers.other.LimeTabular", false]], "linearexplainer (class in shap)": [[87, "shap.LinearExplainer", false]], "linnerud() (in module shap.datasets)": [[102, "shap.datasets.linnerud", false]], "load() (shap.additiveexplainer class method)": [[78, "shap.AdditiveExplainer.load", false]], "load() (shap.deepexplainer class method)": [[80, "shap.DeepExplainer.load", false]], "load() (shap.exactexplainer class method)": [[81, "shap.ExactExplainer.load", false]], "load() (shap.explainer class method)": [[82, "shap.Explainer.load", false]], "load() (shap.explainers.other.coefficient class method)": [[105, "shap.explainers.other.Coefficient.load", false]], "load() (shap.explainers.other.limetabular class method)": [[106, "shap.explainers.other.LimeTabular.load", false]], "load() (shap.explainers.other.maple class method)": [[107, "shap.explainers.other.Maple.load", false]], "load() (shap.explainers.other.random class method)": [[108, "shap.explainers.other.Random.load", false]], "load() (shap.explainers.other.treegain class method)": [[109, "shap.explainers.other.TreeGain.load", false]], "load() (shap.explainers.other.treemaple class method)": [[110, "shap.explainers.other.TreeMaple.load", false]], "load() (shap.gputreeexplainer class method)": [[84, "shap.GPUTreeExplainer.load", false]], "load() (shap.gradientexplainer class method)": [[85, "shap.GradientExplainer.load", false]], "load() (shap.kernelexplainer class method)": [[86, "shap.KernelExplainer.load", false]], "load() (shap.linearexplainer class method)": [[87, "shap.LinearExplainer.load", false]], "load() (shap.maskers.composite class method)": [[111, "shap.maskers.Composite.load", false]], "load() (shap.maskers.fixed class method)": [[112, "shap.maskers.Fixed.load", false]], "load() (shap.maskers.fixedcomposite class method)": [[113, "shap.maskers.FixedComposite.load", false]], "load() (shap.maskers.image class method)": [[114, "shap.maskers.Image.load", false]], "load() (shap.maskers.impute class method)": [[115, "shap.maskers.Impute.load", false]], "load() (shap.maskers.independent class method)": [[116, "shap.maskers.Independent.load", false]], "load() (shap.maskers.masker class method)": [[117, "shap.maskers.Masker.load", false]], "load() (shap.maskers.outputcomposite class method)": [[118, "shap.maskers.OutputComposite.load", false]], "load() (shap.maskers.partition class method)": [[119, "shap.maskers.Partition.load", false]], "load() (shap.maskers.text class method)": [[120, "shap.maskers.Text.load", false]], "load() (shap.models.model class method)": [[121, "shap.models.Model.load", false]], "load() (shap.models.teacherforcing class method)": [[122, "shap.models.TeacherForcing.load", false]], "load() (shap.models.textgeneration class method)": [[123, "shap.models.TextGeneration.load", false]], "load() (shap.models.topklm class method)": [[124, "shap.models.TopKLM.load", false]], "load() (shap.models.transformerspipeline class method)": [[125, "shap.models.TransformersPipeline.load", false]], "load() (shap.partitionexplainer class method)": [[88, "shap.PartitionExplainer.load", false]], "load() (shap.permutationexplainer class method)": [[89, "shap.PermutationExplainer.load", false]], "load() (shap.samplingexplainer class method)": [[90, "shap.SamplingExplainer.load", false]], "load() (shap.treeexplainer class method)": [[91, "shap.TreeExplainer.load", false]], "lower_bounds (shap.explanation property)": [[83, "shap.Explanation.lower_bounds", false]], "main_effects (shap.explanation property)": [[83, "shap.Explanation.main_effects", false]], "main_effects() (shap.utils.maskedmodel method)": [[142, "shap.utils.MaskedModel.main_effects", false]], "make_masks() (in module shap.utils)": [[149, "shap.utils.make_masks", false]], "maple (class in shap.explainers.other)": [[107, "shap.explainers.other.Maple", false]], "mask_shapes() (shap.maskers.composite method)": [[111, "shap.maskers.Composite.mask_shapes", false]], "mask_shapes() (shap.maskers.fixed method)": [[112, "shap.maskers.Fixed.mask_shapes", false]], "mask_shapes() (shap.maskers.text method)": [[120, "shap.maskers.Text.mask_shapes", false]], "maskedmodel (class in shap.utils)": [[142, "shap.utils.MaskedModel", false]], "masker (class in shap.maskers)": [[117, "shap.maskers.Masker", false]], "model (class in shap.models)": [[121, "shap.models.Model", false]], "model_generate() (shap.models.textgeneration method)": [[123, "shap.models.TextGeneration.model_generate", false]], "model_inference() (shap.models.teacherforcing method)": [[122, "shap.models.TeacherForcing.model_inference", false]], "monitoring() (in module shap.plots)": [[136, "shap.plots.monitoring", false]], "nhanesi() (in module shap.datasets)": [[103, "shap.datasets.nhanesi", false]], "opchain (class in shap.utils)": [[143, "shap.utils.OpChain", false]], "output_indexes (shap.explanation property)": [[83, "shap.Explanation.output_indexes", false]], "output_names (shap.explanation property)": [[83, "shap.Explanation.output_names", false]], "outputcomposite (class in shap.maskers)": [[118, "shap.maskers.OutputComposite", false]], "owen() (shap.partitionexplainer method)": [[88, "shap.PartitionExplainer.owen", false]], "owen3() (shap.partitionexplainer method)": [[88, "shap.PartitionExplainer.owen3", false]], "parse_prefix_suffix_for_model_generate_output() (shap.models.textgeneration method)": [[123, "shap.models.TextGeneration.parse_prefix_suffix_for_model_generate_output", false]], "partial_dependence() (in module shap.plots)": [[137, "shap.plots.partial_dependence", false]], "partition (class in shap.maskers)": [[119, "shap.maskers.Partition", false]], "partition_tree() (in module shap.utils)": [[150, "shap.utils.partition_tree", false]], "partition_tree_shuffle() (in module shap.utils)": [[151, "shap.utils.partition_tree_shuffle", false]], "partitionexplainer (class in shap)": [[88, "shap.PartitionExplainer", false]], "permutationexplainer (class in shap)": [[89, "shap.PermutationExplainer", false]], "potential_interactions() (in module shap.utils)": [[152, "shap.utils.potential_interactions", false]], "random (class in shap.explainers.other)": [[108, "shap.explainers.other.Random", false]], "rank() (in module shap.datasets)": [[104, "shap.datasets.rank", false]], "sample() (in module shap.utils)": [[153, "shap.utils.sample", false]], "samplingexplainer (class in shap)": [[90, "shap.SamplingExplainer", false]], "save() (shap.additiveexplainer method)": [[78, "shap.AdditiveExplainer.save", false]], "save() (shap.deepexplainer method)": [[80, "shap.DeepExplainer.save", false]], "save() (shap.exactexplainer method)": [[81, "shap.ExactExplainer.save", false]], "save() (shap.explainer method)": [[82, "shap.Explainer.save", false]], "save() (shap.explainers.other.coefficient method)": [[105, "shap.explainers.other.Coefficient.save", false]], "save() (shap.explainers.other.limetabular method)": [[106, "shap.explainers.other.LimeTabular.save", false]], "save() (shap.explainers.other.maple method)": [[107, "shap.explainers.other.Maple.save", false]], "save() (shap.explainers.other.random method)": [[108, "shap.explainers.other.Random.save", false]], "save() (shap.explainers.other.treegain method)": [[109, "shap.explainers.other.TreeGain.save", false]], "save() (shap.explainers.other.treemaple method)": [[110, "shap.explainers.other.TreeMaple.save", false]], "save() (shap.gputreeexplainer method)": [[84, "shap.GPUTreeExplainer.save", false]], "save() (shap.gradientexplainer method)": [[85, "shap.GradientExplainer.save", false]], "save() (shap.kernelexplainer method)": [[86, "shap.KernelExplainer.save", false]], "save() (shap.linearexplainer method)": [[87, "shap.LinearExplainer.save", false]], "save() (shap.maskers.composite method)": [[111, "shap.maskers.Composite.save", false]], "save() (shap.maskers.fixed method)": [[112, "shap.maskers.Fixed.save", false]], "save() (shap.maskers.fixedcomposite method)": [[113, "shap.maskers.FixedComposite.save", false]], "save() (shap.maskers.image method)": [[114, "shap.maskers.Image.save", false]], "save() (shap.maskers.impute method)": [[115, "shap.maskers.Impute.save", false]], "save() (shap.maskers.independent method)": [[116, "shap.maskers.Independent.save", false]], "save() (shap.maskers.masker method)": [[117, "shap.maskers.Masker.save", false]], "save() (shap.maskers.outputcomposite method)": [[118, "shap.maskers.OutputComposite.save", false]], "save() (shap.maskers.partition method)": [[119, "shap.maskers.Partition.save", false]], "save() (shap.maskers.text method)": [[120, "shap.maskers.Text.save", false]], "save() (shap.models.model method)": [[121, "shap.models.Model.save", false]], "save() (shap.models.teacherforcing method)": [[122, "shap.models.TeacherForcing.save", false]], "save() (shap.models.textgeneration method)": [[123, "shap.models.TextGeneration.save", false]], "save() (shap.models.topklm method)": [[124, "shap.models.TopKLM.save", false]], "save() (shap.models.transformerspipeline method)": [[125, "shap.models.TransformersPipeline.save", false]], "save() (shap.partitionexplainer method)": [[88, "shap.PartitionExplainer.save", false]], "save() (shap.permutationexplainer method)": [[89, "shap.PermutationExplainer.save", false]], "save() (shap.samplingexplainer method)": [[90, "shap.SamplingExplainer.save", false]], "save() (shap.treeexplainer method)": [[91, "shap.TreeExplainer.save", false]], "scatter() (in module shap.plots)": [[138, "shap.plots.scatter", false]], "shap_interaction_values() (shap.gputreeexplainer method)": [[84, "shap.GPUTreeExplainer.shap_interaction_values", false]], "shap_interaction_values() (shap.treeexplainer method)": [[91, "shap.TreeExplainer.shap_interaction_values", false]], "shap_values() (shap.deepexplainer method)": [[80, "shap.DeepExplainer.shap_values", false]], "shap_values() (shap.gputreeexplainer method)": [[84, "shap.GPUTreeExplainer.shap_values", false]], "shap_values() (shap.gradientexplainer method)": [[85, "shap.GradientExplainer.shap_values", false]], "shap_values() (shap.kernelexplainer method)": [[86, "shap.KernelExplainer.shap_values", false]], "shap_values() (shap.linearexplainer method)": [[87, "shap.LinearExplainer.shap_values", false]], "shap_values() (shap.permutationexplainer method)": [[89, "shap.PermutationExplainer.shap_values", false]], "shap_values() (shap.samplingexplainer method)": [[90, "shap.SamplingExplainer.shap_values", false]], "shap_values() (shap.treeexplainer method)": [[91, "shap.TreeExplainer.shap_values", false]], "shape (shap.explanation property)": [[83, "shap.Explanation.shape", false]], "shape() (shap.maskers.composite method)": [[111, "shap.maskers.Composite.shape", false]], "shape() (shap.maskers.text method)": [[120, "shap.maskers.Text.shape", false]], "shapley_coefficients() (in module shap.utils)": [[154, "shap.utils.shapley_coefficients", false]], "show_progress() (in module shap.utils)": [[155, "shap.utils.show_progress", false]], "supports_model_with_masker() (shap.additiveexplainer static method)": [[78, "shap.AdditiveExplainer.supports_model_with_masker", false]], "supports_model_with_masker() (shap.deepexplainer static method)": [[80, "shap.DeepExplainer.supports_model_with_masker", false]], "supports_model_with_masker() (shap.exactexplainer static method)": [[81, "shap.ExactExplainer.supports_model_with_masker", false]], "supports_model_with_masker() (shap.explainer static method)": [[82, "shap.Explainer.supports_model_with_masker", false]], "supports_model_with_masker() (shap.explainers.other.coefficient static method)": [[105, "shap.explainers.other.Coefficient.supports_model_with_masker", false]], "supports_model_with_masker() (shap.explainers.other.limetabular static method)": [[106, "shap.explainers.other.LimeTabular.supports_model_with_masker", false]], "supports_model_with_masker() (shap.explainers.other.maple static method)": [[107, "shap.explainers.other.Maple.supports_model_with_masker", false]], "supports_model_with_masker() (shap.explainers.other.random static method)": [[108, "shap.explainers.other.Random.supports_model_with_masker", false]], "supports_model_with_masker() (shap.explainers.other.treegain static method)": [[109, "shap.explainers.other.TreeGain.supports_model_with_masker", false]], "supports_model_with_masker() (shap.explainers.other.treemaple static method)": [[110, "shap.explainers.other.TreeMaple.supports_model_with_masker", false]], "supports_model_with_masker() (shap.gputreeexplainer static method)": [[84, "shap.GPUTreeExplainer.supports_model_with_masker", false]], "supports_model_with_masker() (shap.gradientexplainer static method)": [[85, "shap.GradientExplainer.supports_model_with_masker", false]], "supports_model_with_masker() (shap.kernelexplainer static method)": [[86, "shap.KernelExplainer.supports_model_with_masker", false]], "supports_model_with_masker() (shap.linearexplainer static method)": [[87, "shap.LinearExplainer.supports_model_with_masker", false]], "supports_model_with_masker() (shap.partitionexplainer static method)": [[88, "shap.PartitionExplainer.supports_model_with_masker", false]], "supports_model_with_masker() (shap.permutationexplainer static method)": [[89, "shap.PermutationExplainer.supports_model_with_masker", false]], "supports_model_with_masker() (shap.samplingexplainer static method)": [[90, "shap.SamplingExplainer.supports_model_with_masker", false]], "supports_model_with_masker() (shap.treeexplainer static method)": [[91, "shap.TreeExplainer.supports_model_with_masker", false]], "teacherforcing (class in shap.models)": [[122, "shap.models.TeacherForcing", false]], "text (class in shap.maskers)": [[120, "shap.maskers.Text", false]], "text() (in module shap.plots)": [[139, "shap.plots.text", false]], "textgeneration (class in shap.models)": [[123, "shap.models.TextGeneration", false]], "token_segments() (shap.maskers.text method)": [[120, "shap.maskers.Text.token_segments", false]], "topklm (class in shap.models)": [[124, "shap.models.TopKLM", false]], "transformerspipeline (class in shap.models)": [[125, "shap.models.TransformersPipeline", false]], "treeexplainer (class in shap)": [[91, "shap.TreeExplainer", false]], "treegain (class in shap.explainers.other)": [[109, "shap.explainers.other.TreeGain", false]], "treemaple (class in shap.explainers.other)": [[110, "shap.explainers.other.TreeMaple", false]], "update_cache_x() (shap.models.topklm method)": [[124, "shap.models.TopKLM.update_cache_X", false]], "update_output_names() (shap.models.teacherforcing method)": [[122, "shap.models.TeacherForcing.update_output_names", false]], "upper_bounds (shap.explanation property)": [[83, "shap.Explanation.upper_bounds", false]], "values (shap.explanation property)": [[83, "shap.Explanation.values", false]], "violin() (in module shap.plots)": [[140, "shap.plots.violin", false]], "waterfall() (in module shap.plots)": [[141, "shap.plots.waterfall", false]]}, "objects": {"shap": [[78, 0, 1, "", "AdditiveExplainer"], [79, 0, 1, "", "Cohorts"], [80, 0, 1, "", "DeepExplainer"], [81, 0, 1, "", "ExactExplainer"], [82, 0, 1, "", "Explainer"], [83, 0, 1, "", "Explanation"], [84, 0, 1, "", "GPUTreeExplainer"], [85, 0, 1, "", "GradientExplainer"], [86, 0, 1, "", "KernelExplainer"], [87, 0, 1, "", "LinearExplainer"], [88, 0, 1, "", "PartitionExplainer"], [89, 0, 1, "", "PermutationExplainer"], [90, 0, 1, "", "SamplingExplainer"], [91, 0, 1, "", "TreeExplainer"]], "shap.AdditiveExplainer": [[78, 1, 1, "", "__init__"], [78, 1, 1, "", "explain_row"], [78, 1, 1, "", "load"], [78, 1, 1, "", "save"], [78, 1, 1, "", "supports_model_with_masker"]], "shap.Cohorts": [[79, 1, 1, "", "__init__"], [79, 2, 1, "", "cohorts"]], "shap.DeepExplainer": [[80, 1, 1, "", "__init__"], [80, 1, 1, "", "explain_row"], [80, 1, 1, "", "load"], [80, 1, 1, "", "save"], [80, 1, 1, "", "shap_values"], [80, 1, 1, "", "supports_model_with_masker"]], "shap.ExactExplainer": [[81, 1, 1, "", "__init__"], [81, 1, 1, "", "explain_row"], [81, 1, 1, "", "load"], [81, 1, 1, "", "save"], [81, 1, 1, "", "supports_model_with_masker"]], "shap.Explainer": [[82, 1, 1, "", "__init__"], [82, 1, 1, "", "explain_row"], [82, 1, 1, "", "load"], [82, 1, 1, "", "save"], [82, 1, 1, "", "supports_model_with_masker"]], "shap.Explanation": [[83, 1, 1, "", "__init__"], [83, 2, 1, "", "base_values"], [83, 2, 1, "", "clustering"], [83, 1, 1, "", "cohorts"], [83, 2, 1, "", "data"], [83, 2, 1, "", "display_data"], [83, 2, 1, "", "error_std"], [83, 2, 1, "", "feature_names"], [83, 2, 1, "", "hierarchical_values"], [83, 1, 1, "", "hstack"], [83, 2, 1, "", "instance_names"], [83, 2, 1, "", "lower_bounds"], [83, 2, 1, "", "main_effects"], [83, 2, 1, "", "output_indexes"], [83, 2, 1, "", "output_names"], [83, 2, 1, "", "shape"], [83, 2, 1, "", "upper_bounds"], [83, 2, 1, "", "values"]], "shap.GPUTreeExplainer": [[84, 1, 1, "", "__init__"], [84, 1, 1, "", "explain_row"], [84, 1, 1, "", "load"], [84, 1, 1, "", "save"], [84, 1, 1, "", "shap_interaction_values"], [84, 1, 1, "", "shap_values"], [84, 1, 1, "", "supports_model_with_masker"]], "shap.GradientExplainer": [[85, 1, 1, "", "__init__"], [85, 1, 1, "", "explain_row"], [85, 1, 1, "", "load"], [85, 1, 1, "", "save"], [85, 1, 1, "", "shap_values"], [85, 1, 1, "", "supports_model_with_masker"]], "shap.KernelExplainer": [[86, 1, 1, "", "__init__"], [86, 1, 1, "", "explain_row"], [86, 1, 1, "", "load"], [86, 1, 1, "", "save"], [86, 1, 1, "", "shap_values"], [86, 1, 1, "", "supports_model_with_masker"]], "shap.LinearExplainer": [[87, 1, 1, "", "__init__"], [87, 1, 1, "", "explain_row"], [87, 1, 1, "", "load"], [87, 1, 1, "", "save"], [87, 1, 1, "", "shap_values"], [87, 1, 1, "", "supports_model_with_masker"]], "shap.PartitionExplainer": [[88, 1, 1, "", "__init__"], [88, 1, 1, "", "explain_row"], [88, 1, 1, "", "load"], [88, 1, 1, "", "owen"], [88, 1, 1, "", "owen3"], [88, 1, 1, "", "save"], [88, 1, 1, "", "supports_model_with_masker"]], "shap.PermutationExplainer": [[89, 1, 1, "", "__init__"], [89, 1, 1, "", "explain_row"], [89, 1, 1, "", "load"], [89, 1, 1, "", "save"], [89, 1, 1, "", "shap_values"], [89, 1, 1, "", "supports_model_with_masker"]], "shap.SamplingExplainer": [[90, 1, 1, "", "__init__"], [90, 1, 1, "", "explain_row"], [90, 1, 1, "", "load"], [90, 1, 1, "", "save"], [90, 1, 1, "", "shap_values"], [90, 1, 1, "", "supports_model_with_masker"]], "shap.TreeExplainer": [[91, 1, 1, "", "__init__"], [91, 1, 1, "", "explain_row"], [91, 1, 1, "", "load"], [91, 1, 1, "", "save"], [91, 1, 1, "", "shap_interaction_values"], [91, 1, 1, "", "shap_values"], [91, 1, 1, "", "supports_model_with_masker"]], "shap.datasets": [[92, 3, 1, "", "a1a"], [93, 3, 1, "", "adult"], [94, 3, 1, "", "california"], [95, 3, 1, "", "communitiesandcrime"], [96, 3, 1, "", "corrgroups60"], [97, 3, 1, "", "diabetes"], [98, 3, 1, "", "imagenet50"], [99, 3, 1, "", "imdb"], [100, 3, 1, "", "independentlinear60"], [101, 3, 1, "", "iris"], [102, 3, 1, "", "linnerud"], [103, 3, 1, "", "nhanesi"], [104, 3, 1, "", "rank"]], "shap.explainers.other": [[105, 0, 1, "", "Coefficient"], [106, 0, 1, "", "LimeTabular"], [107, 0, 1, "", "Maple"], [108, 0, 1, "", "Random"], [109, 0, 1, "", "TreeGain"], [110, 0, 1, "", "TreeMaple"]], "shap.explainers.other.Coefficient": [[105, 1, 1, "", "__init__"], [105, 1, 1, "", "explain_row"], [105, 1, 1, "", "load"], [105, 1, 1, "", "save"], [105, 1, 1, "", "supports_model_with_masker"]], "shap.explainers.other.LimeTabular": [[106, 1, 1, "", "__init__"], [106, 1, 1, "", "explain_row"], [106, 1, 1, "", "load"], [106, 1, 1, "", "save"], [106, 1, 1, "", "supports_model_with_masker"]], "shap.explainers.other.Maple": [[107, 1, 1, "", "__init__"], [107, 1, 1, "", "attributions"], [107, 1, 1, "", "explain_row"], [107, 1, 1, "", "load"], [107, 1, 1, "", "save"], [107, 1, 1, "", "supports_model_with_masker"]], "shap.explainers.other.Random": [[108, 1, 1, "", "__init__"], [108, 1, 1, "", "explain_row"], [108, 1, 1, "", "load"], [108, 1, 1, "", "save"], [108, 1, 1, "", "supports_model_with_masker"]], "shap.explainers.other.TreeGain": [[109, 1, 1, "", "__init__"], [109, 1, 1, "", "explain_row"], [109, 1, 1, "", "load"], [109, 1, 1, "", "save"], [109, 1, 1, "", "supports_model_with_masker"]], "shap.explainers.other.TreeMaple": [[110, 1, 1, "", "__init__"], [110, 1, 1, "", "attributions"], [110, 1, 1, "", "explain_row"], [110, 1, 1, "", "load"], [110, 1, 1, "", "save"], [110, 1, 1, "", "supports_model_with_masker"]], "shap.maskers": [[111, 0, 1, "", "Composite"], [112, 0, 1, "", "Fixed"], [113, 0, 1, "", "FixedComposite"], [114, 0, 1, "", "Image"], [115, 0, 1, "", "Impute"], [116, 0, 1, "", "Independent"], [117, 0, 1, "", "Masker"], [118, 0, 1, "", "OutputComposite"], [119, 0, 1, "", "Partition"], [120, 0, 1, "", "Text"]], "shap.maskers.Composite": [[111, 1, 1, "", "__init__"], [111, 1, 1, "", "data_transform"], [111, 1, 1, "", "load"], [111, 1, 1, "", "mask_shapes"], [111, 1, 1, "", "save"], [111, 1, 1, "", "shape"]], "shap.maskers.Fixed": [[112, 1, 1, "", "__init__"], [112, 1, 1, "", "load"], [112, 1, 1, "", "mask_shapes"], [112, 1, 1, "", "save"]], "shap.maskers.FixedComposite": [[113, 1, 1, "", "__init__"], [113, 1, 1, "", "load"], [113, 1, 1, "", "save"]], "shap.maskers.Image": [[114, 1, 1, "", "__init__"], [114, 1, 1, "", "build_partition_tree"], [114, 1, 1, "", "inpaint"], [114, 1, 1, "", "load"], [114, 1, 1, "", "save"]], "shap.maskers.Impute": [[115, 1, 1, "", "__init__"], [115, 1, 1, "", "load"], [115, 1, 1, "", "save"]], "shap.maskers.Independent": [[116, 1, 1, "", "__init__"], [116, 1, 1, "", "invariants"], [116, 1, 1, "", "load"], [116, 1, 1, "", "save"]], "shap.maskers.Masker": [[117, 1, 1, "", "__init__"], [117, 1, 1, "", "load"], [117, 1, 1, "", "save"]], "shap.maskers.OutputComposite": [[118, 1, 1, "", "__init__"], [118, 1, 1, "", "load"], [118, 1, 1, "", "save"]], "shap.maskers.Partition": [[119, 1, 1, "", "__init__"], [119, 1, 1, "", "invariants"], [119, 1, 1, "", "load"], [119, 1, 1, "", "save"]], "shap.maskers.Text": [[120, 1, 1, "", "__init__"], [120, 1, 1, "", "clustering"], [120, 1, 1, "", "data_transform"], [120, 1, 1, "", "feature_names"], [120, 1, 1, "", "invariants"], [120, 1, 1, "", "load"], [120, 1, 1, "", "mask_shapes"], [120, 1, 1, "", "save"], [120, 1, 1, "", "shape"], [120, 1, 1, "", "token_segments"]], "shap.models": [[121, 0, 1, "", "Model"], [122, 0, 1, "", "TeacherForcing"], [123, 0, 1, "", "TextGeneration"], [124, 0, 1, "", "TopKLM"], [125, 0, 1, "", "TransformersPipeline"]], "shap.models.Model": [[121, 1, 1, "", "__init__"], [121, 1, 1, "", "load"], [121, 1, 1, "", "save"]], "shap.models.TeacherForcing": [[122, 1, 1, "", "__init__"], [122, 1, 1, "", "get_inputs"], [122, 1, 1, "", "get_logodds"], [122, 1, 1, "", "get_output_names"], [122, 1, 1, "", "get_outputs"], [122, 1, 1, "", "get_teacher_forced_logits"], [122, 1, 1, "", "load"], [122, 1, 1, "", "model_inference"], [122, 1, 1, "", "save"], [122, 1, 1, "", "update_output_names"]], "shap.models.TextGeneration": [[123, 1, 1, "", "__init__"], [123, 1, 1, "", "get_inputs"], [123, 1, 1, "", "load"], [123, 1, 1, "", "model_generate"], [123, 1, 1, "", "parse_prefix_suffix_for_model_generate_output"], [123, 1, 1, "", "save"]], "shap.models.TopKLM": [[124, 1, 1, "", "__init__"], [124, 1, 1, "", "generate_topk_token_ids"], [124, 1, 1, "", "get_inputs"], [124, 1, 1, "", "get_lm_logits"], [124, 1, 1, "", "get_logodds"], [124, 1, 1, "", "get_output_names_and_update_topk_token_ids"], [124, 1, 1, "", "load"], [124, 1, 1, "", "save"], [124, 1, 1, "", "update_cache_X"]], "shap.models.TransformersPipeline": [[125, 1, 1, "", "__init__"], [125, 1, 1, "", "load"], [125, 1, 1, "", "save"]], "shap.plots": [[126, 3, 1, "", "bar"], [127, 3, 1, "", "beeswarm"], [128, 3, 1, "", "decision"], [129, 3, 1, "", "embedding"], [130, 3, 1, "", "force"], [131, 3, 1, "", "group_difference"], [132, 3, 1, "", "heatmap"], [133, 3, 1, "", "image"], [134, 3, 1, "", "image_to_text"], [135, 3, 1, "", "initjs"], [136, 3, 1, "", "monitoring"], [137, 3, 1, "", "partial_dependence"], [138, 3, 1, "", "scatter"], [139, 3, 1, "", "text"], [140, 3, 1, "", "violin"], [141, 3, 1, "", "waterfall"]], "shap.utils": [[142, 0, 1, "", "MaskedModel"], [143, 0, 1, "", "OpChain"], [144, 3, 1, "", "approximate_interactions"], [145, 3, 1, "", "convert_name"], [146, 3, 1, "", "delta_minimization_order"], [147, 3, 1, "", "hclust"], [148, 3, 1, "", "hclust_ordering"], [149, 3, 1, "", "make_masks"], [150, 3, 1, "", "partition_tree"], [151, 3, 1, "", "partition_tree_shuffle"], [152, 3, 1, "", "potential_interactions"], [153, 3, 1, "", "sample"], [154, 3, 1, "", "shapley_coefficients"], [155, 3, 1, "", "show_progress"]], "shap.utils.MaskedModel": [[142, 1, 1, "", "__init__"], [142, 1, 1, "", "main_effects"]], "shap.utils.OpChain": [[143, 1, 1, "", "__init__"], [143, 1, 1, "", "apply"]]}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "property", "Python property"], "3": ["py", "function", "Python function"]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:property", "3": "py:function"}, "terms": {"": [3, 4, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 33, 36, 38, 39, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 60, 61, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 80, 84, 85, 86, 87, 88, 89, 90, 91, 112, 118, 119, 120, 127, 128, 129, 136, 138, 141, 144, 152, 153], "0": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162], "00": [4, 10, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 32, 33, 34, 35, 38, 40, 44, 45, 48, 51, 52, 56, 58, 67, 69, 70, 72, 74, 75, 77], "000": [11, 39, 54, 55, 62, 67, 96, 100], "0000": [38, 57], "000000": 51, "000000000000002": 49, "000006": 64, "0000999": 52, "0000e": 56, "000100001693": 52, "000100019999": 52, "00010002": 52, "00024": 52, "00029": 69, "00029base": 69, "000382330": 70, "00038233fsurpris": 70, "0004076050": 70, "000407605fsurpris": 70, "000462820": 70, "00046282fanger": 70, "0005347490392160024": 52, "00059": 68, "00059f": 68, "0006467590": 70, "000646759ffear": 70, "0006490040": 70, "000649004flove": 70, "0006807040": 70, "000680704fjoi": 70, "0006832050": 70, "000683205fjoi": 70, "0009963020": 70, "000996302flove": 70, "000e": 56, "001": [38, 39, 68, 69, 70, 74, 76, 77], "0010": 69, "001191470": 70, "00119147fjoi": 70, "00120351": 72, "0012035118415951729": 72, "001233210": 70, "00123321fanger": 70, "00133": 77, "00133base": 77, "001564880": 70, "00156488fsurpris": 70, "001649440": 70, "00164944ffear": 70, "001936230": 70, "00193623ffear": 70, "001a": 70, "001be": 70, "001can": 70, "001damn": 70, "001feel": 70, "001former": 77, "001from": 70, "001go": 70, "001i": [69, 70], "001just": 70, "001lp": 77, "001scientists0": 76, "001so": 70, "001t": 70, "001to": 70, "001what": 69, "001who": 70, "001will": 38, "001wrong0": 70, "002": [38, 63, 68, 69, 70, 73, 74, 76, 77], "002046010": 69, "00204601fmy": 69, "002076040": 70, "00207604flove": 70, "00221878": 72, "002218781039118767": 72, "002277240": 70, "00227724fsad": 70, "00234993e": 33, "00237288e": 33, "0025": 68, "0025base": 68, "0026": 37, "002816": 64, "002a": 70, "002and": [69, 70, 73], "002around": 70, "002awak": 70, "002awake0": 70, "002be": 70, "002from": 70, "002grab": 70, "002i": 70, "002in": 68, "002just": 70, "002make": 38, "002on": 69, "002post": 70, "002tabl": 69, "002the": 69, "002to": 70, "002unless": 38, "002who": 70, "003": [38, 68, 69, 70, 73, 74, 76, 77], "003481960": 74, "00348196fwale": 74, "00372148e": 33, "003and": 70, "003around": 70, "003be": 70, "003can": 70, "003cat": 69, "003damn": [70, 73], "003from": 70, "003go": 70, "003grow": 38, "003i": 70, "003im": 70, "003it": 38, "003my": 69, "003post": 70, "003saw": 69, "003so": 70, "003the": 69, "003to": 70, "003who": 70, "004": [15, 38, 68, 69, 70, 74, 76, 77], "0040": 69, "00409007e": 33, "00415988": 8, "0046": 37, "0049": 68, "0049f": 68, "004and": 70, "004around": 70, "004can": 70, "004damn": 70, "004didn0": 70, "004feel": 70, "004from": 70, "004i": 70, "004just": 70, "004minut": 70, "004so": 70, "004someon": 70, "004the": 69, "004truli": 15, "004what": 69, "004who": 70, "005": [38, 39, 68, 69, 70, 73, 74, 76, 77], "0051": 76, "0051base": 76, "0056": 68, "0056base": 68, "00597": 74, "00597f": 74, "005a": 70, "005around": 70, "005awak": 70, "005be": 70, "005can": 70, "005come": 38, "005damn": 70, "005feel": 70, "005film": 38, "005from": 70, "005i": [69, 70, 73], "005i0": 76, "005im": 70, "005in0": 68, "005lp": 77, "005lp0": 77, "005minut": 70, "005table0": 69, "005the": 69, "005to": 70, "005ural": 77, "005with": 38, "006": [38, 68, 69, 70, 73, 74, 76, 77], "0060": 69, "0062": 15, "00675": 68, "00675f": 68, "006a": 70, "006and": 70, "006can": 70, "006er": 77, "006ern": 38, "006feel": 70, "006from": [70, 73], "006i": 70, "006issu": 38, "006just": 70, "006on": 69, "006so": [38, 70], "006someon": 70, "006to": 70, "006wrong0": 70, "007": [38, 68, 69, 70, 73, 74, 77], "0071": 68, "00711962e": 33, "0071base": 68, "0072": 77, "00732926e": 33, "0075643062591552734": 65, "00760876e": 33, "00797": 74, "00797base": 74, "007and": 73, "007around": 70, "007feel": 70, "007i": [69, 70, 73], "007im": 70, "007import": 38, "007lp0": 77, "007on": 69, "007one": 38, "007t": 70, "008": [38, 68, 69, 70, 74, 77], "0081": 68, "0081base": 68, "00892007e": 33, "008and": 69, "008i": 70, "008in0": 68, "008just": 70, "008my": 69, "008new": 38, "008on": 69, "008post": 70, "008s1": 77, "008someon": 70, "008t": 70, "009": [38, 68, 69, 70, 74, 76, 77], "0090": 15, "00914447e": 33, "00956938": 75, "00978305e": 33, "009didn0": 70, "009i": 70, "009just": 70, "009mani": 38, "009minut": 70, "009my": 69, "009post": 70, "009someon": 70, "009time": 38, "009who": 70, "009wrong0": 70, "01": [15, 16, 19, 23, 24, 33, 37, 38, 44, 47, 51, 55, 56, 57, 58, 59, 60, 65, 66, 68, 69, 70, 73, 74, 76, 77, 139], "010": [32, 69, 70, 77], "01004643": 65, "0105": 51, "0107": 71, "01079906": 8, "010921": 77, "01092fred": 77, "011": [15, 68, 69, 70, 73, 74, 76, 77], "011025": 64, "011121": 74, "01112fbe": 74, "0115": 38, "01153": 38, "0117": 71, "0119": 71, "011care": 70, "011er": 77, "011i": [69, 73], "011i0": 76, "011im": 73, "011saw": 69, "011so": 70, "011someon": 70, "011the": 69, "011to": 73, "012": [15, 68, 69, 70, 73, 74, 76, 77], "01224640e": 33, "01256774e": 33, "012i": 76, "012im": 70, "012orns1": 68, "012table0": 69, "012who": 73, "013": [15, 38, 56, 68, 69, 70, 73, 74, 76, 77], "01316288e": 33, "013271975120564434": 59, "01329768e": 33, "01343765e": 33, "013a": 38, "013grab": 70, "013hopeless": 73, "013i": 69, "013i0": 76, "013im": 73, "013orns1": 68, "013tabl": 69, "013the": 69, "013todai": 69, "014": [68, 69, 70, 74, 76, 77], "014022": 77, "01402fmod\u00e8l": 77, "01442929e": 33, "01488891e": 33, "014care": 70, "014didn": 70, "014im": 70, "014in0": 68, "014lp": 77, "014the": 69, "015": [38, 39, 68, 69, 70, 73, 74, 76, 77], "0150": 15, "01511": 74, "01511base": 74, "01521367e": 33, "01528255e": 33, "01543409e": 33, "0156": 71, "01562196": 8, "015damn": 70, "015e": 56, "015feel": 38, "015from": [70, 73], "015i": 70, "015im": 70, "015of": 38, "015saw": 69, "015tabl": 69, "015when": 69, "016": [38, 68, 69, 70, 73, 74, 76, 77], "01639348": 8, "01641439e": 33, "01686": 69, "01686fmy": 69, "01693309e": 33, "016a": [38, 70], "016from": 70, "016i": [38, 69], "016minut": 70, "016s0": 77, "016scientists0": 76, "016so": 70, "016to": [70, 73], "017": [15, 38, 68, 69, 70, 73, 74, 77], "0170": 15, "0172": [68, 71], "0172base": 68, "0173": 68, "0173base": 68, "017563": 77, "01756fnaux": 77, "017and": 70, "017around": 70, "017dure": 38, "017feel": 70, "017from": 73, "017grab": 70, "017lp": 77, "017minut": 70, "017my": 69, "017post": 70, "017so": 70, "017wander0": 38, "017when": 69, "018": [38, 68, 69, 74, 76, 77], "018552": 74, "01855fto": 74, "01898695e": 33, "018better": 38, "018former": 77, "018on": 69, "018orns1": 68, "018table0": 69, "019": [38, 68, 69, 70, 73, 74, 76, 77], "01953614e": 33, "019551": 77, "01955fse": 77, "019around": 73, "019avoid": 38, "019awak": 70, "019br": 38, "019experi": 38, "019feel": 70, "019futur": 38, "019hopeless": 70, "019i": [70, 73], "019might": 38, "019mind": 38, "019my": 69, "019on": 69, "019one": 38, "019s0": 77, "019someon": 70, "019tabl": 69, "019when": 69, "01a": 70, "01and": 69, "01be": 73, "01in0": 68, "01my": 69, "01one": 38, "01so": 70, "01t": 70, "01when": 69, "02": [23, 24, 26, 33, 38, 51, 56, 58, 59, 68, 69, 70, 74, 75, 76, 77], "020": [15, 69, 70], "0200": 70, "02046807e": 33, "02051": 68, "02051f": 68, "021": [38, 68, 69, 70, 74, 76, 77], "0210": [69, 70], "02113234e": 33, "021care": 70, "021co0": 38, "021feel": 70, "021i": 69, "021lp": 77, "021lp2": 77, "021t": 70, "021the": 69, "022": [15, 38, 68, 69, 70, 74, 77], "022292": 38, "02288918e": 33, "0229": 53, "022feel": 70, "022in0": 68, "022just": 70, "022my": 69, "022one": 38, "022the": 69, "023": [38, 68, 69, 70, 74, 76, 77], "0230": 15, "02344483": 8, "02374431e": 33, "023br": 38, "023didn": 70, "023i": [69, 70], "023it": 38, "023my": 69, "023on": 69, "023orns0": 68, "023post": 70, "023s0": 77, "023thru": 38, "023window": 38, "024": [15, 38, 68, 69, 70, 74, 76, 77], "02462077e": 33, "02488227e": 33, "024i": [69, 70], "024in0": 68, "024wrong": 70, "025": [68, 69, 70, 74, 77], "025131": 77, "02513fpour": 77, "02517796e": 33, "02528": 68, "02528f": 68, "02530529e": 33, "0254638": 8, "02564897": 8, "02591919e": 33, "025grab": 70, "025hope": 70, "025i": 69, "025in": 68, "025minut": 70, "025tabl": 69, "026": [15, 38, 68, 69, 70, 73, 74, 76, 77], "02604030": 77, "0260403fde": 77, "0262": 15, "026388": 47, "02646": 76, "02646fnot": 76, "02653412": 50, "026far": 15, "026got": 69, "026i": 69, "026lp": 77, "026on": 69, "026tabl": 69, "026thi": 38, "026to": [70, 73], "026todai": 69, "026viewer": 38, "026when": 69, "027": [38, 68, 69, 70, 74, 76, 77], "02737399e": 33, "027and": 69, "027awak": 70, "027er": 77, "027i": 69, "027lp": 77, "027on": 69, "027saw": 69, "027tabl": 69, "027the": 69, "027thi": 38, "027when": 69, "027wrong": 70, "028": [38, 68, 69, 70, 73, 74, 76, 77], "0283": 71, "02898469e": 33, "028awake0": 70, "028br": 38, "028didn0": 70, "028i": 69, "028my": 69, "028onli": 38, "028orns0": 68, "028the": 38, "028to": 73, "028type": 38, "029": [38, 68, 69, 70, 73, 74, 76, 77], "02930160e": 33, "02974789e": 33, "02985": 63, "02986023e": 33, "029a": [38, 73], "029care": 70, "029from": [70, 73], "029hope": 70, "029i": 69, "029in0": 68, "029to": 38, "029vi0": 38, "029while": 38, "02and": 70, "02becaus": 38, "02br": 38, "02feel": 70, "02grab": 70, "02i": 70, "02my": 69, "02tabl": 69, "02the": 69, "02ural0": 77, "03": [11, 15, 18, 23, 24, 26, 33, 38, 47, 56, 58, 68, 69, 70, 74, 75, 76, 77], "030": 70, "0300": 70, "030e": 56, "031": [38, 68, 69, 70, 73, 74, 76, 77], "0310": 15, "0312": 71, "031and": 70, "031at": 38, "031didnt": 73, "031former": 77, "031i0": 76, "031out": 38, "031so": 38, "031wrong": 73, "032": [38, 68, 69, 70, 74, 76, 77], "0320": 75, "03210": 69, "03218982e": 33, "03254220e": 33, "03291946e": 33, "03292": 69, "03292base": 69, "0329e": 56, "032care": 70, "032home": 69, "033": [15, 68, 69, 70, 73, 74, 77], "0330": 15, "03323497e": 33, "03358708e": 33, "03395638e": 33, "033from": 73, "033i": 69, "033ural": 77, "034": [15, 38, 68, 69, 73, 74, 77], "034253": 74, "03425f": 74, "034an": 38, "034around": 73, "034lp": 77, "034what": 69, "034when": 69, "035": [68, 69, 70, 73, 74, 76, 77], "03510": 77, "035from": 73, "035lp": 77, "035saw": 69, "035table0": 69, "035when": 69, "036": [15, 68, 69, 70, 73, 74, 76, 77], "0360": 15, "03607": 69, "03607base": 69, "0362201": 72, "036341": 74, "03634fuse": 74, "03641539e": 33, "03679446e": 33, "03692": 74, "03692fstar": 74, "036and": 69, "036feel": 70, "036from": 73, "036i": 76, "036saw": 69, "036ural1": 77, "036when": 69, "037": [15, 38, 68, 69, 70, 74, 77], "03732842e": 33, "03734176": 8, "03735617e": 33, "03747282e": 33, "03770143e": 33, "037from": 70, "037gent": 38, "037i": 70, "037orn": 68, "037tabl": 69, "037to": 70, "038": [38, 68, 69, 70, 73, 74, 75, 76, 77], "0380": 15, "03847982e": 33, "03871483e": 33, "038br": 38, "038film": 38, "038greedi": 70, "038hope": 70, "038i": 73, "038im": 70, "038my": 69, "038so": 73, "038the": 69, "039": [68, 69, 70, 73, 74, 77], "03913461e": 33, "03922932e": 33, "039former": 77, "039hope": 73, "039so": 70, "039the": 69, "03and": 69, "03i": 69, "03in": 38, "03lp": 77, "03my": 69, "03tree": 38, "04": [15, 23, 24, 32, 33, 38, 51, 52, 56, 58, 68, 70, 73, 74, 76, 77], "040": 70, "0400": 70, "04002657": 65, "04051956e": 33, "04053": 38, "04073711e": 33, "04092226e": 33, "041": [38, 68, 69, 73, 74, 76, 77], "04127292e": 33, "041i": [69, 73], "041on": 69, "041one": 38, "041orns0": 68, "041story0": 38, "041the": 69, "041ural": 77, "042": [38, 68, 69, 70, 74, 76, 77], "04213725e": 33, "04235218e": 33, "0424": 51, "04254432e": 33, "042641": 51, "04275789e": 33, "042cat": 69, "042feel": 70, "042in": 68, "042tabl": 69, "042when": 69, "042wrong0": 70, "043": [38, 68, 69, 74, 76, 77], "0436": 71, "04366243e": 33, "04375": 68, "04375f": 68, "043cat": 69, "043tabl": 69, "043when": 69, "043with": 38, "044": [38, 68, 69, 74, 76, 77], "044041": 74, "04404base": 74, "04407": 74, "04407base": 74, "04418854e": 33, "0442": 36, "04479627e": 33, "044come": 38, "044i0": 76, "044in0": 68, "044on": 69, "044the": 69, "045": [38, 68, 69, 70, 74, 77], "04526993": 65, "04552180": 77, "0455218fde": 77, "04562007e": 33, "045feel": 70, "045hope": 70, "045in0": 68, "045my": 69, "045on": 38, "046": [15, 68, 69, 70, 73, 74, 76, 77], "04698156e": 33, "046er": 77, "046i": [69, 73], "046in0": 68, "046my": 69, "046so": 73, "047": [38, 68, 69, 70, 74, 76, 77], "047078389674425125": 32, "04711056e": 33, "04739233e": 33, "04744712e": 33, "04755992e": 33, "047836": 64, "04788414e": 33, "047abl": 38, "047damn": 70, "047i": 69, "047ural0": 77, "048": [56, 68, 69, 73, 74, 76, 77], "04825070": 77, "0482507fproblema": 77, "04826234e": 33, "048301": 64, "04859": 76, "04859base": 76, "04882440e": 33, "048833": 47, "048awak": 73, "048ers0": 77, "048i": 76, "048on": 69, "048table0": 69, "048ural0": 77, "048when": 69, "049": [38, 68, 69, 70, 73, 74, 77], "0492": 32, "04941": 76, "04941base": 76, "049909": 64, "049br": 38, "049care": 70, "049er": 77, "049from": 70, "049hopeless": 70, "049i": [69, 73], "049post": 73, "049table0": 69, "049the": 69, "049ural0": 77, "04awai": 38, "04ers0": 77, "04i": 70, "04i0": 76, "04post": 73, "05": [11, 23, 24, 27, 33, 37, 38, 39, 40, 52, 54, 55, 56, 57, 68, 69, 70, 74, 76, 77, 130], "050": 70, "050018": 52, "050049": 52, "0500e": 56, "05033": 77, "05033base": 77, "05066081e": 33, "051": [15, 38, 68, 69, 70, 73, 74, 77], "05109788e": 33, "051former0": 77, "051greedi": 73, "051i": 70, "051on": 69, "051saw": 69, "051when": 69, "052": [68, 69, 70, 74, 77], "05207": 68, "05207f": 68, "0524": 68, "0524base": 68, "052awak": 70, "052the": 69, "052to": 70, "053": [68, 69, 70, 73, 74, 76, 77], "0531241": 72, "0533118387982904e": 52, "05352684e": 33, "053damn": 70, "053in": 68, "053on": 69, "053saw": 69, "053so": 73, "053to": 73, "054": [38, 68, 69, 70, 74, 76, 77], "05413511e": 33, "05419": 68, "05419f": 68, "05499045e": 33, "054disc": 38, "054i": [69, 70], "054in0": 68, "054the": 69, "054up": 38, "055": [38, 68, 69, 70, 74, 76, 77], "0550": 15, "05501686e": 33, "0554": 59, "05571511e": 33, "055former0": 77, "055i": 70, "055in0": 68, "055it": 38, "055what": 69, "056": [38, 68, 69, 73, 74, 76, 77], "05647219e": 33, "05675921e": 33, "056be": 73, "056i": 69, "056i0": 76, "056in0": 68, "056one0": 38, "056what": 69, "057": [38, 68, 69, 70, 73, 74, 76, 77], "0570": 15, "05710324": 75, "0572": 32, "057615": 76, "05761base": 76, "05781": 68, "05781f": 68, "057a": 38, "057and": 73, "057greedi": 70, "057saw": 69, "057tabl": 69, "058": [15, 68, 69, 74, 76, 77], "05816713e": 33, "058er": 77, "058in": 68, "058my": 69, "058on": 69, "059": [15, 68, 69, 70, 74, 76, 77], "05914063e": 33, "0594": 68, "0594base": 68, "059and": 70, "059i0": 76, "059ural0": 77, "059when": 69, "05ers0": 77, "05from": 70, "05i": [69, 70], "05in0": 68, "05the": 69, "06": [24, 33, 38, 48, 51, 52, 68, 70, 73, 74, 76, 77], "060": 70, "06038": 76, "06038f": 76, "06074947e": 33, "061": [38, 68, 69, 70, 73, 74, 76, 77], "06132834e": 33, "06195104e": 33, "061a": 70, "061damn": 70, "061do": 38, "061it": 38, "061lp": 77, "061to": 73, "061todai": 69, "061when": 69, "062": [68, 69, 70, 74, 76, 77], "06251745e": 33, "0626": 51, "062e": 56, "062feel": 70, "062table0": 69, "063": [38, 68, 69, 70, 74, 76, 77], "0635": 36, "063doe": 38, "063greedi": 70, "063home": 69, "063i": 69, "063interest": 38, "063the": 69, "064": [15, 38, 68, 69, 73, 74, 76, 77], "06455775e": 33, "06477435e": 33, "06487481e": 33, "064a": 73, "064former": 77, "064i0": 76, "064motiv": 38, "064my": 69, "064post": 73, "064todai": 69, "064uou": 38, "065": [68, 69, 74, 76, 77], "0652": 38, "0652f": 38, "065i": 69, "065i0": 76, "065lp": 77, "065my": 69, "065on": 69, "066": [15, 38, 56, 68, 69, 73, 74, 77], "06600019e": 33, "066532": 77, "06653fprobl\u00e8m": 77, "066around": 73, "066e": 56, "066in": 68, "066on": 69, "066tabl": 69, "067": [38, 68, 69, 70, 74, 76, 77], "0670": 15, "067for": 38, "067in0": 68, "067saw": 69, "067tabl": 69, "067to": 70, "067when": 69, "068": [38, 68, 69, 73, 74, 76, 77], "06802375e": 33, "068just": 73, "068might": 38, "068saw": 69, "068to": 73, "069": [68, 69, 73, 74, 76, 77], "069569": 64, "06988329e": 33, "069go": 73, "069i0": 76, "069in": 68, "069my": 69, "069on": 69, "06from": 73, "06go": 73, "06i0": 76, "06minut": 70, "07": [24, 47, 51, 52, 68, 70, 73, 74, 76, 77], "070": 70, "071": [68, 69, 70, 73, 74, 76, 77], "07119440e": 33, "071be": 73, "071i": 69, "071lp": 77, "071orns0": 68, "072": [68, 69, 73, 74, 76, 77], "07296862": 49, "072got": 69, "072minut": 73, "072my": 69, "073": [15, 68, 69, 70, 73, 74, 77], "07320263e": 33, "0733": 71, "07354": 68, "07354f": 68, "0735e": 56, "07366790e": 33, "073hopeless": 70, "073i": [69, 73], "073on": 69, "074": [68, 69, 74, 76, 77], "0740": 15, "0745": 76, "0745fthei": 76, "074ers0": 77, "074my": 69, "075": [68, 69, 70, 74, 76, 77], "0750": 15, "07513968e": 33, "0755": 71, "075i": 69, "075when": 69, "076": [68, 69, 70, 74, 76, 77], "0762": 68, "0762f": 68, "07665410e": 33, "076got": 69, "076humili": 70, "076my": 69, "076t": 70, "077": [68, 69, 73, 74, 76, 77], "07740611e": 33, "077from": 73, "077in0": 68, "077todai": 69, "078": [38, 68, 69, 70, 74, 76, 77], "0780": 15, "078056": 64, "07817706e": 33, "07819144": 65, "0788": 59, "0789": 32, "078frog": 69, "078i": 70, "078i0": 76, "078in": 68, "078my": 69, "078on": 69, "078stare": 38, "079": [68, 69, 70, 74, 76, 77], "0790": 71, "079i": 76, "079saw": 69, "07base": 68, "07damn": 73, "07feel": 70, "07former": 77, "07grab": 70, "07i": 76, "07in0": 68, "07minut": [70, 73], "08": [24, 39, 68, 70, 74, 76, 77], "080": 70, "08011079e": 33, "08042186e": 33, "08059035e": 33, "081": [38, 68, 69, 73, 74, 76, 77], "0810": 15, "081119": 64, "0812186": 74, "0812186fsai": 74, "08137": 68, "08137f": 68, "081former0": 77, "081just": 73, "081my": 69, "081so": 73, "081spend": 38, "081table0": 69, "081the": 38, "082": [38, 68, 69, 73, 74, 76, 77], "0820": 69, "08251": [70, 73], "08251fsad": [70, 73], "08274": 76, "08274fthei": 76, "082go": 73, "082got": 69, "082home": 69, "083": [15, 68, 69, 70, 74, 77], "08359178e": 33, "083and": 70, "083home": 69, "083my": 69, "083on": 69, "083veri": 15, "084": [68, 69, 70, 74, 76, 77], "0845": 59, "084care": 70, "084i": 69, "084in": 68, "084orns0": 68, "085": [15, 38, 68, 69, 70, 73, 74, 76, 77], "08507685e": 33, "08534540e": 33, "0857": 32, "08589311e": 33, "08597590": 70, "0859759base": 70, "085and": 69, "085im": 73, "085on": 69, "085post": 70, "085to": 70, "086": [15, 69, 70, 74, 77], "08667": 74, "08667fgareth": 74, "0867": 71, "0867270610725879": 71, "086and": 70, "086frog": 69, "087": [15, 68, 69, 73, 74, 76, 77], "08729248e": 33, "08750509e": 33, "08776470": 70, "0877647base": 70, "087and": 69, "087can": 73, "087i": 69, "087who": 73, "088": [38, 68, 69, 70, 73, 74, 76, 77], "0880": 15, "088awak": 73, "088if": 38, "088my": 69, "088orns0": 68, "088to": 70, "089": [69, 74, 76, 77], "089032": 64, "08946": 68, "08946f": 68, "08985603e": 33, "089former": 77, "089i0": 76, "089saw": 69, "089when": 69, "08a": 70, "08former0": 77, "08hopeless": 70, "08humili": 70, "08in": 68, "09": [23, 24, 28, 38, 51, 68, 69, 73, 74, 77], "090": 70, "09005": 74, "09005base": 74, "09011": 70, "09011base": 70, "090156": 64, "0902277": 77, "0902277fn": 77, "091": [38, 68, 69, 74, 77], "09178177e": 33, "091home": 69, "091tabl": 69, "092": [68, 69, 70, 73, 74, 77], "09234373e": 33, "09251858e": 33, "09289220e": 33, "092didnt": 73, "092er": 77, "092feel": 70, "092from": 70, "092grab": 73, "092i": 69, "093": [15, 38, 68, 69, 70, 73, 74, 76, 77], "0930": 15, "09326": 69, "09326base": 69, "09347078e": 33, "093555": 47, "093i": [69, 70], "093minut": 73, "093rt": 38, "093the": 69, "094": [15, 56, 68, 69, 73, 74, 76, 77], "094332": 77, "09433fe": 77, "09486": 68, "09486f": 68, "094985": 64, "094go": 73, "094home": 69, "094i": 76, "094in0": 68, "094my": 69, "095": [38, 68, 69, 74, 76, 77], "09501": 76, "09501f": 76, "09535496e": 33, "0955e": 56, "09580781e": 33, "09588052": 65, "09599710": 70, "0959971base": 70, "095er": 77, "095i": 69, "095on": 69, "095touch": 38, "095when": 69, "096": [68, 69, 74, 77], "09619": 74, "09619base": 74, "09638": 68, "09638f": 68, "09660351e": 33, "096frog": 69, "096my": 69, "096orns1": 68, "097": [38, 68, 69, 70, 74, 77], "09766687e": 33, "097greedi": 70, "097hope": 70, "097my": 69, "097orn": 68, "097perspect": 38, "098": [15, 68, 69, 70, 73, 74, 76, 77], "09853136e": 33, "0986": 59, "098didn0": 70, "098i": 69, "098on": 69, "098saw": 69, "098wrong": 73, "099": [68, 69, 70, 74, 76, 77], "0990": [15, 69], "09970924e": 33, "09985948e": 33, "099minut": 70, "09i": 69, "09in0": 68, "09orns0": 68, "09someon": 73, "09the": 69, "09ural": 77, "0a": 73, "0and": [70, 73], "0b7fndx_jaqhtbvyzourmddnhsgm": 27, "0cuadro7": 15, "0cuatro": 15, "0damn": 70, "0entail": 75, "0este1": 15, "0f": 37, "0from": 70, "0go": 70, "0hai": 15, "0hermana": 15, "0hermano": 15, "0i": [69, 70, 73], "0madr": 15, "0mb": 47, "0mi": 15, "0mi0": 15, "0minut": 70, "0neutral0": 75, "0orns0": 68, "0padr": 15, "0personas0": 15, "0saw": 69, "0so": 70, "0th": [15, 72, 75], "0to": 70, "0x13fe19db0": 53, "0x13ff33220": 53, "0x14037a080": 53, "0x2b1bf5beb30": 51, "0x636e08da0": 36, "0x7f08e9a7e490": 47, "0y0": 15, "1": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 84, 85, 86, 87, 89, 90, 91, 96, 100, 101, 116, 119, 127, 128, 129, 137, 138, 139, 140], "10": [8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28, 29, 32, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 86, 89, 90, 116, 119, 124, 126, 127, 132, 141, 155], "100": [4, 5, 6, 7, 8, 9, 11, 12, 16, 19, 21, 23, 24, 25, 28, 29, 30, 32, 33, 37, 38, 39, 40, 45, 46, 47, 48, 50, 51, 54, 55, 57, 60, 62, 66, 67, 68, 69, 70, 71, 75, 80, 81, 84, 91, 102, 103, 116, 119, 137, 146, 153], "1000": [11, 12, 14, 20, 28, 29, 33, 38, 44, 45, 47, 52, 54, 55, 59, 63, 64, 65, 66, 80, 84, 87, 91, 96, 100, 116, 119], "10000": [11, 28, 32, 37, 38, 39, 40, 49, 54, 59, 63, 64], "10009874e": 33, "1001it": [38, 44], "10074": 69, "10074base": 69, "100base": 69, "100it": 48, "100k": 95, "101": [11, 15, 26, 43, 68, 69, 73, 74, 76, 77], "1010": 77, "10100": [11, 77], "10101": 77, "10102": 77, "1012": [69, 74], "10120": 69, "1015": 99, "1016": 15, "10187": 69, "10187base": 69, "1019": 55, "101it": 4, "101m": 51, "101minut": 73, "101so": 73, "102": [15, 68, 69, 70, 73, 74, 77], "10206723e": 33, "1021": 74, "10250810e": 33, "10258": 73, "102feel": 73, "102got": 69, "102grab": 70, "102in0": 68, "102post": 73, "103": [37, 68, 69, 70, 74, 76, 77], "10329": 56, "1034": 74, "1034base": 74, "10355": 68, "10355f": 68, "10379575e": 33, "103a": 70, "103er": 77, "103i": 69, "103lp": 77, "103ural6": 77, "104": [68, 69, 70, 73, 74, 76, 77], "10409739e": 33, "10423168e": 33, "10456323": 8, "1046": 69, "1046fand": 69, "1048": 77, "1048base": 77, "104feel": 73, "105": [15, 68, 69, 70, 74, 77], "10502650e": 33, "1052": 15, "1057": 71, "105former0": 77, "105frog": 69, "105humili": 70, "106": [15, 68, 69, 73, 74, 76, 77], "1060": 15, "10661949e": 33, "1067": 51, "1067140": 70, "106714base": 70, "10692402e": 33, "106and": 69, "106be": 73, "106er": 77, "106got": 69, "106in": 68, "106s0": 77, "106so": 73, "107": [68, 69, 74, 76, 77], "10731193e": 33, "107er": 77, "107ers0": 77, "107former": 77, "107the": 69, "108": [68, 69, 71, 73, 74, 77], "10804399e": 33, "10857523": 72, "1085756": 72, "108575f": 72, "10857607": 72, "1088": 27, "10896956e": 33, "108around": 73, "108frog": 69, "108i": 69, "108on": 69, "108orns0": 68, "108saw": 69, "108the": 69, "108who": 73, "109": [68, 69, 70, 71, 73, 74, 76, 77], "1090": 69, "10979": 76, "10979base": 76, "109feel": 70, "109grab": 73, "109home": 69, "109minut": 73, "109orns0": 68, "109t": 70, "109todai": 69, "10but": 72, "10m": 51, "10me": 15, "10mutual": 15, "10young": 15, "11": [3, 9, 11, 14, 15, 16, 18, 19, 20, 24, 25, 26, 28, 32, 33, 38, 39, 40, 43, 44, 45, 47, 50, 51, 52, 53, 54, 55, 56, 59, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "110": [26, 70, 71], "1100": 55, "11004211e": 33, "1100620": 70, "110062base": 70, "11025714e": 33, "1109": 68, "1109base": 68, "111": [38, 68, 69, 70, 71, 73, 74, 76], "11137240e": 33, "111and": 73, "111damn": 70, "111i": 69, "111i0": 76, "111table0": 69, "111without": 38, "112": [68, 69, 70, 73, 74, 76, 77], "112515": 64, "112didn0": 70, "112in0": 68, "112m": 51, "112to": 73, "113": [68, 69, 71, 74, 76, 77], "11344976": 50, "114": [68, 69, 71, 74, 77], "11448": 74, "11448base": 74, "114ers1": 77, "114on": 69, "114tabl": 69, "115": [15, 26, 68, 69, 70, 74, 76, 77], "1150": 15, "11527169e": 58, "11527711e": 58, "11583337e": 33, "11593704e": 33, "115and": 70, "115i": 70, "115in0": 68, "115on": 69, "115orns0": 68, "115ural0": 77, "116": [15, 68, 69, 70, 74, 76, 77], "1160": 69, "11620267e": 33, "11629296": 75, "1165": 71, "11682360e": 33, "116and": 69, "116on": 69, "116post": 70, "117": [68, 69, 70, 74, 76, 77], "11715": 74, "11715base": 74, "11732305e": 33, "11764705882352941": 55, "117and": 70, "117ers0": 77, "117i": [69, 76], "117the": 69, "118": [64, 68, 69, 70, 73, 74, 77], "1180": 15, "11828982e": 33, "11853424e": 33, "1187": 51, "1189": 64, "118i": [69, 73], "118in0": 68, "118the": 69, "118wrong0": 70, "119": [15, 64, 68, 69, 70, 74, 76, 77], "1190": 15, "1196": 32, "11966879e": 33, "119care": 70, "119in0": 68, "119ural0": 77, "11a": 73, "11er": 77, "11feel": 70, "11it": [23, 38, 51], "11my": 69, "11orns0": 68, "11succeed": 74, "12": [4, 9, 11, 12, 14, 15, 16, 19, 20, 22, 24, 25, 26, 27, 28, 32, 38, 39, 40, 44, 45, 47, 48, 51, 52, 53, 55, 56, 59, 63, 64, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79], "120": [46, 70, 74], "1200": 55, "1204": 77, "120521": 74, "12052fshould": 74, "121": [15, 68, 69, 70, 71, 73, 74, 76, 77], "12123": 68, "12123f": 68, "121go": 73, "121orns0": 68, "121post": 70, "121s0": 77, "122": [15, 68, 69, 70, 74, 76, 77], "12231665e": 33, "12249615": 75, "1224989": 8, "12250843e": 33, "122frog": 69, "122orn": 68, "122when": 69, "123": [53, 68, 69, 74, 76, 77], "1230": [15, 74], "1230250": 70, "123025base": 70, "1234": 77, "12383519e": 33, "124": [52, 69, 70, 74, 76], "12411294e": 33, "12453": 68, "12453f": 68, "12476": 70, "12476base": 70, "124my": 69, "124on": 69, "124wrong": 70, "125": [52, 67, 68, 69, 73, 74, 76, 77], "12529": 38, "12538948e": 33, "12542": 68, "12542f": 68, "12571": 68, "12571f": 68, "125841": 74, "12584fchairman": 74, "125frog": 69, "125i": 73, "125what": 69, "126": [47, 68, 69, 70, 73, 74, 76, 77], "12641185e": 33, "12642660e": 33, "126590": 77, "12659fancien": 77, "126can": 73, "126damn": 70, "126i": 76, "126i0": 76, "126my": 69, "126post": 70, "126tabl": 69, "126the": 69, "127": [69, 71, 74, 77], "12760302e": 33, "12773397e": 33, "128": [15, 24, 28, 29, 32, 33, 36, 37, 56, 64, 68, 69, 71, 73, 74, 76, 77, 122, 124], "1280": 15, "12800": 37, "12801300e": 33, "128328": 15, "128328f": 15, "1285": 15, "12886608e": 33, "12888": 69, "12888fwhat": 69, "128damn": 73, "128orns1": 68, "128when": 69, "129": [68, 69, 74, 76, 77], "1290": 69, "1297": 51, "129lp": 77, "12it": 15, "12m": 51, "13": [8, 11, 14, 15, 16, 19, 24, 25, 26, 28, 32, 34, 35, 38, 39, 40, 45, 47, 51, 52, 53, 55, 56, 59, 63, 64, 68, 69, 70, 71, 72, 74, 75, 76, 77], "130": [46, 70], "1300": 55, "1300e": 56, "13030304e": 33, "130671": 77, "13067fchoix": 77, "131": [15, 68, 69, 70, 73, 74, 76, 77], "1310": [59, 69], "1316720": 70, "131672base": 70, "13187120e": 33, "131a": 70, "131be": 73, "131cat": 69, "131in0": 68, "132": [28, 68, 69, 74, 76, 77], "133": [68, 69, 74, 76, 77], "13316": 68, "13316f": 68, "13318184e": 33, "1332": 68, "1332base": 68, "13376061e": 33, "133in0": 68, "133my": 69, "133the": 69, "134": [38, 68, 69, 74, 76, 77], "1345": 70, "134and": 69, "134invari": 38, "134the": 69, "134ural0": 77, "135": [68, 69, 70, 74, 76, 77], "13501586e": 33, "135awak": 70, "135i0": 76, "135the": 69, "136": [32, 68, 69, 70, 71, 74, 77], "13639137e": 33, "136feel": 70, "136got": 69, "137": [38, 68, 69, 74, 77], "1370": 15, "137got": 69, "137home": 69, "137in": 68, "137my": 69, "137orns0": 68, "137saw": 69, "137sit": 38, "138": [68, 70, 74, 76, 77], "1380": 15, "13804": 68, "13804485e": 33, "13804f": 68, "13888": 68, "13888f": 68, "138didn": 70, "138i0": 76, "139": [68, 69, 74, 77], "13904": 68, "13904f": 68, "13911111111111111111110": 77, "1391134262084961": 65, "13925": 77, "13925base": 77, "1394060": 70, "139406base": 70, "1395": 59, "13967442e": 33, "139881": 69, "13988f": 69, "139i": 69, "13feel": 70, "13i0": 76, "13idol": 72, "13it": [4, 15], "13m": 51, "13so": 70, "14": [11, 14, 15, 16, 19, 24, 26, 28, 38, 40, 44, 45, 47, 48, 51, 52, 53, 55, 56, 57, 59, 63, 64, 68, 69, 70, 71, 73, 74, 75, 76, 77], "140": 70, "1400": 55, "140242": 74, "14024fin": 74, "14068719e": 33, "14081291e": 33, "141": [68, 69, 74, 76, 77], "1410": 15, "14109635e": 33, "141391": 77, "14139f": 77, "141former0": 77, "141home": 69, "141i": 69, "141saw": 69, "142": [38, 69, 73, 74, 76, 77], "14210588e": 33, "14230409e": 33, "142312": 77, "14231fen": 77, "1425870": 77, "142587fde": 77, "14276": 76, "14276fthei": 76, "14294258e": 33, "142and": 69, "142home": 69, "142im": 73, "142thi": 38, "143": [15, 68, 69, 73, 74, 77], "14379": 76, "14379flove": 76, "143a": 73, "143got": 69, "143in": 68, "143it": 15, "143lawyer": 15, "144": [68, 69, 73, 74, 76, 77], "14411": 68, "14411f": 68, "1441950": 70, "144195base": 70, "144go": 73, "144got": 69, "144i": 69, "144someon": 73, "145": [57, 68, 69, 73, 74, 76, 77], "1453": 51, "1455260": 15, "14567": 69, "1459": 77, "145918": 51, "1459base": 77, "145from": 73, "145i": 69, "145orns0": 68, "146": [68, 69, 73, 74, 76, 77], "1460": 15, "14669": 69, "14669base": 69, "146i": 73, "146saw": 69, "147": [69, 70, 73, 74, 76, 77], "14751": 38, "14751base": 38, "14761": 56, "147can": 73, "147i": 69, "147my": 69, "147on": 69, "147t": 70, "148": [68, 69, 70, 74, 76, 77], "14801470e": 33, "14820994e": 33, "1483": 32, "14865397e": 33, "14866011e": 33, "14868": 74, "14868base": 74, "14875911e": 33, "14876524e": 33, "148er": 77, "148got": 69, "148i": 70, "148i0": 76, "149": [68, 69, 70, 73, 74, 76, 77], "1491": 15, "14911": 68, "14911f": 68, "149home": 69, "149hope": 70, "149i": [69, 73], "149i0": 76, "14frog": 69, "14hopeless": 73, "14i": [69, 76], "14m": 51, "14my": 15, "14t": 70, "14table0": 69, "14todai": 69, "15": [11, 14, 15, 16, 18, 19, 24, 26, 28, 38, 40, 45, 47, 48, 51, 52, 53, 55, 56, 59, 63, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 81], "150": [46, 70], "1500": 55, "151": [68, 69, 70, 74, 76, 77], "1510": 38, "151in0": 68, "151saw": 69, "151t": 70, "152": [68, 69, 70, 73, 74, 77], "152000": 64, "15209": 68, "15209base": 68, "152122": 15, "152610": 70, "15261base": 70, "15265": 68, "15265f": 68, "15294117647058825": 55, "152can": 73, "152grab": 73, "152i": 69, "152im": 70, "152just": 73, "152post": 73, "152someon": 73, "153": [15, 64, 68, 69, 70, 74, 77], "15348": 68, "15348f": 68, "153got": 69, "153i": [69, 70], "153m": 74, "154": [15, 68, 74], "15418845e": 33, "154596": 47, "154in0": 68, "155": [68, 69, 74, 76, 77], "15534": 69, "15534ftodai": 69, "1557": 71, "15571762e": 33, "15577168e": 33, "15584684e": 33, "155what": 69, "156": [68, 69, 74, 76, 77], "156118": 69, "156118base": 69, "1565": 55, "15658753e": 33, "15661494e": 33, "15665382e": 33, "15690008e": 33, "156cat": 69, "156frog": 69, "156home": 69, "156tabl": 69, "156the": 69, "156ural": 77, "157": [15, 68, 69, 73, 74, 76, 77], "15740923": 65, "157and": 69, "157awak": 73, "157care": 73, "157orns0": 68, "158": [15, 68, 69, 74, 76, 77], "15805033e": 33, "15851881e": 33, "158718": 15, "158i": 69, "158saw": 69, "158take": 15, "159": [15, 68, 69, 70, 73, 74, 77], "15930704e": 33, "15937": 77, "15937base": 77, "1595": 15, "15985182e": 33, "15989812e": 33, "159926": 64, "159got": 69, "159im": 70, "159table1": 69, "159to": 73, "15be": 73, "15dragon": 74, "15m": 51, "15my": 69, "15sure": 15, "15the": 72, "16": [11, 14, 15, 16, 19, 24, 25, 27, 28, 32, 37, 38, 47, 48, 51, 52, 53, 55, 56, 59, 63, 64, 68, 69, 70, 74, 75, 76, 77, 127, 138], "160": 70, "1600": 32, "16009100e": 33, "16016": 77, "16016base": 77, "161": [68, 69, 73, 74], "161grab": 73, "162": [68, 69, 74, 76, 77], "1621": 76, "1621base": 76, "1623": 36, "16253315e": 33, "16266": 68, "16266f": 68, "16268": 76, "16268base": 76, "16277879e": 33, "162orns0": 68, "163": [68, 69, 70, 74, 76, 77], "16315282e": 33, "1633": 76, "1633fvodka": 76, "163i": 69, "163in0": 68, "164": [68, 69, 70, 74, 76, 77], "16414631e": 33, "16430230e": 33, "16448684e": 33, "16449": 69, "16449f": 69, "16452434e": 33, "1645970": 15, "1648650": 70, "164865base": 70, "164minut": 70, "164my": 69, "164tabl": 69, "164todai": 69, "165": [38, 68, 69, 74, 77], "1650": 15, "16524985e": 33, "165315base": 15, "165todai": 69, "165ural0": 77, "166": [68, 69, 74, 76, 77], "1662": 68, "1662base": 68, "166got": 69, "166i": 69, "166in0": 68, "167": [15, 68, 69, 74, 76], "1670": 69, "16778909e": 33, "16782": 68, "16782f": 68, "167todai": 69, "168": [15, 68, 69, 70, 74, 76, 77], "16879227e": 33, "16890655e": 33, "168i": 69, "168in": 68, "169": [15, 27, 68, 69, 70, 73, 74, 76, 77], "169awake0": 70, "169home": 69, "169lp0": 77, "169to": 73, "169wrong0": 70, "16frog": 69, "16i": 70, "16it": 45, "16m": 51, "16on": 69, "16saw": 69, "16tabl": 69, "17": [11, 14, 15, 16, 19, 23, 24, 29, 33, 38, 47, 51, 52, 53, 55, 59, 63, 64, 68, 69, 71, 74, 75, 77], "170": [32, 70], "17022275e": 33, "17039803e": 33, "17046312e": 33, "17050910e": 33, "17054806e": 33, "17095978e": 33, "171": [27, 32, 68, 69, 74, 76, 77], "17113445e": 33, "171193": 15, "171297base": 15, "17149972e": 33, "171732664108276": 65, "171963": 64, "171in0": 68, "171when": 69, "172": [27, 32, 68, 70, 73, 74, 76, 77], "1721570": 70, "172157base": 70, "17233": 68, "17233f": 68, "17255": 74, "17255base": 74, "17261903e": 33, "172former": 77, "172from": 73, "172orns0": 68, "173": [15, 27, 32, 69, 70, 73, 77], "1730": 15, "1738": [26, 27], "1739": [26, 27], "173a": 73, "173didn0": 70, "173i": 69, "173tabl": 69, "174": [15, 17, 32, 70, 73, 74, 76, 77], "17410037e": 33, "17424": 69, "17424base": 69, "17427": 69, "17427base": 69, "17482": 56, "174around": 73, "174greedi": 70, "175": [38, 56, 68, 69, 70, 74, 76, 77], "17521": [70, 73], "17521flove": [70, 73], "17564": 77, "17564base": 77, "175humiliated0": 70, "175no": 38, "175todai": 69, "176": [15, 68, 69, 73, 74, 76, 77], "17621040e": 33, "176617": 69, "176617base": 69, "17689230e": 33, "176and": 69, "176in0": 68, "176on": 69, "176saw": 69, "176todai": 69, "176who": 73, "177": [15, 38, 56, 68, 69, 74, 76], "177789": 15, "17787": 68, "17787base": 68, "177ani": 38, "177in0": 68, "178": [68, 69, 70, 74, 76, 77], "17800": 56, "17801314e": 33, "17837378e": 33, "178feel": 70, "178former": 77, "178m": 51, "178my": 69, "179": [15, 68, 72, 73, 74, 77], "17932164e": 33, "1796": 15, "17997164e": 58, "17997435e": 58, "179i": 73, "17it": 15, "17m": 51, "17my": 69, "17orns0": 68, "17there": 74, "17todai": 69, "18": [11, 13, 14, 15, 16, 19, 24, 26, 32, 34, 35, 38, 39, 47, 48, 51, 52, 53, 55, 59, 63, 64, 68, 69, 70, 73, 74, 75, 76, 77], "180": 62, "1800e": 56, "18088622e": 33, "181": [68, 69, 74, 77], "18146122e": 33, "18191394e": 33, "181i": 69, "181on": 69, "181table0": 69, "182": [68, 69, 73, 74, 76, 77, 79], "18201734e": 33, "18267970e": 33, "18288": 74, "18288base": 74, "182and": 69, "182awak": 73, "182awake20": 73, "182frog": 69, "183": [68, 69, 74, 76], "1831": 69, "18313493e": 33, "1831base": 69, "18322930e": 33, "18328382e": 33, "18341956e": 33, "18374873e": 33, "18398767e": 33, "183i": 69, "183in": 68, "183the": 69, "184": [68, 69, 74, 76, 77], "1840": 69, "184386base": 15, "18482581": 75, "184in0": 68, "184saw": 69, "185": [68, 69, 70, 74, 76, 77], "18510260e": 33, "18534744e": 33, "18579002e": 33, "185cat": 69, "185i": 70, "185in0": 68, "186": [68, 69, 74, 76, 77], "1860": 69, "1863130": 74, "186313fgareth": 74, "1866": 11, "186lp": 77, "186on": 69, "186ural": 77, "187": [68, 69, 70, 74, 77], "187151base": 72, "18718512e": 33, "187humili": 70, "187i": 69, "187orns0": 68, "187saw": 69, "187tabl": 69, "188": [68, 69, 70, 74, 76, 77], "18803572e": 33, "188081": 77, "18808fneuro": 77, "1882": 68, "1882base": 68, "18882686e": 33, "188cat": 69, "188former": 77, "188i": 69, "189": [68, 69, 73, 74], "1890": 75, "189im": 73, "189table0": 69, "18and": 69, "18e": 38, "18im": [70, 73], "18in0": 68, "18look": 15, "18m": 51, "18on": 69, "18todai": 69, "19": [11, 14, 19, 23, 24, 38, 45, 47, 51, 52, 55, 59, 63, 68, 74, 75], "19001100e": 33, "19067168": 75, "190753": 74, "19075fm": 74, "19096444e": 33, "191": [56, 68, 69, 74], "1910": [15, 75], "1913": 72, "19161239e": 33, "191on": 69, "192": [69, 74, 76], "1922226": 72, "19240600e": 33, "19249064e": 33, "192and": 69, "192i0": 76, "192tabl": 69, "193": [68, 69, 70, 74, 76, 77], "1930": 69, "193052": 77, "19305f": 77, "19330061e": 33, "19351": 69, "19351base": 69, "193cat": 69, "193fvodka": 76, "193i": 69, "193im": 70, "193on": 69, "194": [69, 74, 76, 77], "19483": 69, "19483fgot": 69, "194the": 69, "194todai": 69, "195": [68, 69, 74], "1950": 69, "19536": 74, "19536fnew": 74, "195the": 69, "196": [68, 69, 76, 77], "1962": 43, "19639414e": 33, "19668525e": 33, "1968": 68, "1968base": 68, "196former0": 77, "196frog": 69, "196lp": 77, "196on": 69, "196ural0": 77, "197": [68, 69, 73, 74], "1970": [15, 69], "19726609e": 33, "19742246e": 33, "197i": 73, "198": [68, 69, 74, 77, 79], "19829152e": 33, "19869197e": 33, "19893031e": 33, "199": [68, 69, 70, 74, 76, 77], "1990": [10, 12, 38, 43], "19927": 69, "19927base": 69, "19959": 69, "19959base": 69, "1996": 43, "19961730e": 33, "199humili": 70, "199i": 69, "199i0": 76, "199on": 69, "19in0": 68, "19m": 51, "19open": 72, "1_000": [52, 60], "1_125": 52, "1_250": 52, "1_375": 52, "1_500": 52, "1_625": 52, "1_750": 52, "1_875": 52, "1cat": 69, "1classic": 15, "1d": [25, 130], "1e": [45, 46, 56], "1e88e5": [55, 138], "1er": 77, "1f": 14, "1frog": 69, "1m": 51, "1osb_jldorjnzkz6xsofk1n493p3hwop0": 27, "1st": [15, 72], "1ural0": 77, "1x3": 16, "2": [3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 85, 86, 89, 90, 101, 128, 129, 133, 137, 146, 161], "20": [10, 11, 14, 16, 17, 19, 23, 24, 25, 26, 33, 37, 38, 39, 40, 45, 46, 48, 51, 52, 55, 59, 62, 63, 64, 69, 70, 72, 73, 74, 75, 76, 77, 86, 90, 102, 128, 130, 133, 138, 140], "200": [30, 31, 36, 55, 56, 85], "2000": [9, 52, 63], "20000": [54, 71], "200000": 39, "20000577e": 33, "20011197e": 33, "2002890": 70, "200289base": 70, "20048": 69, "20048ftabl": 69, "200698": 15, "201": [68, 69, 70, 74, 76, 77], "2010": 90, "2013": 74, "2014": 62, "2017": [15, 47, 80, 85], "2018": 47, "201feel": 70, "201in0": 68, "201on": 69, "201ural": 77, "202": [68, 69, 73, 74, 76, 77], "2020": [15, 84, 91], "2021": 47, "2022": 38, "2023": 48, "2024": 37, "20263958e": 33, "202i": 73, "202in0": 68, "203": [68, 69, 70, 74, 76, 77], "20313": 21, "20363343e": 33, "203feel": 70, "203in0": 68, "203s0": 77, "204": [68, 69, 70, 74, 76, 77], "2040": 69, "20401": 68, "20401f": 68, "204055base": 72, "204112": 51, "20431083e": 33, "20475224e": 33, "2048": [86, 90], "20497": 69, "20497base": 69, "204and": 69, "204i": 69, "204in": 68, "205": [68, 69, 74, 76, 77], "20527288e": 33, "20545771e": 33, "205in": 68, "205in0": 68, "205on": 69, "205todai": 69, "206": [68, 69, 73, 74, 77], "20615275e": 33, "2062": 70, "2062base": 70, "20640": 21, "206and": 69, "206just": 73, "206my": 69, "206tabl": 69, "207": [68, 69, 74, 76, 77], "2070": 69, "207and": 69, "208": [68, 69, 74, 77], "2080": 38, "20818664": 72, "20818753": 72, "20897702e": 33, "208frog": 69, "208on": 69, "209": [38, 68, 74, 77], "2091256": 72, "20924": 68, "20924f": 68, "20951": 76, "20951base": 76, "20961696e": 33, "20975601e": 33, "20979142e": 33, "20988615e": 33, "209but": 38, "20m": 51, "20th": 11, "21": [11, 14, 19, 22, 24, 26, 28, 37, 38, 45, 48, 51, 52, 63, 68, 69, 74, 75, 76, 77, 128], "210": 37, "211": [56, 69, 77], "211my": 69, "212": [68, 69, 70, 74, 76, 77], "212wrong0": 70, "213": [68, 69, 74, 77], "21334312e": 33, "21358": 74, "21358base": 74, "21371403e": 33, "21397563e": 33, "213home": 69, "213todai": 69, "214": [68, 69, 74, 77], "21487504": 65, "214cat": 69, "214on": 69, "215": [15, 68, 69, 73, 74, 76], "21500799": 75, "21555126e": 33, "215frog": 69, "215i": 73, "215on": 69, "216": [15, 68, 69, 70, 76, 77], "216656": 51, "216care": 70, "216i": 69, "217": [68, 69, 73, 74, 76], "2170": 69, "21731": 69, "21731fi": 69, "217and": 69, "217feel": 73, "217got": 69, "218": [68, 69, 73, 74, 76, 77], "2183": 68, "2183base": 68, "218and": 69, "218feel": 73, "218what": 69, "219": [68, 69, 74], "21940892e": 33, "21989758e": 33, "21992": 74, "21992fnew": 74, "219999": 37, "219and": 69, "219cat": 69, "21cat": 69, "21it": [24, 72], "21m": 51, "21st": 11, "21the": 72, "22": [11, 19, 23, 24, 25, 26, 38, 47, 51, 52, 63, 68, 69, 73, 74, 75, 76, 77], "2200e": 56, "22041956e": 33, "22045e": 74, "22073": 69, "22073fthe": 69, "221": [68, 69, 73, 74, 76], "2210": 71, "22117897e": 33, "22133445e": 33, "22153884e": 33, "221awak": 73, "221feel": 73, "221saw": 69, "221tabl": 69, "222": [15, 68, 69, 74, 77], "22222222222222222221": 74, "22262": 68, "22262f": 68, "2227780": 70, "222778base": 70, "222frog": 69, "222impress": 15, "222in0": 68, "222lp0": 77, "222table0": 69, "222todai": 69, "223": [56, 68, 69, 73, 74, 77], "2230": 69, "22340": 77, "22345": 69, "22352367e": 33, "22368413e": 33, "223damn": 73, "223from": 73, "224": [26, 28, 31, 69, 73, 74, 77, 98], "22444949e": 33, "224cat": 69, "224i": 69, "224post": 73, "225": [15, 28, 31, 63, 68, 73, 74, 76, 77], "22513816e": 33, "225someon": 73, "226": [68, 69, 77], "22663773e": 33, "226home": 69, "226my": 69, "226the": 69, "226todai": 69, "227": [68, 69, 74, 76, 77], "22775": 69, "22775f": 69, "22782": 69, "22782f": 69, "22792616e": 33, "227the": 69, "228": [68, 74, 77], "229": [28, 31, 68, 69, 76, 77], "2295": 15, "229my": 69, "229tabl": 69, "22got": 69, "22m": 51, "22who": 73, "23": [11, 19, 23, 24, 25, 37, 38, 51, 52, 63, 64, 68, 69, 74, 75, 76, 77], "2300990": 15, "2303730": 70, "230373base": 70, "231": [68, 69, 70, 73, 74, 76, 77], "23168957e": 33, "2319390": 74, "231939f3": 74, "231and": 73, "231awak": 73, "231orn": 68, "231t": 70, "231the": 69, "231to": 73, "232": [15, 68, 69, 70, 73, 74, 76], "23222424e": 33, "23224": 69, "23224fhome": 69, "2323450": 77, "232345freemplaza": 77, "23281629": 75, "232around": 73, "232im": 70, "233": [68, 69, 70, 74, 77], "2330": 75, "233feel": 70, "233my": 69, "233what": 69, "234": [68, 69, 73], "23409": 68, "23409f": 68, "23446": 76, "23446flove": 76, "23456": 73, "23460988e": 33, "234i": 69, "234so": 73, "234table0": 69, "235": [68, 69, 74], "2353": 68, "2353f": 68, "23568": 68, "23568f": 68, "235what": 69, "236": [38, 68, 69, 74, 77], "2360": 69, "23629247e": 33, "236362": 77, "23636fdevenu": 77, "23684637": 75, "236but": 38, "236cat": 69, "236former0": 77, "236table0": 69, "236when": 69, "237": [68, 69, 74, 77], "23727470e": 33, "237frog": 69, "237home": 69, "237in": 68, "237on": 69, "238": [68, 69, 70, 74, 76, 77], "23821": 68, "23821base": 68, "23862468e": 33, "23877830e": 33, "23895316e": 33, "23898253": 51, "238care": 70, "238tabl": 69, "239": [68, 69, 74, 77], "2390": 69, "239340": 77, "23934fneuro": 77, "23968381e": 33, "23969074e": 33, "23m": 51, "23the": 69, "24": [15, 18, 19, 23, 24, 26, 33, 38, 48, 51, 52, 63, 68, 69, 73, 74, 75, 76, 77], "240": 64, "2400": 59, "2401": 59, "24028": 68, "24028f": 68, "24058286e": 33, "24086940e": 33, "241": [56, 68, 69, 70, 76], "2410": 69, "241316": 64, "2414520": 77, "241452base": 77, "24183003e": 33, "241so": 70, "242": [68, 69, 73, 74, 76, 77], "24211209e": 33, "24215968e": 33, "24251": 70, "24251base": 70, "2426": 43, "24293879e": 33, "242i": 73, "242in": 68, "242just": 73, "242on": 69, "242orn": 68, "243": [68, 69, 74], "24312258e": 33, "24314654e": 33, "24343760e": 33, "243got": 69, "243i": 69, "243orns0": 68, "244": [69, 73, 77], "244grab": 73, "244m": 51, "245": [68, 69, 74, 75, 76], "24508": [70, 73], "24508ffear": [70, 73], "245i": 69, "245in0": 68, "245tabl": 69, "246": [68, 69, 70, 73, 74, 77], "24618163e": 33, "2467": 59, "24685976e": 33, "246cat": 69, "246i": 69, "246orn": 68, "246orns0": 68, "247": [68, 70, 74, 76, 77], "2472": 76, "24723987e": 33, "2472fvodka": 76, "24777": 74, "24777fkeep": 74, "24795842972228": 45, "247didn": 70, "248": [68, 70, 74, 76, 77], "24848": 76, "24848base": 76, "24879230e": 33, "248so": 70, "249": [68, 69, 74, 77], "2490": 69, "24955": 70, "24955base": 70, "249and": 69, "249on": 69, "24and": 15, "24he": 15, "24i": 69, "24m": 51, "24my": 69, "24who": 73, "25": [11, 19, 23, 24, 27, 38, 39, 44, 47, 51, 52, 62, 63, 67, 68, 69, 70, 74, 75, 77], "250": 52, "25000": 71, "2500e": 56, "25012506": 52, "25042219e": 33, "2509": 51, "251": [68, 69, 74, 76], "2510": 69, "25159859e": 33, "251603": 64, "251it": 20, "252": [68, 69, 74, 76, 77], "252i": 69, "253": [15, 68, 69, 70, 74, 76, 77], "25390972e": 33, "253awake0": 70, "253i": 69, "253on": 69, "254": [68, 69, 70, 77], "254cat": 69, "254home": 69, "255": [15, 19, 28, 31, 32, 36, 68, 69, 73, 74], "25571": 68, "25571f": 68, "255i": 73, "255in0": 68, "255the": 15, "256": [68, 69, 70, 74, 75, 77], "25600": 37, "2561e": 56, "25672": 68, "25672f": 68, "256awake0": 70, "256cat": 69, "256on": 69, "257": [68, 69, 76], "25729610e": 33, "2574": 43, "25766": 76, "25766ftheir": 76, "257frog": 69, "257in0": 68, "257m": 51, "258": [68, 70, 74, 76, 77], "25807380e": 33, "258209": 47, "258didn": 70, "258former2": 77, "259": [68, 69, 74, 77], "2590": 15, "259051": 77, "25905fle": 77, "2592131": 77, "25948922e": 33, "259my": 69, "25hope": 70, "25m": 51, "25on": 69, "25orns0": 68, "25so": 70, "25tabl": 69, "26": [11, 23, 24, 25, 27, 32, 33, 38, 44, 51, 63, 68, 69, 74, 75, 76], "26059996e": 33, "26099811e": 33, "261": [68, 70, 74, 76, 77], "26118344e": 33, "261lp": 77, "261orns0": 68, "262": [68, 69, 74], "262and": 69, "262in": 68, "263": [68, 74], "263058": 64, "26315960e": 33, "26332932e": 33, "26337171e": 33, "26347": 69, "26347base": 69, "26361": 68, "26361f": 68, "264": [68, 69, 74], "26410867e": 33, "264187": 15, "2643": 51, "26456341e": 33, "26464": 74, "26464base": 74, "264in": 68, "264orns0": 68, "264todai": 69, "265": [68, 69, 74, 76], "26528": 77, "26528base": 77, "26549304e": 33, "26562698e": 33, "265and": 69, "265i": 69, "265my": 69, "265on": 69, "265orns0": 68, "266": [68, 69, 74, 76, 77], "26673936e": 33, "26685749e": 33, "266and": 69, "266frog": 69, "266in0": 68, "267": [68, 69, 77], "268": [68, 69, 74], "2680": 69, "26815441e": 33, "26847284e": 33, "2687050": 77, "268705base": 77, "268731": 77, "26873frapid": 77, "268cat": 69, "268on": 69, "269": [15, 68, 69, 73, 74, 76], "2690": 69, "269care": 73, "269frog": 69, "269on": 69, "269the": 69, "26charact": 15, "26frog": 69, "26in0": 68, "26m": 51, "26on": 69, "26scientist": 76, "26table0": 69, "27": [8, 11, 15, 24, 38, 47, 51, 63, 68, 69, 70, 72, 74, 75], "2706647518976772": 11, "2707": 68, "2707845": 15, "2707base": 68, "271": [68, 69], "27119932e": 33, "2716290": 70, "271629base": 70, "271the": 69, "272": [15, 68, 69, 73, 74, 77], "27237683e": 33, "27278283e": 33, "27284331e": 33, "272feel": 73, "272on": [15, 69], "272ural": 77, "273": [68, 69, 74], "27316": 68, "27316113e": 33, "27316f": 68, "273home": 69, "273on": 69, "274": [68, 69, 73, 74, 77], "2743920496745268": 11, "27449345e": 33, "27485720e": 33, "274frog": 69, "274got": 69, "274i": 73, "274the": 69, "275": [15, 69, 72, 74, 76], "27522": 76, "27522f": 76, "2753": 59, "275on": 69, "276": [68, 69, 74, 76], "2760": 69, "27621043e": 33, "277": [69, 74, 76], "277144": 11, "278": [68, 70, 73], "2785044277595166": 11, "2789150": 70, "278915base": 70, "278greedi": 73, "278i": 70, "278orns1": 68, "279": [68, 69, 74, 77], "2790": 15, "27915": 68, "27915f": 68, "27928": 55, "27935": 55, "27955333e": 33, "27992": 55, "27care": 70, "27cat": 69, "27m": 51, "28": [11, 23, 24, 26, 32, 36, 38, 51, 68, 70, 75, 76, 77], "28016312e": 33, "28055816e": 33, "28060734e": 33, "28064": 55, "2809048231217079": 11, "281": [68, 69, 73], "2815730": 70, "281573base": 70, "28181": 55, "281931": 64, "28195": 76, "28195flove": 76, "281just": 73, "281minut": 73, "281tabl": 69, "282": [68, 69, 74, 76, 77], "28227451e": 33, "28257": 68, "28257base": 68, "28269999e": 33, "28279460948508833": 11, "282886": 69, "28288fcat": 69, "282and": 69, "282ers6": 77, "282former": 77, "282frog": 69, "282home": 69, "282i": 69, "282orns0": 68, "282what": 69, "283": [68, 76], "28381": 55, "283orns0": 68, "284": [68, 69, 76], "28404": 63, "28432": 68, "28432f": 68, "28446651e": 33, "284673": 64, "284and": 69, "285": [68, 69, 74, 76, 77], "28539": 69, "28539fi": 69, "28598602e": 33, "285my": 69, "286": [68, 69, 74, 77], "28678": 55, "286and": 69, "286former0": 77, "286i": 69, "286in0": 68, "286table0": 69, "287": [68, 69, 73, 77], "287tabl": 69, "287to": 73, "288": [69, 74, 76, 77], "28803": [70, 73], "28803fjoi": [70, 73], "28826": 68, "28826f": 68, "28857": 68, "28857f": 68, "28866944e": 33, "28874002e": 33, "288former": 77, "288what": 69, "289": [68, 69, 73, 74, 77], "289damn": 73, "28feel": 70, "28i": 72, "28m": 51, "29": [11, 24, 27, 38, 51, 59, 68, 69, 74, 75, 77], "291": [39, 68, 69, 74, 76], "291201": 64, "29155": 68, "29155f": 68, "2917": [70, 73], "2917fjoi": [70, 73], "291in0": 68, "291on": 69, "292": [68, 69, 74, 76, 77], "29207": 55, "29222501e": 33, "29237270e": 33, "29240400e": 33, "2925": 77, "2925base": 77, "293": [15, 68, 69, 76], "29309764e": 33, "2931": 15, "293orns0": 68, "293the": 69, "294": [68, 69, 73, 74, 76], "29403366e": 33, "294228": 73, "294228base": 73, "29439": 55, "29471": 55, "29488914": 75, "294cat": 69, "294humili": 73, "294in0": 68, "295": [68, 69, 74, 77], "2950": 69, "29511899e": 33, "29518": 68, "29518f": 68, "29525": 55, "295and": 69, "295on": 69, "296": [68, 74], "29606": 55, "29635768e": 33, "29647441e": 33, "29695": 55, "297": [68, 74, 76, 77], "29732513e": 33, "29741": 76, "29741base": 76, "29795": 38, "29796": 55, "298": [68, 69, 70, 74, 76, 77], "29846021e": 33, "298humili": 70, "299": [15, 51, 68, 69, 74, 77], "29913": 55, "299and": 69, "299s0": 77, "29m": [32, 51], "2_000": 52, "2a": 15, "2at": 15, "2be": 70, "2can": 70, "2cat": 69, "2d": [51, 129, 130, 147], "2f": [11, 48, 75], "2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1": 38, "2fetch": 15, "2got": 69, "2high": 15, "2i": [15, 70], "2in": 15, "2it": [19, 22, 26, 27, 28, 51, 69, 74, 75, 77], "2just": 70, "2lovabl": 15, "2m": [51, 74], "2my": 69, "2nd": 15, "2not": 15, "2on": 69, "2someon": 70, "2still": 15, "2stink": 15, "2tabl": 69, "2the": 69, "2thi": 15, "2to": [15, 70], "2todai": 69, "2when": 69, "3": [3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 130], "30": [11, 20, 23, 24, 38, 51, 55, 64, 69, 70, 74, 75, 76, 77], "300": [11, 26, 27, 29, 33, 48, 51, 53, 55, 63], "3000": 63, "30000": 40, "300000012": 5, "30035": 55, "30061": 55, "300671": 64, "301": [68, 69, 74, 76, 77], "30111": 74, "30111base": 74, "3012": 74, "30132": 76, "30132fcome": 76, "30167168e": 33, "30184": 55, "301and": 69, "301the": 69, "302": [68, 69, 74, 79], "30265497e": 33, "30289579e": 33, "303": [68, 69, 73, 74, 77], "3030": 15, "30311023e": 33, "30371": 55, "303feel": 73, "303i": 69, "304": [68, 69, 70, 74, 77], "30400702e": 33, "3048": 71, "304cat": 69, "304so": 70, "305": [68, 69, 70, 74, 76], "30516074e": 33, "30594799e": 33, "305in0": 68, "306": [15, 64, 69, 74, 79], "30619": 55, "30670751e": 33, "30676": 68, "30676f": 68, "306what": 69, "307": [69, 70, 73, 74], "3070": 69, "307135": 69, "30713ffrog": 69, "307frog": 69, "307i": [69, 73], "307on": 69, "307so": 70, "308": [68, 69, 74, 76, 77], "30887298e": 33, "30891727e": 33, "308and": 69, "308the": 69, "309": [15, 68, 69, 73, 74, 76, 77], "30925": 68, "30925base": 68, "30929557e": 33, "30930": 55, "30982637e": 33, "309and": 69, "309got": 69, "309hope": 73, "30brilliant": 15, "30m": 51, "31": [11, 23, 24, 26, 33, 36, 38, 51, 59, 68, 69, 74, 75, 76, 77], "310e": 56, "311": [69, 76], "311027": 64, "311112": 37, "3119460": 74, "311946fuse": 74, "311table0": 69, "311the": 69, "312": [69, 74, 77], "3123": [69, 74], "3126": 77, "3126base": 77, "312got": 69, "313": [68, 74, 77], "31331": 55, "31345329e": 33, "31366367e": 33, "31375678e": 33, "314": [68, 74], "31415171e": 33, "3143560": 74, "314356fin": 74, "31480657e": 33, "314orns0": 68, "315": [68, 69, 76, 77], "31584621e": 33, "315and": 69, "316": [68, 69, 74, 77], "31675867e": 33, "316on": 69, "316orns0": 68, "317": [68, 74, 76], "31716942e": 33, "31752113e": 33, "31793": 55, "317orn": 68, "318": [15, 56, 68, 69, 74, 76], "3182": 59, "31836259": 49, "31839": 38, "3188120": 69, "318812base": 69, "318the": 69, "319": [15, 68, 69, 74, 77], "31901": 55, "319114": 64, "31995": 73, "31995base": 73, "319and": 69, "319orns0": 68, "31cat": 69, "31home": 69, "31m": 51, "32": [11, 24, 28, 32, 36, 38, 47, 51, 59, 68, 69, 71, 75, 76, 77], "320": [32, 37, 51], "32063496e": 33, "32071": 10, "32080293e": 33, "321": [68, 69, 74], "32122": 68, "32122f": 68, "3214": 59, "321cat": 69, "321on": 69, "322": [15, 68, 69, 74], "3220": 69, "32211058e": 33, "32266139e": 33, "323": [73, 74, 76, 77], "32335": 17, "3238": 51, "323so": 73, "324": [15, 68, 69, 73, 74], "3244470": 77, "324447frempla\u00e7": 77, "324feel": 73, "324orns0": 68, "325": [56, 68, 69, 74, 76, 77], "32538475e": 33, "32551": 68, "32551f": 68, "32561": [10, 17, 38, 54, 55, 56], "325on": 69, "325scientists0": 76, "325the": 69, "326": [68, 69, 70, 73, 77], "32613585e": 33, "32637697e": 33, "32686793e": 33, "326awake0": 70, "326orn": 68, "326so": 73, "327": [38, 68, 69, 76, 77], "327film0": 38, "327the": 69, "328": [68, 69, 73, 77], "32848": 55, "32881791e": 33, "32885": 69, "32885fthe": 69, "328orns0": 68, "328someon": 73, "329": [15, 38, 68, 69, 74, 76, 77], "32918101e": 33, "3295135e": 57, "3296": 68, "32969309e": 33, "3296base": 68, "3297": 76, "3297fvodka": 76, "32981": 68, "32981f": 68, "329no": 38, "32and": 69, "32in": 68, "32m": 51, "32ural": 77, "32what": 69, "33": [11, 23, 28, 38, 51, 59, 68, 69, 74, 75], "330": 51, "331": [68, 74, 77], "33153354e": 33, "332": [68, 69, 73, 74], "332361": 37, "33246894e": 33, "33258": 69, "33258f": 69, "332in0": 68, "332on": 69, "332orns0": 68, "332so": 73, "333": [68, 69, 74, 76], "333333": [127, 128, 138, 140], "333cat": 69, "333i": 76, "333on": 69, "334": [68, 69, 74], "33445268e": 33, "334the": 69, "335": [56, 68, 69, 74], "335002": 37, "3357": 68, "3357base": 68, "335bff": 60, "335got": 69, "335in0": 68, "335the": 69, "336": [68, 69, 74], "336in0": 68, "336tabl": 69, "337": [68, 69, 74, 76], "338": [69, 74], "33829069e": 33, "338294": 47, "33830389e": 33, "338and": 69, "339": [68, 69, 76], "33920406e": 33, "33942": [70, 73], "33942flove": [70, 73], "339and": 69, "339orns0": 68, "33actor": 72, "33m": 51, "33the": 15, "34": [11, 24, 32, 33, 38, 43, 47, 51, 59, 68, 69, 74, 75, 76], "34049235e": 33, "341": [15, 68, 69, 76], "3411764705882353": 55, "3412": 59, "34124": 70, "34124base": 70, "34132949e": 33, "34167858e": 33, "34168877e": 33, "34171474e": 33, "342": [74, 77], "34284": 76, "34284fvodka": 76, "34288691e": 33, "34289": [70, 73], "34289ffear": [70, 73], "34293": 62, "343": [69, 76], "34301575e": 33, "34304": 68, "34304base": 68, "3431527": 72, "34323": 62, "34331994e": 33, "344": [68, 74, 77], "34400232e": 33, "344069": 76, "344069fdai": 76, "34461065e": 33, "34477": 76, "34477f": 76, "345": [68, 69, 74, 77], "34528691e": 33, "34549962e": 33, "3455": 68, "34555133e": 33, "3455base": 68, "345and": 69, "346": [15, 68, 77], "34655710e": 33, "3469024": 15, "346902f": 15, "346orns0": 68, "347": [15, 68, 69], "3471": 68, "3471base": 68, "34743": 68, "34743base": 68, "34793035e": 33, "347in0": 68, "347on": 69, "348": [68, 69, 74], "3480": 15, "34808709e": 33, "349": [69, 74, 77], "3490": 15, "34953": 69, "34953744e": 33, "34953fon": 69, "349831": 64, "349the": 69, "34and": 15, "34it": [20, 48], "34m": 51, "34osprei": 74, "34the": 69, "35": [11, 15, 24, 26, 38, 47, 48, 51, 68, 69, 70, 72, 74, 75, 77], "3500e": 56, "35011272e": 33, "3503560": 69, "350356fcat": 69, "35079": 68, "35079f": 68, "35081": 77, "35081base": 77, "351": [69, 70, 76], "351862": 74, "35186funion": 74, "35192638e": 33, "35199817e": 33, "351i": 76, "351on": 69, "351the": 69, "351wrong": 70, "352": [68, 69, 73, 74], "352base": 68, "352on": 69, "352so": 73, "353": [68, 69, 76, 77], "35342843e": 33, "353885": [70, 73], "35388fsad": [70, 73], "353on": 69, "354": [68, 69, 74, 77], "3546": 51, "35475280e": 33, "35499": 55, "354and": 69, "354i": 69, "35507381e": 33, "3555260": 74, "355526base": 74, "35582286e": 33, "356": [68, 76], "35622499e": 33, "35655146e": 33, "35691": 68, "35691f": 68, "356kb": 47, "357": [15, 68, 69, 74], "35738961e": 33, "358": [15, 68, 69, 74], "3585": 15, "358cat": 69, "358kb": 47, "358the": 69, "359": [68, 69, 72, 77], "35901155e": 33, "359397": 74, "359397fshould": 74, "35955503e": 33, "35978654e": 33, "35979441e": 33, "359s1": 77, "35m": 51, "35mayb": 15, "35what": 69, "36": [8, 11, 23, 24, 27, 38, 48, 51, 69, 73, 74, 75, 76, 77], "3600567": 72, "36048309e": 33, "360e": 56, "361": [68, 69, 73, 74, 77], "3613": 68, "3613base": 68, "36168788": 8, "361can": 73, "362": [68, 69, 77], "36239048e": 33, "362and": 69, "362in0": 68, "363": [68, 69], "36373": 55, "36379": 70, "36379base": 70, "364": [68, 69, 70, 74, 77], "364care": 70, "364frog": 69, "364orns1": 68, "364the": 69, "365": [38, 68, 69, 76, 77], "365orns0": 68, "366": [38, 68, 69, 76, 77], "366081": 77, "36608fpara": 77, "36609805e": 33, "36653134e": 33, "36698000e": 33, "366tell": 38, "366when": 69, "367": [68, 70, 73], "36751638e": 33, "367feel": 73, "367hopeless": 70, "368": [69, 74], "3684": 51, "3688": 51, "368and": 69, "369": [68, 69, 74, 77], "3690": 51, "36935152e": 33, "3694": 51, "36davi": 74, "36didnt": 73, "36m": 51, "37": [11, 23, 24, 29, 38, 51, 68, 69, 74, 75, 77], "3702": 51, "37021038e": 33, "37029": 69, "37029base": 69, "371": [15, 68, 69, 74, 76], "3711": 15, "37113822": 75, "3714": 51, "37150423e": 33, "372": [56, 69, 74, 76], "37202": 69, "37202base": 69, "3721": 51, "37212363e": 33, "3728": 51, "372the": 69, "373": [15, 68, 69, 74], "3737": 51, "373i": 69, "374": [68, 69, 73, 74, 76], "3740": 51, "37425945e": 33, "3745": 51, "374feel": 73, "374tabl": 69, "374table0": 69, "375": [52, 67, 74, 76, 77], "3753": 51, "3754": 77, "3754base": 77, "37561609e": 33, "376": [68, 74, 76], "37602425e": 33, "37629": 69, "37629f": 69, "3767": 68, "3767base": 68, "37692579e": 33, "376base": 68, "377": [69, 70, 74, 76, 77], "3773": 15, "3776": 51, "377hopeless": 70, "377i": 76, "377the": 69, "378": [15, 68, 69, 74, 76, 77], "3780": 51, "37802403e": 33, "37821451e": 33, "37846563": 65, "378the": 69, "379": [68, 69], "37901196e": 33, "3792230": 74, "379223f": 74, "3794": [51, 71], "37979460e": 33, "3799": 51, "379in0": 68, "37m": 51, "37provid": 74, "37todai": 69, "38": [11, 21, 23, 27, 37, 38, 44, 51, 64, 69, 74, 75, 76], "38024008e": 33, "3807": 51, "38077943e": 33, "3808": 51, "381": [68, 69, 77], "38105": 76, "38105fsure": 76, "3815": 68, "3815base": 68, "3818": 51, "382": [68, 69, 76], "38278": 74, "38278109e": 33, "38278base": 74, "382and": 69, "382tabl": 69, "383": [69, 74], "383the": 69, "384": [74, 75], "38400": 37, "38428388e": 33, "38449": 70, "38449base": 70, "385": [15, 57, 68, 69, 76, 77], "38569065e": 33, "385and": 69, "386": [15, 68, 69], "3864": 51, "38652884e": 33, "386i": 69, "387": [15, 68, 69, 74, 76], "38723": 68, "38723f": 68, "388": [68, 69, 74], "38847245e": 33, "38898808": 75, "389": [68, 69, 74], "38956": 74, "38956base": 74, "3896": 51, "38996": 68, "38996f": 68, "389in": 68, "389the": 69, "38i": 76, "38m": [32, 51], "39": [5, 8, 11, 15, 28, 30, 31, 32, 33, 38, 43, 47, 51, 59, 60, 64, 68, 69, 72, 74, 75, 76, 77], "39092177e": 33, "391": [68, 69, 73, 74], "3914": 51, "391greedi": 73, "391i": 69, "392": [14, 68, 69, 76], "39261465e": 33, "392i": 69, "392in0": 68, "392my": 69, "393": [15, 68, 69, 76, 77], "39315515e": 33, "39321840e": 33, "39340307e": 33, "39376134e": 33, "393table0": 69, "394": 77, "3940": 15, "39472": 47, "395": [68, 70, 73, 74, 77], "395353": 74, "395353f": 74, "395feel": 73, "395humiliated0": 70, "396": [15, 68, 69, 74], "396371": 64, "39668138e": 33, "396cat": 69, "396ran": 15, "396saw": 69, "397": [68, 69, 74], "3970": 71, "397and": 69, "398": [68, 72, 74, 76, 77], "398964": 74, "398964ffund": 74, "39898028e": 33, "398er": 77, "398orn": 68, "399": [76, 77], "3999": 52, "399i": 76, "39it": 38, "39m": 51, "39my": 69, "39ural0": 77, "3a": 15, "3easili": 15, "3greedi": 70, "3he": 15, "3hope": 70, "3it": [13, 18, 19, 29, 33, 34, 35], "3m": [51, 74], "3on": 69, "3rd": 3, "3someon": 73, "4": [4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "40": [8, 11, 14, 23, 24, 26, 40, 51, 55, 64, 69, 70, 74, 75, 128], "400": 55, "4000": 63, "40055524e": 33, "400e": 56, "401": [68, 69, 73, 74, 76], "4012": [69, 74], "40123": [69, 74, 77], "40125": 38, "40148": 77, "40148base": 77, "401feel": 73, "401tabl": 69, "402": [68, 69, 74], "40222663e": 33, "402home": 69, "402on": 69, "403": [68, 69, 70, 77], "40331360e": 33, "40335624e": 33, "4036e": 56, "403feel": 70, "403in0": 68, "403the": 69, "404": [68, 74], "405": [68, 69, 73, 76, 77], "40567": [70, 73], "40567ffear": [70, 73], "405can": 73, "405s0": 77, "405tabl": 69, "405the": 69, "406": [28, 31, 68, 69, 76, 77], "406011": 74, "40601fwale": 74, "4062": 51, "406i0": 76, "407": [15, 74, 76, 77], "408": [68, 70, 74, 76], "408904": 64, "408wrong0": 70, "409": [68, 69, 73], "40927164e": 33, "40990349e": 33, "409and": 69, "409care": 73, "409tabl": 69, "40_000": 57, "40m": 51, "41": [11, 23, 30, 31, 47, 51, 69, 72, 75, 76], "41041": 69, "41041base": 69, "411": [68, 76], "4116": 51, "412": [68, 69, 74, 77], "41204": 38, "4122": 51, "4123": 77, "4126": 51, "412in": 68, "412in0": 68, "412the": 69, "413": [69, 74], "414": [68, 69, 76], "41437432e": 33, "41452435e": 33, "415": [68, 74, 77], "415orns0": 68, "416": [68, 69, 73, 74], "4163": 51, "41678562e": 33, "416hope": 73, "417": [68, 77], "41729": 76, "41729base": 76, "41739": 74, "41739base": 74, "41746947e": 33, "4175": 51, "41784": 76, "41784flove": 76, "417854": 47, "418": [68, 74, 77], "41808981e": 33, "4182": 51, "41849874e": 58, "41849875e": 58, "41858088e": 33, "4186": 59, "419": 68, "4197": 71, "41i": 76, "41i0": 76, "41m": 51, "41my": 69, "41on": 69, "42": [23, 24, 27, 39, 51, 57, 64, 68, 69, 72, 74, 75, 77, 153], "420": 15, "420053": 51, "42042244e": 33, "42074548e": 33, "42078109e": 33, "42085895e": 33, "42096503e": 33, "420e": 56, "421": [68, 73, 76, 77], "421wrong": 73, "422": [32, 68], "423": [68, 74, 77], "4231": 51, "42370665e": 33, "4238": 51, "424": [68, 69, 74, 76, 77], "4241": 76, "4245": 76, "4246": [74, 77], "424and": 69, "424what": 69, "425": [68, 69], "42515026e": 33, "4256": 74, "4256base": 74, "42575": 76, "42575ftheir": 76, "425cat": 69, "426": [68, 69], "42620936e": 33, "426tabl": 69, "427": [68, 69, 73, 74, 76], "427didnt": 73, "427grab": 73, "428": [68, 69, 74, 76], "42857461e": 33, "42889383e": 33, "428the": 69, "429": [74, 76], "4296968952292404": 11, "4297": 11, "429i": 76, "42m": 51, "42table0": 69, "43": [3, 22, 24, 37, 38, 51, 69, 74, 75, 76], "431": [68, 69, 76], "43101468e": 33, "43152502e": 33, "431and": 69, "431table0": 69, "432": [68, 77], "4320": 75, "4320e": 56, "43230298": 75, "433": [68, 69], "43363092e": 33, "434": [68, 74], "4340": 15, "43427046e": 33, "43495": 69, "43495base": 69, "435": [68, 69, 74, 77], "43523454e": 33, "43542802e": 33, "43557079e": 33, "435641": 77, "435641fm\u00e1": 77, "4358": 51, "43599": 68, "43599f": 68, "435got": 69, "436": [68, 69, 76], "43607": 68, "43607f": 68, "43612": 68, "43612f": 68, "4369": 51, "437": [70, 74], "43703653e": 33, "43710693e": 33, "43752168": 49, "43796897e": 58, "437feel": 70, "438": [68, 69, 74, 76, 77], "43801317e": 58, "438092": 77, "43809fndo": 77, "43823": 68, "43823f": 68, "43837762e": 33, "43840865e": 33, "43847588e": 33, "43872213e": 33, "43880873e": 58, "43887488e": 58, "438saw": 69, "439": [68, 69, 74, 76], "439got": 69, "439i": 76, "43m": 51, "43tabl": 69, "43to": 15, "44": [8, 27, 28, 51, 68, 69, 74, 75, 76], "440": 3, "44012073e": 33, "44020942e": 33, "4404": 51, "44065": 69, "44065f": 69, "441": [15, 68, 69, 74], "44103158e": 33, "4411": 51, "44111234e": 33, "4412": 47, "441what": 69, "442": [68, 69, 74, 76], "44245707e": 33, "44268419e": 33, "4429": 51, "442and": 69, "442scientist": 76, "442tabl": 69, "443": [68, 69], "4432": 56, "44324": 68, "44324f": 68, "44384784e": 33, "443i": 69, "444": [68, 69, 73, 74, 76, 77], "4447": 68, "4447base": 68, "4449": 51, "44493266e": 33, "444hopeless": 73, "445": [68, 69, 76, 77], "4455160": 77, "445516fde": 77, "445home": 69, "445i": 76, "446": [68, 69, 76, 77], "4460e": 56, "44630976e": 33, "44658901e": 33, "4468": 73, "446in0": 68, "446my": 69, "446the": 69, "447": [68, 69], "447321": 76, "44732fabl": 76, "447orns0": 68, "447tabl": 69, "448": [68, 69, 74, 76], "4481": 51, "44811999e": 33, "44894": 68, "44894f": 68, "44897928e": 33, "448on": 69, "448table0": 69, "449": [68, 76], "4499": 52, "449i": 76, "44m": 51, "44the": 69, "45": [23, 24, 39, 51, 59, 68, 69, 75, 76, 80, 85, 86, 87, 90, 91], "4500": 52, "45077": 68, "45077f": 68, "4509": 51, "451": [15, 56, 68, 69, 74, 76], "4513": 51, "45166923e": 33, "451the": 69, "452": [68, 74], "45231204e": 33, "453": [68, 76], "45328": 63, "45378": 74, "45378base": 74, "453in": 68, "454": [15, 68, 69, 74, 76], "45405869e": 33, "45434223": 75, "4545": 51, "4549": 51, "454home": 69, "454i": 76, "455": [74, 76, 77], "4550": 15, "4557": 51, "455er": 77, "455i": 76, "456": [28, 31, 68, 69, 70, 74], "45622762e": 33, "456231": 37, "456greedi": 70, "456the": 69, "457": [68, 69, 75, 76, 77], "45769": 38, "4577": 71, "457on": 69, "458": [68, 69, 77], "45838": [70, 73], "45838fsurpris": [70, 73], "458the": 69, "459": [69, 74], "45928192e": 33, "45950279e": 33, "459752": 77, "45975ftransformateur": 77, "45994454e": 33, "459i": 69, "45m": 51, "45my": 69, "46": [24, 27, 51, 59, 68, 73, 74, 75, 76], "4600": 51, "4602": 51, "46041076e": 33, "461": [68, 74, 76, 77], "461i": 76, "462": [68, 69, 74], "4621": 51, "46244482e": 33, "4627": 51, "4628": 47, "462the": 69, "462what": 69, "463": 68, "46375887e": 33, "464": [68, 69, 74, 77], "464142": 77, "46414base": 77, "4645": 51, "464603": 64, "46476041": 8, "46494092e": 33, "464the": 69, "465": [68, 74, 77], "46525475e": 33, "466": [73, 74], "46612704e": 33, "466care": 73, "467": [68, 69, 74, 76, 77], "467i": 76, "468": [68, 74], "46804469e": 33, "4681": 77, "4681base": 77, "468442": 64, "4687": 71, "469": [69, 73, 76], "46946550e": 33, "46988168e": 33, "469so": 73, "469tabl": 69, "46hopeless": 73, "46m": 51, "46orn": 68, "47": [24, 25, 27, 51, 59, 68, 69, 72, 74, 75, 84, 86, 90, 91], "47012542e": 33, "47023078e": 33, "47048": 74, "47048base": 74, "471": 74, "47122": 63, "4719": 74, "4719base": 74, "472": [69, 76, 77], "4729": 51, "472cat": 69, "473": 68, "47348856e": 33, "473in": 68, "473m": 74, "474": [68, 69, 76], "47433345e": 33, "47455": 77, "47455base": 77, "474home": 69, "475": [68, 69], "47565": 74, "47565fa": 74, "476": [74, 77], "47616291e": 33, "4761e": 56, "47620167e": 33, "47626798e": 33, "477": [68, 69], "47746861e": 33, "4776": 51, "47763": 76, "47763base": 76, "4777": 51, "47793456e": 33, "477and": 69, "478": [68, 69, 74], "4781": 51, "47819": 74, "47819base": 74, "47823477e": 33, "4783": 68, "4783base": 68, "47865": 69, "47865base": 69, "47871488e": 33, "47898585e": 58, "47898608e": 58, "4791": 75, "47m": 51, "48": [51, 59, 72, 75], "480": 15, "48080294e": 33, "481": [69, 74], "48107536": 75, "4811": 69, "48119268e": 33, "4811fon": 69, "48136": 76, "48136fvodka": 76, "48173926e": 33, "48189050e": 33, "48199712e": 33, "481todai": 69, "481what": 69, "482": [68, 76], "4823": 68, "4823base": 68, "48254": 68, "48254f": 68, "48262605e": 33, "482i": 76, "483": [56, 68, 77], "4832": 68, "4832base": 68, "4834": 68, "4834f": 68, "484": [15, 69, 70, 74, 76], "48451": 68, "48451f": 68, "484and": 69, "484feel": 70, "484i": [15, 76], "485": [28, 31, 68, 69, 70, 75, 76], "48544926e": 33, "48575078e": 33, "485awake0": 70, "485i": 69, "485in0": 68, "485tabl": 69, "486": [68, 74, 77], "4860": 51, "48605": 69, "48605base": 69, "487": [68, 69, 76], "48715": 68, "48715f": 68, "48757566e": 33, "487what": 69, "488": [68, 76, 77], "4883": 51, "48898237e": 33, "489": [68, 76], "48955398e": 33, "48m": 51, "49": [15, 24, 27, 51, 59, 69, 72, 74, 75, 77, 84, 91], "49085918e": 33, "491": 68, "491624": 47, "492": 77, "49212": 68, "49212f": 68, "49226135e": 33, "49238822": 75, "493": [68, 76], "49311381e": 33, "4932": 51, "49337298e": 33, "49367": 74, "49367fstar": 74, "49386": [68, 69], "49386f": 68, "49386fthe": 69, "494": [68, 69, 74], "4940835": 72, "49425339e": 33, "49429640e": 33, "4943": 68, "4943f": 68, "4945": 51, "49486": 69, "49486fthe": 69, "49490": 63, "494and": 69, "494what": 69, "495": [68, 69, 77], "49581831e": 33, "495i": 69, "496": [32, 68], "4962": 15, "497": 68, "49706873e": 33, "498": 69, "4980790": 69, "498079fmy": 69, "498283": 64, "498338": 74, "498338base": 74, "49878833e": 33, "49898115": 75, "498what": 69, "499": [68, 69, 74], "4991": 76, "4992": 15, "4999": [52, 63], "499base": 76, "499on": 69, "49but": 15, "49homeless": 15, "49i": 72, "49m": 51, "49on": 69, "4after": 15, "4f": [37, 53, 57], "4it": 28, "4m": [51, 71], "4mb": 26, "4necessari": 15, "4same": 15, "4tabl": 69, "4the": 15, "4todai": 69, "4when": 69, "5": [4, 5, 6, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 126, 127, 128], "50": [0, 1, 2, 3, 4, 6, 9, 11, 13, 14, 18, 19, 23, 24, 26, 27, 28, 29, 33, 34, 35, 37, 46, 47, 50, 51, 54, 55, 63, 70, 72, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162], "500": [13, 15, 18, 19, 26, 27, 29, 33, 34, 35, 38, 40, 50, 51, 52, 53, 55, 59, 61, 62, 72, 79], "5000": [29, 33, 43, 55, 59, 63, 64], "5000e": 56, "5001490": 74, "500149fsai": 74, "50049": 68, "50049base": 68, "50061": 76, "50061ftheir": 76, "50074469e": 33, "500base": 69, "501": 68, "5012": [69, 74], "50123": [69, 74, 77], "50157": 69, "50157base": 69, "50180674e": 33, "502": [69, 77], "50219047e": 33, "50256": 76, "50297": 77, "50297base": 77, "502er": 77, "502got": 69, "503": [56, 68, 69], "50342930e": 33, "503827": 47, "503what": 69, "504": [15, 68, 74, 77], "5041": 51, "50416": 68, "50416f": 68, "50417589e": 33, "505": [68, 69, 74, 77], "50564": 68, "50564f": 68, "505i": 69, "506": [50, 68, 69, 70, 74], "50643864e": 33, "506grab": 70, "506on": 69, "507": [68, 69, 74], "50748165e": 33, "50748750e": 33, "507table0": 69, "508": [68, 69, 74], "50828767e": 33, "5084": 51, "50853336": 75, "508i": 69, "508orns0": 68, "508the": 69, "509": 68, "50967354e": 33, "509722": 64, "50k": [9, 10, 11, 12, 14, 17, 44, 54, 55, 93], "50m": 51, "50x50": 26, "51": [15, 24, 26, 47, 51, 70, 72, 74, 75, 76], "51042400e": 33, "5109875": 72, "511": [15, 68, 70, 73, 76], "5116": 68, "5116base": 68, "51177555e": 33, "511care": 73, "511feel": 70, "512": [11, 38, 51, 54, 68, 77], "51200": 37, "51283562e": 33, "51292086e": 33, "51296447e": 33, "513": [68, 69, 73, 74, 77], "51379456e": 33, "51396252e": 33, "513wrong": 73, "514": [68, 69, 74, 76], "5140118": 65, "514878": 47, "51496": 68, "51496f": 68, "514i": 69, "515": [68, 69, 77], "51567": 69, "51567fwhen": 69, "516": [68, 69, 74, 76], "51606662": 75, "51698780e": 33, "516in0": 68, "516what": 69, "517": 68, "51709687e": 33, "517105754085364": 45, "51766": 74, "51766133582009": 45, "51766fplayer": 74, "517u": 36, "518": [15, 68, 69, 70], "51803600e": 33, "51832": 68, "51832base": 68, "518grab": 70, "519": [68, 76], "5190": 15, "519orns0": 68, "51hopeless": 70, "51m": 51, "52": [24, 48, 69, 72, 74, 77], "521": [69, 74], "521836": 76, "52183fto": 76, "521the": 69, "521todai": 69, "522": [69, 73], "5226": 51, "522802": 37, "522feel": 73, "523": [68, 69], "5234": 68, "5234base": 68, "523home": 69, "524": 68, "5240": 15, "52411381e": 33, "52413466e": 33, "52419981e": 33, "5242": 51, "525": 68, "525u": 36, "526": 76, "52605474e": 33, "526581": 74, "52658f3": 74, "527": 77, "527824": 64, "528": [68, 69, 70, 74], "5281": 51, "52817175": 49, "52828421e": 33, "52835": 76, "52835flove": 76, "52849994e": 33, "52892": 69, "52892f": 69, "528feel": 70, "528orns1": 68, "528what": 69, "529": [68, 76, 77], "52912931e": 33, "529277": 64, "529former": 77, "52and": 69, "52m": 51, "52most": 15, "53": [24, 51, 68, 69, 72, 74], "53026136e": 33, "53028246e": 33, "53062156e": 33, "531": 74, "53134": 63, "532": [59, 68], "5320": 51, "532152": 77, "53215flp": 77, "53278966e": 33, "53284360e": 33, "533": 69, "5333333333333333": 55, "5337": 51, "533836": 77, "533836fr\u00e9seaux": 77, "533got": 69, "534": [68, 69], "53428": 74, "53428fkeep": 74, "5344": 51, "53443623e": 33, "53444610e": 33, "5345": 68, "5345base": 68, "5348": 59, "534i": 69, "535": [68, 74], "53547439e": 33, "53559": 74, "53559base": 74, "535u": 36, "536": [68, 73], "5360": 15, "53620885e": 33, "536367": 77, "536367base": 77, "53652": 69, "53652fwhat": 69, "536feel": 73, "536in0": 68, "537": [68, 69, 74], "538": 68, "53816455e": 33, "53889210e": 33, "53893842e": 33, "53frog": 69, "53m": 51, "54": [47, 70, 72, 73], "54094": 76, "54094base": 76, "541": [74, 77], "54113": 55, "5412": 51, "54125": 69, "54125base": 69, "541s1": 77, "542": 69, "54228": 77, "54228base": 77, "54264562e": 33, "543": 69, "54324962e": 33, "54350952e": 33, "5437": 68, "5437base": 68, "54381361e": 33, "5439": 74, "5439base": 74, "544": [15, 68], "54479500e": 33, "544orns0": 68, "545": [68, 69, 70, 73], "54518042e": 33, "5456": 59, "54573101e": 33, "545greedi": 70, "545i": 73, "545tabl": 69, "545what": 69, "546236": 37, "54663": 55, "546911": 77, "54691frecurrent": 77, "547": 74, "54717401": 75, "548": 69, "54854601": 8, "549": [68, 70, 74, 77], "54949": 76, "54949base": 76, "549grab": 70, "549lp0": 77, "549ural0": 77, "54grab": 70, "54humili": 73, "54humiliated210": 73, "54m": 51, "55": [24, 51, 68, 69, 72, 76], "55029": 77, "55029base": 77, "55093584213122": 49, "55094492e": 33, "55153718e": 33, "552": [68, 77], "55202758e": 33, "55207381e": 33, "552238": 64, "552orns0": 68, "553": [68, 69, 74], "55347": 77, "55347base": 77, "5536": 68, "5536base": 68, "55382": 77, "553828": 37, "5538fmodelo": 77, "553my": 69, "553orns0": 68, "554": [15, 68], "55444": 68, "55444f": 68, "55454": 69, "55454base": 69, "555": [68, 70, 74], "55510512e": 33, "55517923e": 33, "555511": 77, "55551base": 77, "555823": 74, "55582fdavi": 74, "555greedi": 70, "556": 69, "55616": 77, "55616base": 77, "55638": 47, "556what": 69, "557": [15, 68, 74], "557orn": 68, "558": [59, 68, 69, 74, 77], "55858996e": 33, "5586": 68, "5586f": 68, "55878990e": 33, "5588": 68, "5588base": 68, "558got": 69, "558orn": 68, "559": [68, 77], "5594": 74, "5594base": 74, "55952512e": 33, "55952876e": 33, "55i": 69, "55it": 44, "55m": 51, "56": [11, 23, 26, 27, 51, 68, 72], "56077331e": 33, "561": [68, 69, 76], "56132140e": 33, "56141": 77, "56141base": 77, "56183428": 8, "56191216e": 33, "562": 74, "56201809e": 33, "56205360e": 33, "56290082e": 33, "563": [69, 73, 74], "56369548e": 33, "56387687e": 33, "563i": 73, "565": [68, 69], "56545924e": 33, "566": [69, 74], "5662": 51, "56658": 69, "56658base": 69, "566i": 69, "567": [68, 70, 77], "5674": 59, "567feel": 70, "568": 74, "56805": 76, "56805ftheir": 76, "56837": 76, "56837f": 76, "569": [68, 69], "56953": 68, "56953f": 68, "56f91f2e778daf14a499f21b": 26, "56m": 51, "57": [24, 33, 37, 51, 68, 72, 75], "57041": 70, "57041base": 70, "571": [68, 74, 76], "5710": 15, "5714": 77, "57140807e": 33, "5714base": 77, "572": [68, 69, 70], "57225": 69, "57225base": 69, "57244479e": 33, "572529": 74, "572529f": 74, "57255": 62, "57258": 62, "57267496e": 33, "57296371e": 33, "572hope": 70, "572todai": 69, "573022": 69, "573022fi": 69, "5736": 68, "5736base": 68, "574": [68, 74], "5741": 51, "575": [68, 77], "57506050e": 33, "576": [68, 77], "57617": 68, "57617base": 68, "57620137e": 33, "576orns0": 68, "57771": 74, "57771base": 74, "578": [68, 69, 70, 76], "5781": 51, "578531": 64, "578grab": 70, "578scientists0": 76, "579": 69, "57908": 76, "57908f": 76, "57913503e": 33, "5792": 68, "5792base": 68, "579653": 69, "57965ffloor": 69, "57991": 76, "57991base": 76, "57999836e": 33, "579todai": 69, "57m": 51, "58": [10, 17, 23, 24, 33, 37, 38, 45, 51, 68, 74], "580e": 56, "581": [68, 73, 77], "581damn": 73, "582": 68, "58263346e": 33, "58320142e": 33, "58322830e": 33, "58328272e": 33, "58339016e": 33, "584": [68, 69, 73], "58421525e": 33, "58422904": 8, "58454558e": 33, "58459095e": 33, "58464256": 49, "584didnt": 73, "584i": 69, "585": 68, "58560916e": 33, "5858": 68, "5858base": 68, "586": [68, 74], "58677243e": 33, "5878": 69, "5878fon": 69, "588": [68, 77], "58840441e": 33, "589": 77, "589361": 77, "58936fhan": 77, "58988": 68, "58988f": 68, "58m": 51, "59": [15, 19, 24, 33, 37, 69, 72, 74], "59006": 68, "59006f": 68, "59063807e": 33, "591": 77, "59173209e": 33, "591ers0": 77, "592": 68, "592141": 77, "59214felecci\u00f3n": 77, "59291131e": 33, "593": 77, "59340711e": 33, "59394997e": 33, "595": 68, "59520757e": 33, "595orns0": 68, "596": 68, "59645104e": 33, "596605": 69, "596605base": 69, "59675707e": 33, "59689171e": 33, "596in0": 68, "597": [68, 77], "59767864e": 33, "59768169e": 33, "59781": 68, "59781base": 68, "59797564e": 33, "597in": 68, "598": [15, 69, 74, 77], "59803119e": 33, "59819072e": 33, "598home": 69, "598what": 69, "599": [68, 70, 77], "59942": 68, "59942base": 68, "599hopeless": 70, "59and": 69, "59m": 51, "59the": 69, "5and": 15, "5be": 15, "5bromwel": 15, "5e": 38, "5in": 15, "5m": [51, 71], "5sell": 15, "5think": 15, "6": [4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 38, 39, 40, 43, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "60": [23, 24, 27, 33, 38, 50, 51, 62, 63, 70, 74, 96, 100], "600": 55, "6000": 63, "60000": [32, 36, 37], "60033255e": 58, "60033274e": 58, "600823": 74, "60082f3": 74, "601": [64, 68], "602": [68, 69, 74, 77], "602table0": 69, "602what": 69, "603": [69, 74], "6039070": 76, "603907f": 76, "604": 74, "605": 68, "6050570": 77, "605057fle": 77, "605in": 68, "606": [68, 77], "60601024e": 33, "6069": 68, "6069base": 68, "607": [68, 77], "60702": 77, "60702base": 77, "60738": 77, "60738base": 77, "60756264e": 33, "608": [68, 69, 77], "60848489e": 33, "60852": 68, "60852base": 68, "60868": 63, "608s2": 77, "608the": 69, "609": 68, "60936": 69, "60936base": 69, "60944095e": 33, "6095": 71, "60959898e": 33, "60967": 76, "60967flove": 76, "609682": 74, "60968fwelsh": 74, "60985219e": 33, "60m": [51, 74], "61": [33, 45, 68, 69], "61000774e": 33, "611": [69, 74], "6113": 51, "61175641": 49, "612": [59, 68, 69, 72], "612what": 69, "613": [68, 69], "61327654e": 33, "61366333e": 33, "613on": 69, "614": [68, 73], "61411": 74, "61411base": 74, "61444": 68, "61444f": 68, "61449284e": 33, "614644": 64, "614931": 69, "614931base": 69, "614humili": 73, "61559995e": 33, "61580717e": 33, "61581129e": 33, "61583801e": 33, "6159": 51, "616": 77, "61688542e": 33, "61699": 76, "61699349e": 33, "61699ftheir": 76, "617": [68, 77], "6178": 59, "617orns0": 68, "618": 68, "61821784e": 33, "619": [68, 77], "61910939e": 33, "619631": 77, "61963f": 77, "619987": 76, "619987f": 76, "61999938e": 33, "61it": 38, "61m": [32, 51], "61table0": 69, "62": [68, 69, 74], "6201": 71, "62042": 68, "62042base": 68, "62095050e": 33, "621454": 64, "62147082e": 33, "62198048e": 33, "622": [68, 74, 77], "62247": 70, "62247base": 70, "623": [68, 74, 77], "62398820e": 33, "624": [68, 69], "6240": 15, "62434536": 49, "6244": 15, "62440856e": 33, "624486": 64, "624tabl": 69, "625": [52, 67, 68], "62530720e": 33, "625445": [70, 73], "62544fsad": [70, 73], "625811": 74, "62581base": 74, "62596": 77, "62596base": 77, "625base": 68, "626": [69, 73], "626wrong": 73, "626wrong20": 73, "627": 15, "62770463e": 33, "628": 74, "62802847": 75, "62838216e": 33, "629": 70, "62974946e": 33, "62990356e": 33, "629hope": 70, "62the": 69, "63": 77, "63055": 76, "63055fthei": 76, "63076770e": 33, "632": [68, 76, 77], "63202620e": 33, "632orn": 68, "633": [68, 77], "633281": 74, "63328fbe": 74, "6333723": 15, "633372f": 15, "633596": 69, "633596base": 69, "63397": 69, "63397ftabl": 69, "634": [68, 69], "6340": 75, "634696": 69, "63469fmy": 69, "635": 69, "63505945e": 33, "6359": 59, "636": 69, "63609492e": 33, "6365": 51, "63713237e": 33, "637274": 74, "637274ffund": 74, "63745839e": 33, "63771833e": 33, "63816": 76, "63816flove": 76, "6385940": 74, "638594base": 74, "639": [68, 74], "63949953e": 33, "63967852e": 33, "63991455e": 33, "63995": 69, "63995ftodai": 69, "63m": 51, "63three": 15, "64": [32, 37, 47, 69], "640": 38, "64027": 74, "64027base": 74, "641": 74, "64143920e": 33, "642": 69, "642263": 69, "642263base": 69, "64235049e": 33, "644": 70, "64410839e": 33, "64444": 73, "64444base": 73, "644hope": 70, "645": 68, "6450143": 72, "64511754e": 33, "64547542e": 33, "6455": 51, "64556390e": 33, "64568322e": 33, "646": 69, "64692199": 8, "646i": 69, "64772126e": 33, "648": [68, 74, 76], "64813": 69, "64813base": 69, "64890280e": 33, "64894590e": 33, "648orn": 68, "649321": 74, "64932fto": 74, "64978": 68, "64978f": 68, "64got": 69, "64m": 51, "65": [14, 18, 24, 68, 69, 77], "65011360e": 33, "65030882e": 33, "651": [68, 69], "651what": 69, "652": [68, 69, 73], "6523": 68, "6523base": 68, "65241177e": 33, "65254387e": 33, "652humili": 73, "652what": 69, "653": [69, 77], "65351326e": 33, "654": [68, 69], "65407902e": 33, "6542433490447965e": 52, "654the": 69, "655": [74, 77], "655827": 47, "656": [68, 74], "65600795e": 33, "6560e": 56, "65619456e": 33, "65649": 77, "65649base": 77, "656772": 69, "65677f": 69, "656orns0": 68, "657": 74, "65742051e": 33, "6574230": 74, "657423funion": 74, "65840166": 75, "659": [68, 69, 77], "6591": 68, "6591base": 68, "65it": 45, "66": 74, "66013405e": 33, "6604": 68, "6604base": 68, "66050": 77, "6605fn": 77, "6606": 77, "6606base": 77, "661": [69, 77], "66111950e": 33, "66113": 74, "66113base": 74, "6619183": 72, "66197169e": 33, "66199796e": 33, "661on": 69, "662": 77, "66212": 77, "6621fmod\u00e8l": 77, "66235329e": 33, "663": 77, "66373": 68, "66373base": 68, "664": 77, "6643": 15, "664lp": 77, "665": [68, 77], "66519734e": 33, "6659": 59, "666": [69, 76], "66666666666667": 46, "666when": 69, "667": [68, 69], "66722": 76, "66722base": 76, "668": [38, 68], "66828": 76, "66828ftheir": 76, "66837": 77, "66837base": 77, "66858081e": 33, "66886639e": 33, "6689": 77, "6689base": 77, "668pointless": 38, "669": 69, "66912321e": 33, "6692": 15, "66963": 68, "66963base": 68, "669tabl": 69, "669table0": 69, "67": 23, "67022704e": 33, "67027392e": 33, "67076190e": 33, "671": [68, 69, 73, 74, 77], "67114752e": 33, "67125933e": 33, "671287": 73, "671287base": 73, "6715": 68, "6715base": 68, "671care": 73, "671what": 69, "672": [68, 74, 77], "672orn": 68, "672orns0": 68, "673": [68, 70], "6731": 69, "6731base": 69, "6739": 51, "673humili": 70, "674": [68, 74], "67407416e": 33, "67468010e": 33, "675": [69, 74, 77], "676": [15, 74], "67602": 76, "67602fthei": 76, "67634551e": 33, "67642674e": 33, "676i": 15, "677": 69, "67771": [70, 73], "67771fanger": [70, 73], "677frog": 69, "678": 69, "67822865e": 33, "67849924e": 33, "679": 68, "67918": 63, "67933850e": 33, "67939991e": 33, "67m": 51, "68011480e": 33, "68017897e": 33, "68050027e": 33, "680684": 64, "6807": 68, "6807base": 68, "681": [68, 69, 74, 77], "6810": 77, "68100668e": 33, "6813": 51, "681432": 69, "681432fmy": 69, "68163021e": 33, "681todai": 69, "682": 68, "68219": 68, "68219base": 68, "68223705e": 33, "682885": 74, "682885base": 74, "683": [11, 69], "683975": 69, "683975base": 69, "684": [15, 68], "68490616e": 33, "685": [68, 70], "685032": 64, "68524691": 8, "68559418e": 33, "68564642e": 33, "685feel": 70, "686": 68, "68635260e": 33, "68641151e": 33, "687": [68, 74], "6874": 51, "68801": 68, "68801f": 68, "68813955e": 33, "688u": 71, "68977969e": 33, "6898": 68, "6898base": 68, "69": [24, 77], "6917": 77, "6917base": 77, "692": [68, 74], "69207989e": 33, "69218032": 75, "6925": 59, "692986": 37, "693": [68, 69], "69377157e": 33, "69378": 69, "69378fthe": 69, "69394498e": 33, "694": [68, 69, 70, 77], "6943": 51, "6947": 51, "694wrong": 70, "695": [15, 68, 69, 77], "69561": 74, "69561base": 74, "696": [69, 74], "69673445e": 33, "6969": [70, 73], "6969fanger": [70, 73], "696saw": 69, "69752": 74, "69752base": 74, "698": [68, 77], "69857871e": 33, "698er": 77, "699": 68, "699orn": 68, "69it": 44, "6davi": 74, "6f": 37, "6other": 15, "6such": 15, "6wai": 15, "6what": 69, "7": [4, 6, 9, 10, 11, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 36, 38, 39, 40, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 127], "70": [22, 23, 24, 47, 51, 70], "700": 55, "7000": 63, "70079084e": 33, "701": [68, 76], "70197119e": 33, "701orns0": 68, "702": [70, 77], "7028312": 15, "70285151e": 58, "70287136e": 58, "70297808e": 33, "702hopeless": 70, "703": [74, 77], "70305798e": 33, "70345920e": 33, "70354599": 8, "703821": 69, "703821base": 69, "70410256e": 33, "7043": 68, "7043f": 68, "70553578e": 33, "70565539e": 33, "70575456e": 33, "70595356e": 33, "706": 68, "7063": 77, "7063base": 77, "706orn": 68, "707": 68, "707orns1": 68, "708": 68, "70826330e": 33, "70858320e": 33, "70881874e": 33, "709": 68, "709427": 15, "70951336e": 33, "70m": 51, "71": [24, 45, 69, 76], "71015688e": 33, "711": [15, 69, 77], "711what": 69, "712": [68, 69], "71266763e": 33, "712frog": 69, "713": 77, "71349748e": 33, "7135": 77, "713ural": 77, "71428": 70, "71428base": 70, "71429429e": 33, "715": 68, "71519205e": 33, "7159": 68, "71596": 69, "71596fhome": 69, "7159base": 68, "716": [69, 76], "716024": 15, "71619": 69, "71619fon": 69, "71634930e": 33, "71683": 69, "71683fi": 69, "716i": 69, "71764317e": 33, "71770240e": 33, "718": [15, 68, 69], "71808079e": 33, "718superb": 15, "719": 69, "71916054e": 33, "71919542e": 33, "719table0": 69, "72": [68, 74], "720": 38, "72038257e": 33, "72092204": 72, "72092316": 72, "720e": 56, "721": 56, "72130722": 72, "72133589": 72, "7213366": 72, "721336f": 72, "72134": 74, "72134base": 74, "722": [68, 74], "72244": 68, "72244f": 68, "72253": 68, "72253base": 68, "722620base": 15, "722orns0": 68, "723": [68, 69], "72369": 74, "72369base": 74, "72377680e": 33, "723orns1": 68, "724": 56, "72401183e": 33, "725": [69, 70], "7250": 69, "725186": 37, "72599531e": 33, "726": 76, "72617563e": 33, "727": [68, 69, 73], "72717": 69, "72717base": 69, "727hopeless": 73, "727the": 69, "728": 77, "72801761e": 33, "729": [68, 69], "72900041e": 33, "7291": 15, "7293": 68, "729354": 15, "729354f": 15, "7293base": 68, "72940012e": 33, "7299": 68, "7299f": 68, "729table0": 69, "72m": 51, "73": 74, "7309": 77, "7309base": 77, "731": [68, 74], "731330": 38, "73137": 70, "73137fjoi": 70, "73138": 73, "73138fjoi": 73, "7314": 68, "7314base": 68, "731919": 37, "732": 68, "732184": 38, "73271954e": 33, "732orns0": 68, "733": [72, 77], "733lp9": 77, "734": 69, "734todai": 69, "735": [69, 74], "735161": 76, "735161fi": 76, "73546228e": 33, "73567": 69, "73567fand": 69, "735and": 69, "735i": 69, "736": [68, 69, 70], "7360": 71, "73615": 76, "73615f": 76, "73619": 77, "73619fmodelo": 77, "7365037830677591e": 52, "736humiliated0": 70, "736what": 69, "737": [74, 77], "73706532e": 33, "73798": 68, "73798base": 68, "738": 68, "73833750e": 33, "7384": 76, "73842219e": 33, "7384fin": 76, "739": 68, "7396": [59, 76], "7396base": 76, "73980646e": 33, "73m": [51, 74], "74": [51, 68, 69], "74004652e": 33, "74015139e": 33, "741": [68, 69, 70], "74153834e": 33, "741feel": 70, "741orns1": 68, "742": [68, 70], "74207263e": 33, "74227796e": 33, "742greedi": 70, "743": [68, 74], "7439490": 77, "743949fantiguo": 77, "743base": 68, "744": [69, 77], "7443": 68, "74437363e": 33, "7443base": 68, "74475": 76, "74475ftheir": 76, "744what": 69, "745": 69, "745926": 77, "745926base": 77, "74597": 69, "74597base": 69, "74597ftabl": 69, "746": 77, "74651941e": 33, "74662": 77, "74662base": 77, "748": [68, 77], "7482e": 56, "749": [69, 74, 77], "74987503e": 33, "749i": 69, "74m": 51, "74orns0": 68, "74what": 69, "75": [24, 47, 51, 67, 73, 76], "750": 52, "75147157e": 33, "75166926e": 33, "7517": 68, "7517base": 68, "75202565e": 33, "75254655e": 33, "75295805e": 33, "753": [69, 77], "75361225e": 33, "75361261e": 33, "7539": 53, "753what": 69, "754": [68, 77], "75400544e": 33, "7540e": 56, "754683": 69, "75468fmy": 69, "75474": [70, 73], "7547fanger": [70, 73], "754orns0": 68, "755": [59, 69], "75504149e": 33, "756": [68, 77], "75696": 74, "75696base": 74, "757": [68, 69, 73, 77], "75755": 68, "75755f": 68, "75757751e": 33, "757hopeless": 73, "758": [69, 74, 76], "75858896e": 33, "75865619e": 33, "758699": 77, "758699base": 77, "758table0": 69, "759": [68, 69, 73], "759humili": 73, "759what": 69, "75greedi": 73, "76": [11, 76, 77], "7600": 57, "7607": 51, "76084475e": 58, "76084566e": 58, "76087164e": 33, "761": [68, 69], "76116576e": 33, "76131": 73, "76131base": 73, "76169444e": 33, "761my": 69, "7623": 75, "76321148e": 33, "764": 68, "76445": 69, "76445base": 69, "76475863e": 33, "76549394e": 33, "7657": 32, "766": 74, "766082": 74, "76608base": 74, "7663": 77, "7663base": 77, "7664": 68, "7664f": 68, "767": [70, 74], "76709506e": 33, "7673550": 74, "767355fwelsh": 74, "767greedi": 70, "768": 69, "768011": 74, "76801fchairman": 74, "7683716e": 52, "76886606e": 33, "768tabl": 69, "769": 69, "76972214e": 33, "7699": 32, "76it": 72, "77": [23, 64, 68], "770179": 64, "77018": 76, "77018base": 76, "77027574e": 33, "771": 70, "771891": 77, "77189fr\u00e1pidament": 77, "771hopeless": 70, "772": 68, "772base": 68, "773": 69, "77343885e": 33, "773tabl": 69, "77434": 76, "77434flove": 76, "775": [15, 68], "77507783e": 33, "776": [68, 73], "77634486e": 33, "77659339e": 33, "77661893e": 33, "776humili": 73, "777": [69, 74], "77738373e": 33, "77788815e": 33, "778": [68, 75], "77811": 68, "77811base": 68, "778orn": 68, "779": [68, 76], "77940441e": 33, "77983743e": 33, "77orns0": 68, "78": [11, 47, 69], "7800e": 56, "7806": 68, "7806base": 68, "7807650": 77, "780765flo": 77, "78086266e": 33, "78088": 70, "78088base": 70, "781": [68, 74, 76], "78152613e": 33, "78153806e": 33, "78181485e": 33, "782": [51, 68], "78233521e": 58, "7825": 71, "78262809e": 58, "78296075e": 33, "783": 77, "78326": 69, "78326base": 69, "78349799": 8, "78452": 76, "78452fthei": 76, "78574": 74, "78574base": 74, "78596678e": 33, "786": 68, "787": [68, 69, 77], "78703503e": 33, "78715834e": 33, "7873": 59, "787orns1": 68, "788": 77, "788038": 64, "7887": 68, "78874": 77, "78874base": 77, "7887base": 68, "78m": 51, "78what": 69, "79": [51, 68, 70], "79018209e": 33, "79025": 74, "79025base": 74, "79037606e": 33, "79141953e": 33, "793": [68, 69, 74], "79309698e": 33, "79362061e": 33, "793cat": 69, "795": 74, "79535338e": 33, "795382": 74, "79538frugbi": 74, "796": [68, 76], "79636675e": 33, "7967": 68, "7967base": 68, "79754803e": 33, "798": 74, "799": 68, "79feel": 70, "7base": 74, "7m": 51, "7mani": 15, "7th": [30, 31], "8": [4, 6, 9, 11, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 32, 33, 36, 38, 39, 40, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 132], "80": [19, 23, 24, 38, 51, 63, 70, 71, 74], "800": 55, "8000": 63, "80011001e": 33, "80036": 76, "80036f": 76, "801": 69, "80130472e": 33, "80155170e": 33, "80166": 68, "80166f": 68, "801what": 69, "8020": 15, "80203": 68, "80203base": 68, "8021": 59, "8024": 77, "8024214": 15, "803": 68, "803861": 77, "80386f": 77, "804": [68, 69], "804691": 69, "804691base": 69, "8048": 74, "80481": [70, 73], "80481fsurpris": [70, 73], "8048base": 74, "8049": 51, "804cat": 69, "804orns0": 68, "804what": 69, "80635159e": 33, "80639011e": 33, "80652621e": 33, "8070e": 56, "8074": 59, "80747423e": 33, "8076": 68, "8076base": 68, "80798": 69, "807985": 64, "80798base": 69, "809": 74, "8090183": 15, "8091": 71, "80911": 74, "80911103e": 33, "80911base": 74, "80912": 71, "809221": 76, "809221base": 76, "80950242e": 33, "8096": 71, "80983": 69, "80983base": 69, "80m": 51, "81": [48, 64, 68, 69], "810": 70, "81001033e": 33, "810357": 69, "810357base": 69, "8106": 71, "811": 76, "811076": 76, "811076fever": 76, "811387829626835": 52, "8117": 71, "812": 74, "81214471e": 33, "8123": 71, "8126": 71, "8128": 71, "81299256e": 33, "813": [73, 74], "8130": 53, "81379146e": 33, "813feel": 73, "814": [28, 74, 77], "8140": 74, "8141": 74, "8142": 74, "8145": 71, "81493106e": 33, "815": 68, "815base": 68, "816": [68, 69, 70, 77], "8169": 71, "81690009e": 33, "816911": 77, "81691ftransformador": 77, "816former": 77, "816greedi": 70, "816orns1": 68, "816what": 69, "817": 77, "8170": 75, "817035332310394": 63, "8172": 68, "81726": 74, "81726base": 74, "8172base": 68, "8177": 71, "8180": 71, "81831": 68, "81831f": 68, "81886": 68, "81886f": 68, "819": 69, "81938729e": 33, "819951": 74, "81995frugbi": 74, "819what": 69, "81m": 51, "81the": 69, "82": [68, 74], "82023": 70, "82023base": 70, "82061548e": 33, "82069867e": 33, "821": 69, "82113149e": 33, "821492": 15, "823": 77, "8230": 15, "82338935e": 33, "8234": 51, "8240": 71, "82438840e": 33, "8246": 71, "825": 77, "826": [32, 68, 77], "82612066e": 33, "82618242e": 33, "826u": 47, "827": [69, 74, 77], "82756392e": 33, "8279": 71, "827table0": 69, "828": [68, 77], "8280893": 15, "82871279e": 33, "82875578e": 33, "829": 68, "82900709e": 33, "82931762e": 33, "82971": 74, "82971fa": 74, "829orns0": 68, "82m": 51, "82the": 15, "83": 51, "8300": 71, "83015407e": 33, "831": 68, "83104083e": 33, "832": 15, "83280281e": 33, "833": [68, 69], "8330": [51, 71], "833orns0": 68, "833the": 69, "834": [68, 69], "834451": 77, "83445fde": 77, "834946": 37, "834i": 69, "834orns0": 68, "8351720": 74, "835172f": 74, "83597527e": 33, "836": 15, "837": 68, "838": [15, 68, 69], "83802091": 8, "838162": 77, "838162base": 77, "83896496e": 33, "838what": 69, "839": [68, 69], "8395": 38, "83982721e": 33, "83987": 69, "83987ffloor": 69, "839what": 69, "84": [24, 43, 68], "8406610": 74, "840661base": 74, "84131012e": 33, "84185": 76, "84185f": 76, "842": 68, "84216580e": 33, "84234": 73, "84234base": 73, "8425": 76, "8425f": 76, "8427": 68, "8427f": 68, "843": [14, 73], "843greedi": 73, "844": 68, "844245": 64, "84463": 77, "84463base": 77, "845": [68, 69, 77], "84550682e": 33, "84557885e": 33, "845i": 69, "845orns0": 68, "846": 74, "84655980e": 33, "84707": 68, "84707f": 68, "847191": 64, "84794": 69, "84794base": 69, "848": [68, 70, 74], "84802": 69, "84802base": 69, "84828204": 8, "8485": 51, "84897833e": 33, "848hopeless": 70, "849": 73, "84969807e": 33, "84980168e": 33, "849feel": 73, "849greedi": 73, "84in0": 68, "85": [24, 37, 39, 43, 48, 68, 69, 76], "85001": 69, "85001fthe": 69, "85043": 69, "85043fi": 69, "85078": 69, "85078base": 69, "851": 68, "8516": 68, "8516base": 68, "852": 77, "852082": 74, "85208base": 74, "852275": 69, "852275base": 69, "85255765e": 33, "853": [68, 74], "8531": 68, "85317978e": 33, "8531base": 68, "85346958e": 33, "8538": 77, "8538base": 77, "855": [68, 70], "85521979e": 33, "85566168e": 33, "855humiliated0": 70, "856": 68, "8563": 68, "8563base": 68, "857": 15, "857841": 77, "85784fnal": 77, "858": 68, "8581053": 15, "85896521e": 33, "85896822": 8, "858orns0": 68, "859": 68, "85921": 68, "85921f": 68, "85932173e": 33, "85977016e": 33, "85978739e": 33, "85tabl": 69, "86": [24, 69], "86057645e": 33, "861": [75, 77], "8610": 15, "86151311": 8, "86159959e": 33, "86202475e": 33, "86406018e": 33, "8644150": 74, "864415f": 74, "865": [68, 69], "8657": 51, "86593557e": 33, "865table0": 69, "866": 69, "86757010e": 33, "86796489e": 33, "868": 74, "868269": 69, "868269base": 69, "86884": [70, 73], "86884fsurpris": [70, 73], "86936624e": 33, "86966406e": 33, "869925": 76, "869925fbe": 76, "86994192e": 33, "87": [29, 32, 51, 68], "870": 15, "870e": 56, "871": [68, 69, 77], "87110184e": 33, "8717": 51, "871what": 69, "872": 69, "872254": 64, "87227430e": 33, "87230679e": 33, "87276634e": 33, "872cat": 69, "872todai": 69, "873": [68, 69, 76], "873i1": 76, "873on": 69, "874": 69, "87449579e": 33, "875": [52, 67, 69, 77], "87516066e": 33, "8752": 71, "87520718e": 33, "87570893e": 33, "875832": 74, "87583fdavi": 74, "875what": 69, "87711974e": 33, "8777": 68, "8777base": 68, "878": [15, 68, 69], "88": [26, 48, 74], "8808": 68, "8808base": 68, "88093021e": 33, "880e": 56, "88102460e": 33, "88112425": 75, "881162": 74, "88116fm": 74, "88136": 76, "88136base": 76, "88145": 68, "88145f": 68, "882": [68, 69, 73], "88242": 68, "88242base": 68, "882table0": 69, "882wrong": 73, "883": 69, "883250": 64, "883383": 76, "883383base": 76, "88358642e": 33, "883saw": 69, "883what": 69, "884": 74, "8841": 68, "8841base": 68, "885": [68, 72, 74], "88550509e": 33, "886": [68, 69], "88626": 70, "88626base": 70, "886433": 69, "886433base": 69, "88692890e": 33, "886table0": 69, "88707030e": 33, "8875066": 15, "887642": 74, "88764f3": 74, "8877": 68, "8877base": 68, "88849764e": 33, "88888": 76, "88888ftheir": 76, "88945584e": 33, "88978534e": 33, "89": [32, 45, 68], "89027": 68, "89027f": 68, "89033": 77, "89033base": 77, "89046846e": 33, "89048231e": 33, "891": 68, "89146267": 49, "8915": 59, "892": 68, "8921210": 77, "892121fle": 77, "89242372e": 33, "893": 68, "893042": 77, "89304flp": 77, "894": 68, "89436760e": 33, "895": [69, 74], "8952": 47, "895209312438965": 47, "895e": 56, "895what": 69, "89607745e": 33, "89655": 76, "89655fbut": 76, "897": [68, 77], "89713420e": 33, "898": [68, 69], "8980392156862745": 55, "89821274e": 33, "89823142e": 33, "89837": 76, "89837base": 76, "899": [73, 77], "899feel": 73, "8a": 15, "8film": 15, "8i": 15, "8m": 51, "8my": 15, "8orns1": 68, "8recent": 74, "8satir": 15, "8underr": 15, "8wru": 74, "9": [9, 11, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 32, 33, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 62, 63, 64, 65, 67, 68, 69, 71, 72, 74, 75, 76, 77], "90": [9, 14, 17, 23, 24, 32, 37, 51, 53, 70, 74], "900": 55, "9000": 63, "90000": 40, "90017478e": 33, "9006": 37, "90099cb476936b753383ba2ae6ab2eae419b2e87f71cd5189cb9c8e5814d12a3": 72, "901": [68, 70], "901humiliated0": 70, "902": [68, 69], "902i": 69, "903": 77, "9040": 15, "90419": 76, "90419fthe": 76, "9049780": 77, "904978fsont": 77, "905": [68, 69], "90513470e": 33, "9054": 51, "90565134e": 33, "90597994e": 33, "905what": 69, "906": 69, "90601801e": 33, "906i": 69, "907": 77, "90742142": 72, "90780458": 72, "908": [69, 77], "90845807e": 33, "90883": 69, "90883base": 69, "908former0": 77, "908what": 69, "909": 15, "91": [24, 32, 53, 68, 76, 77], "910": 70, "91016507e": 33, "91018353e": 33, "91035": 77, "91035base": 77, "91046": [70, 73], "91046flove": [70, 73], "910631": 77, "91063fconvertido": 77, "9107": 71, "91077": 69, "91077fon": 69, "911": 69, "91111821e": 33, "9119": 68, "9119base": 68, "911what": 69, "912": 70, "91258034e": 33, "9129": 71, "912greedi": 70, "913": [68, 69], "91337": 68, "91337base": 68, "91392294e": 33, "913table3": 69, "914": [69, 70], "9145": 68, "91455300e": 33, "9145base": 68, "91469": 69, "91469base": 69, "91492": 68, "91492f": 68, "914hopeless": 70, "915": [15, 73], "91534": 76, "91534fvodka": 76, "91546879e": 33, "91574595e": 33, "91575": 69, "91575base": 69, "91578195e": 33, "915hope": 73, "916": [68, 69], "91639676e": 33, "91689895e": 33, "9169083": 15, "917": [68, 74], "91744": 68, "91744f": 68, "918": [69, 74], "918599": 64, "918the": 69, "919": 68, "91921": 74, "91921fplayer": 74, "91966484e": 33, "919orns0": 68, "91m": 51, "92": [32, 53, 74, 77], "92042911e": 33, "92099867e": 33, "921": 68, "92132593e": 33, "92188854e": 33, "921997": 69, "92199fcat": 69, "921orns0": 68, "92200624e": 33, "92248": 76, "92248f": 76, "923": 77, "924": [75, 77], "924lp0": 77, "92546": 68, "92546f": 68, "92587346e": 33, "926": 77, "92636347e": 33, "92682": 69, "92682f": 69, "92697": 69, "92697f": 69, "928": [68, 77], "928431": 77, "92843fel": 77, "929": 68, "929316": 76, "929316fi": 76, "92932855e": 33, "92m": 51, "93": [15, 64, 68, 74, 75], "931": 68, "931881": 64, "932": [68, 74], "93201": 69, "93201base": 69, "932base": 68, "933": [68, 74, 77], "93337468e": 33, "93349": 74, "93349base": 74, "933orns0": 68, "934": [15, 68, 77], "9341": 68, "9341base": 68, "93441359e": 33, "93447": 77, "93447base": 77, "935": 68, "935541": 64, "93592": 69, "93592fsaw": 69, "936672": 70, "936672base": 70, "93690444e": 33, "937": 69, "93702": 76, "93702fvodka": 76, "9377": 37, "938981": 74, "93898base": 74, "939": [68, 72], "93993": 68, "93993base": 68, "939base": 68, "93m": 51, "94": [33, 37, 51, 68], "94002078e": 33, "9410": 15, "94108": 68, "94108f": 68, "943": 69, "94323089e": 33, "9433": 71, "94354588e": 33, "943what": 69, "944": 74, "94423": 68, "94423f": 68, "945": [68, 77], "945222": 74, "94522f": 74, "946": [59, 68], "9467": 77, "94670346e": 33, "94676409e": 33, "9467base": 77, "94690569e": 33, "946orns0": 68, "947": [15, 68], "9474": 51, "948": 15, "94869": 76, "94869fthei": 76, "949": [68, 77], "94985": 70, "94985base": 70, "94998263e": 33, "94orns1": 68, "95": [14, 24, 40, 56, 64, 69, 74, 75], "950005": 52, "950195": 52, "95064305e": 33, "9507": 36, "951": [68, 73], "951didnt": 73, "951f": 68, "952": 68, "95220253e": 33, "95267": 69, "95267fsaw": 69, "95320933e": 33, "95337387e": 33, "953806": 76, "953806fif": 76, "954": 68, "9542": 40, "955": 77, "9553": 71, "9563470": 77, "956347fr\u00e9current": 77, "95697": 77, "95697base": 77, "9576": 71, "95772947e": 33, "95794592e": 33, "958": 15, "95842": 69, "95842fwhen": 69, "958societi": 15, "95909999e": 33, "95m": 51, "95th": 14, "95what": 69, "96": [46, 51, 68, 76], "9607843137254902": 55, "9610": 15, "96114665e": 33, "9615": 71, "9616": 32, "961931": 69, "96193ftabl": 69, "962": [56, 68], "9620": 15, "96217": 63, "96240": 63, "96258763e": 33, "9631": 38, "9634": 71, "964": [68, 69], "96409": 70, "96409base": 70, "9643": 74, "9643base": 74, "964my": 69, "965": 77, "96507452e": 33, "96517725e": 33, "96558": 63, "966": 68, "96635447e": 33, "967": 73, "9676": 68, "9676base": 68, "967hope": 73, "96910370e": 33, "96952": 76, "96952base": 76, "96964378e": 33, "96995": 63, "97": [40, 74], "97027315e": 33, "971": 69, "9713230": 77, "971323fle": 77, "9715": 69, "9715base": 69, "9716": 77, "9716base": 77, "97170162e": 33, "97193": 69, "97193f": 69, "971what": 69, "972": 75, "9720": [40, 71], "97241551e": 33, "973": [68, 76], "97310": 63, "97334204e": 33, "9737": 32, "9746": 71, "97516": 63, "9753": 68, "9753base": 68, "976": 69, "9760": 51, "97622352e": 33, "97690518e": 33, "976i": 69, "977": 15, "97721": 63, "97735872e": 33, "977471": 77, "97747base": 77, "97764": 77, "97764base": 77, "9788": 32, "97925": 69, "97925fgot": 69, "9794": 40, "979473": 69, "97947ffrog": 69, "9795": 15, "97952": 68, "97952base": 68, "98": [10, 11, 21, 38, 40, 48, 50, 73, 74, 77], "9801": 36, "98024783e": 33, "98092088e": 33, "981": [68, 77], "98116": 63, "981580": 64, "98166245e": 33, "98182499e": 33, "98232539e": 33, "98265023e": 33, "98322945e": 33, "98353": 68, "98353base": 68, "9838": 51, "98393560e": 33, "984": [59, 73], "98432": 69, "98432fi": 69, "9847000241279602": 32, "984hope": 73, "98511": 63, "98516776e": 33, "9852": 36, "9853": 32, "9854": 71, "986": [68, 77], "9862": 32, "986371": 70, "986371base": 70, "98699151013147": 45, "98719892e": 33, "98756400e": 33, "988": 68, "98832509e": 33, "989": 69, "98906486e": 33, "98935": 74, "98935base": 74, "9895": 71, "98951869e": 33, "989744": 47, "989what": 69, "98feel": 73, "99": [14, 17, 26, 32, 39, 50, 68, 75], "9909": 71, "991": [68, 77], "9914620": 70, "991462fanger": 70, "991486": 69, "991486fon": 69, "992395": 64, "9925": 69, "9925base": 69, "993e": 56, "994": [68, 77], "99473783e": 33, "9949": 71, "9952920": 70, "995292fsad": 70, "9954": 71, "99575167e": 33, "99599": 68, "99599base": 68, "996": [68, 69], "99616620e": 33, "9962": 71, "9964": 71, "9964080": 70, "996408fsad": 70, "99644450e": 33, "996orn": 68, "9970": [53, 71], "99766242e": 33, "9977812170982361": 72, "99778122": 72, "998": 77, "99800031e": 52, "99879652": 72, "9987965226173401": 72, "999": [52, 68], "9994": 76, "9994fthei": 76, "9996": 40, "99970001": 52, "99970007": 52, "999756": 52, "99977983e": 33, "9998671e": 57, "99989998": 52, "9999": 63, "9aadb769735c60eb90f7d3d896632ac749a1bdd2": 25, "9and": 15, "9be": 15, "9it": 38, "9m": [15, 51], "9some": 15, "9student": 15, "9thi": 15, "9what": 15, "A": [3, 7, 11, 14, 15, 25, 32, 37, 44, 50, 54, 55, 62, 63, 64, 69, 70, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 96, 98, 100, 105, 106, 107, 109, 110, 113, 118, 122, 123, 124, 126, 128, 131, 132, 136, 137, 138, 140, 141, 143, 148, 151], "AND": 25, "And": [14, 40, 43, 52, 53, 74], "As": [8, 39, 40, 43, 59, 78, 81, 82, 85, 86, 87, 88, 89, 90, 105, 106, 107, 108, 109, 110], "At": [3, 11, 43, 53, 98], "Be": [158, 159], "Being": 43, "But": [15, 26, 27, 38, 39, 40, 43, 46, 53, 74], "By": [6, 9, 10, 11, 12, 13, 16, 26, 27, 29, 33, 34, 35, 36, 38, 40, 43, 50, 62, 68, 79, 80, 81, 82, 84, 86, 87, 90, 91, 105, 106, 107, 108, 109, 110, 122, 123, 124, 125, 126, 127, 128, 132, 138, 140], "For": [3, 9, 11, 14, 20, 26, 27, 38, 39, 40, 56, 62, 66, 67, 74, 76, 79, 81, 82, 84, 85, 86, 87, 89, 90, 91, 105, 106, 107, 108, 109, 110, 123, 127, 128, 130, 140, 144, 147, 152], "If": [3, 5, 9, 10, 11, 14, 15, 16, 20, 26, 27, 38, 39, 40, 42, 43, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 66, 67, 71, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 101, 102, 103, 107, 110, 114, 116, 119, 120, 126, 127, 128, 129, 130, 132, 138, 139, 140, 147], "In": [3, 4, 6, 8, 9, 10, 11, 14, 15, 18, 19, 21, 22, 23, 24, 27, 28, 29, 32, 33, 38, 39, 40, 46, 52, 53, 54, 55, 56, 57, 59, 60, 62, 65, 68, 69, 70, 73, 74, 76, 77, 82, 84, 86, 87, 90, 91, 105, 106, 107, 108, 109, 110, 122, 123], "It": [3, 6, 7, 9, 10, 11, 12, 14, 15, 16, 17, 26, 29, 30, 31, 33, 38, 39, 40, 43, 44, 48, 50, 54, 55, 57, 59, 63, 74, 77, 78, 81, 82, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 122, 123, 124, 130, 131, 133, 138, 153, 158], "Its": 15, "NOT": [38, 74, 75, 77], "No": 43, "Not": 84, "OR": 161, "On": [3, 5, 15, 56, 65], "One": [38, 39, 54, 55, 134], "Or": [3, 15, 79, 128], "That": [15, 17, 39], "The": [1, 3, 4, 6, 8, 9, 10, 11, 12, 14, 15, 17, 18, 21, 22, 23, 24, 25, 26, 27, 32, 37, 40, 42, 43, 47, 48, 50, 53, 54, 55, 57, 60, 61, 62, 63, 66, 67, 70, 71, 73, 74, 75, 76, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 119, 120, 122, 123, 124, 128, 129, 130, 132, 133, 138, 139, 141, 142, 147, 151, 153], "Then": 85, "There": [0, 11, 16, 26, 27, 29, 33, 39, 66, 74, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110], "These": [1, 2, 3, 11, 20, 38, 39, 40, 63, 66, 78, 81, 82, 86, 87, 88, 89, 90, 105, 106, 107, 108, 109, 110, 112, 119, 156, 157, 159, 161, 162], "To": [3, 8, 9, 11, 14, 17, 26, 27, 30, 31, 36, 37, 38, 39, 40, 42, 48, 51, 53, 54, 55, 60, 62, 70, 74, 76, 77, 78, 79, 81, 86, 89, 90, 93, 94, 95, 97, 98, 99, 101, 102, 160], "Will": 59, "With": [44, 63], "_": [26, 27, 37, 39, 64], "__": 15, "__call__": [27, 84, 89, 91], "__dict__": 39, "__fixed_var_dictionari": 39, "__init__": [3, 27, 32, 37, 39, 65, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 142, 143], "__setitem__": 39, "__version__": 64, "_arraylik": 147, "_arrayt": 153, "_ax": 138, "_build": 3, "_deep": 32, "_explan": [79, 132, 138], "_forest": 65, "_hierarchy_po": 48, "_imag": 33, "_masker": [78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110], "_match": 62, "_max_bin_with_test_s": 64, "_model": [78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110], "_sequenti": 21, "_stat": 62, "_x": 75, "a0": 68, "a1": 68, "a2": 68, "a4": 68, "a8ab9da52fd159aae6477b5ede6eaaec69fd130fa0fa59f283": 47, "aa34462255cd487d04be8387a2d572588f6ceee23f784f37365aa714afeb8fe6": [70, 73], "ab": [9, 10, 12, 14, 15, 38, 39, 52, 56, 62, 63, 75, 126, 127, 130, 132], "abacu": 33, "abaya": 33, "abcd": 79, "abil": [39, 54, 55, 89], "abl": [26, 38, 39, 40, 68, 72, 76], "abound": 43, "about": [3, 4, 6, 15, 19, 39, 40, 43, 46, 50, 57, 62, 72, 91, 116, 119, 131, 142], "abov": [3, 4, 5, 6, 12, 14, 15, 17, 25, 27, 29, 32, 33, 36, 37, 38, 39, 40, 47, 51, 53, 57, 59, 62, 63, 66, 67, 69, 70, 80, 85, 86, 90], "absent": 43, "absolut": [3, 9, 10, 12, 14, 16, 20, 27, 38, 43, 53, 80, 85, 126, 129, 139], "abstract": [2, 19, 78, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 162], "academic_gown": 33, "acc": 71, "acceler": [5, 84], "accept": [8, 26, 86], "access": [8, 26, 27, 40, 47, 79], "accid": 43, "accomplish": 3, "accord": [63, 84, 91, 120], "accordingli": [11, 122, 123, 124], "accordion": 33, "account": [40, 54, 55, 57, 87, 88, 89], "accur": [9, 11, 36, 39, 40, 66, 80], "accuraci": [9, 32, 36, 37, 43, 46, 56, 71, 89], "accus": 15, "ace_linewidth": 137, "ace_opac": 137, "acend": 70, "acheiv": 46, "achiev": 93, "aclimdb_v1": 99, "aclweb": 99, "acorn": 33, "acorn_squash": 33, "acoustic_guitar": 33, "across": [2, 11, 38, 39, 44, 53, 54, 55, 59, 61, 79, 108, 153], "act": [15, 43], "action": [3, 39, 53, 63], "activ": [3, 32, 36, 39, 47, 48, 51, 71], "actor": 72, "actual": [25, 39, 40, 43, 47, 62, 66, 71, 74, 77, 79, 83, 87, 143], "ad": [3, 11, 14, 33, 38, 39, 48, 50, 62, 84, 91, 96, 100], "adam": [32, 36, 47, 51, 71], "adapt": 85, "add": [3, 5, 6, 7, 9, 10, 12, 13, 15, 16, 17, 20, 29, 30, 31, 33, 34, 35, 38, 41, 44, 47, 52, 60, 68, 69, 70, 71, 73, 74, 75, 76, 77, 138], "add_edg": 48, "add_nod": 48, "add_nodes_edg": 48, "add_sample_imag": [26, 27], "addit": [11, 20, 31, 44, 66, 70, 72, 78, 81, 82, 86, 87, 89, 90, 105, 106, 107, 108, 109, 110, 130, 138, 158], "addiv": [70, 73], "address": 40, "adher": 3, "adjust": [9, 10, 11, 16, 39, 48], "admir": 33, "admit": [72, 74], "adult": [4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 17, 20, 38, 44, 51, 54, 55, 56, 57, 58], "advanc": 11, "advantag": [47, 62, 66, 71], "advertis": 39, "advis": 3, "affect": [39, 53, 57], "affenpinsch": 33, "afghan_hound": 33, "african_chameleon": 33, "african_crocodil": 33, "african_eleph": 33, "african_grei": 33, "african_hunting_dog": 33, "after": [3, 7, 15, 16, 27, 39, 43, 66, 71, 72, 74, 86, 90, 97, 126, 127, 128, 130, 132, 133, 138, 140, 141], "ag": [10, 11, 14, 15, 38, 51, 53, 54, 55, 63, 93, 94, 97], "again": [9, 15, 41], "against": [39, 62, 72], "agama": 33, "agar": 33, "aggreg": 138, "agnost": [4, 6, 7, 9, 45, 47, 74, 88, 89, 122, 123, 157, 158], "agre": [3, 43], "agreement": [15, 39], "ahead": 74, "ai": [40, 84, 91, 99, 158, 159], "aic": [86, 90], "aim": 3, "aircraft_carri": 33, "airedal": 33, "airlin": 33, "airship": 33, "al": 85, "albatross": 33, "alcohol": 43, "algebra": 42, "algorithm": [62, 64, 65, 74, 80, 82, 86, 87, 90, 91, 105, 106, 107, 108, 109, 110, 122], "align": [26, 27, 42, 114], "all": [2, 3, 4, 6, 9, 11, 12, 13, 15, 16, 17, 25, 26, 27, 34, 35, 36, 38, 39, 40, 42, 44, 47, 48, 53, 54, 55, 57, 59, 61, 63, 64, 66, 67, 71, 79, 80, 82, 84, 85, 86, 87, 89, 90, 91, 105, 106, 107, 108, 109, 110, 111, 112, 116, 117, 119, 121, 127, 128, 129, 130, 138, 139, 141, 143, 156, 157, 161, 162], "all_mask": 146, "allclos": 48, "alligator_lizard": 33, "alloc": [38, 40, 48, 57, 158], "allow": [4, 6, 11, 12, 16, 39, 40, 44, 47, 48, 54, 55, 63, 89, 116, 119, 120, 126, 127, 128, 130, 132, 133, 138, 140, 141], "allstat": 62, "allstats_orig": 62, "almost": 40, "alon": [3, 11], "along": [10, 26, 27, 32, 37, 101, 113, 118, 138, 144, 152], "alp": 33, "alpha": [13, 14, 18, 19, 22, 23, 24, 34, 35, 39, 45, 46, 48, 55, 75, 86, 90, 127, 128, 129, 138, 140], "alreadi": [15, 25, 26, 27, 39, 43, 47, 57, 64, 65], "also": [0, 3, 4, 5, 6, 9, 11, 12, 15, 16, 17, 20, 21, 26, 27, 29, 31, 33, 36, 38, 39, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 66, 67, 68, 70, 71, 74, 76, 79, 81, 82, 86, 87, 89, 90, 105, 106, 107, 108, 109, 110, 138], "altar": 33, "alter": 11, "altern": [3, 7, 26, 27, 29, 33, 40, 87, 90, 138], "alwai": [6, 11, 26, 27, 36, 38, 39, 40, 54, 55, 62, 66, 67, 74, 80, 82, 84, 85, 86, 87, 88, 90, 91, 105, 106, 107, 108, 109, 110], "amaa": 99, "amaz": 43, "amazon": 53, "amazonaw": [13, 18, 19, 28, 29, 30, 31, 33, 34, 35], "ambul": 33, "american": [29, 33, 72, 76], "american0": 76, "american_allig": 33, "american_black_bear": 33, "american_chameleon": 33, "american_coot": 33, "american_egret": [28, 33], "american_lobst": 33, "american_staffordshire_terri": 33, "among": [9, 15, 38, 40, 57, 63, 65, 67, 70, 71, 74, 87, 96, 131], "amount": [14, 40, 50, 54, 55, 74, 84, 91, 128], "amp": 43, "amphibian": 33, "amplitud": 11, "amus": 43, "an": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 28, 29, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 47, 48, 50, 52, 53, 54, 55, 56, 61, 62, 63, 66, 67, 68, 69, 71, 75, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 138, 139, 141, 143, 157, 158, 159], "anaconda3": 59, "analog_clock": 33, "analysi": [15, 38, 39, 40, 99, 103, 158, 161], "analyst": 11, "analyz": [26, 53, 63], "analyze_url": 26, "anchor": 15, "anchor_first": 148, "ancien": 77, "and_fb_model": 67, "and_model": 67, "anemone_fish": 33, "anger": [70, 73], "angora": 33, "ani": [3, 4, 5, 6, 7, 10, 11, 14, 15, 17, 19, 26, 27, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 54, 55, 59, 62, 71, 73, 76, 81, 82, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 119, 122, 123, 124, 128, 132, 138, 139, 142, 158], "ann": 15, "annual": [12, 14, 17, 44, 54, 55], "anomali": 11, "anoth": [11, 14, 39, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 59, 60, 61, 62, 70, 71, 73, 75, 87], "answer": [40, 78, 158], "ant": 33, "anthologi": 99, "antiguo": 77, "antithet": 89, "anyth": [15, 66], "anywher": [84, 91], "apart": [71, 120], "api": [18, 21, 22, 23, 24, 73, 120, 158], "api_kei": 26, "apiari": 33, "apim": 26, "appar": 66, "appear": 20, "append": [11, 26, 27, 39, 51, 64, 69, 73, 75, 113, 118], "appenzel": 33, "appli": [11, 14, 20, 38, 39, 40, 41, 42, 47, 60, 78, 80, 83, 85, 87, 112, 143, 156, 157, 161, 162], "applic": [4, 6, 13, 18, 19, 26, 29, 30, 33, 34, 35, 40, 62, 130], "appoxim": 6, "approach": [4, 9, 11, 26, 27, 38, 39, 42, 63, 66, 69, 84, 87, 91, 158], "appropri": [3, 6, 29, 33, 37, 38, 39, 40, 87], "approx": 20, "approxim": [4, 6, 11, 20, 39, 49, 51, 74, 80, 84, 85, 86, 89, 90, 91, 105, 109, 122], "approximate_interact": [14, 138], "apron": 33, "apt": [3, 5], "ar": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 93, 96, 98, 100, 101, 105, 106, 107, 108, 109, 110, 111, 112, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130, 131, 133, 138, 139, 140, 141, 156, 157, 159, 160, 161, 162], "arabian_camel": 33, "arbitrari": [11, 47, 67, 86, 90, 128, 161], "arbitrarili": 39, "architectur": 75, "archiv": 95, "arctic_fox": 33, "are0": 76, "are2": 76, "area": [3, 14, 48], "aren": [86, 90], "arg": [39, 111, 113, 117, 118, 142], "argmax": [11, 28], "argpartit": 11, "argsort": [13, 14, 18, 19, 28, 29, 33, 34, 35, 56, 62, 63, 70, 72, 132], "argu": 57, "argument": [7, 11, 14, 17, 80, 84, 85, 89, 91, 111, 112, 115, 117, 119, 121, 122, 123, 124, 125, 128, 130, 138], "argwher": 69, "aris": [81, 87], "armadillo": 33, "around": [5, 11, 12, 18, 21, 22, 23, 24, 51, 66, 70, 73, 96, 100, 128, 133], "arrai": [8, 18, 19, 25, 26, 27, 28, 33, 39, 47, 50, 51, 52, 56, 57, 58, 65, 67, 69, 71, 72, 74, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 101, 105, 106, 107, 108, 109, 110, 114, 119, 122, 123, 124, 128, 129, 130, 131, 132, 133, 134, 136, 139, 140, 147, 151, 153], "arrang": [3, 11], "arriv": 11, "arrow": [39, 48], "art": [54, 55], "artichok": 33, "articl": [39, 40], "artifici": [84, 91], "arxiv": [54, 55, 80], "as_list": 32, "ascend": [11, 128], "ashcan": 33, "ashton": 72, "asian": 43, "ask": 76, "aspect": [14, 26, 33, 39, 40, 55, 133], "assault_rifl": 33, "assembl": 11, "assert": [25, 56, 64, 65], "assign": [3, 11, 15, 39, 88, 112, 139], "assist": 62, "associ": 120, "assum": [3, 9, 26, 27, 39, 40, 42, 43, 69, 78, 80, 87, 119, 128], "assumpt": [26, 27, 39, 40, 42, 90, 91], "asteroid": 76, "asteroid0": 76, "asteroid2": 76, "astyp": [19, 32, 36, 55, 62, 64, 65], "aten": [74, 77], "ates": 75, "attach": [40, 69], "attempt": [3, 9, 14, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110, 142], "attent": [39, 43, 122, 123, 124], "attention_mask": [24, 73], "attribut": [6, 8, 15, 20, 30, 31, 32, 37, 40, 48, 54, 56, 70, 71, 74, 79, 80, 82, 83, 84, 85, 86, 87, 89, 90, 91, 105, 106, 107, 108, 109, 110, 112, 120, 138, 142], "attributeerror": 32, "auc": [18, 19, 22, 23, 24, 75], "august": 74, "aumann": 85, "australian": 76, "australian0": 76, "australian_terri": 33, "author": [3, 47], "auto": [3, 9, 15, 16, 48, 51, 73, 82, 83, 84, 86, 87, 88, 90, 91, 105, 106, 107, 108, 109, 110, 114, 120, 126, 127, 133, 137, 138, 140, 147], "auto_size_plot": 128, "autom": 3, "automat": [3, 63, 128], "automodelforcausallm": [68, 76], "automodelforseq2seqlm": [15, 19, 22, 23, 26, 27, 74, 77], "automodelforsequenceclassif": [24, 70, 73, 75], "autonotebook": [48, 51], "autotoken": [15, 19, 22, 23, 24, 26, 27, 68, 70, 73, 74, 75, 76, 77], "avail": [0, 1, 2, 3, 11, 16, 26, 27, 29, 33, 37, 60, 63, 74, 82, 84, 86, 87, 88, 90, 105, 106, 107, 108, 109, 110, 156, 157, 159, 161, 162], "avantishri": 25, "avebedrm": [38, 48, 94], "aveoccup": [38, 48, 94], "averag": [7, 10, 11, 37, 38, 39, 40, 42, 44, 53, 55, 66, 67, 70, 78, 81, 82, 86, 87, 88, 89, 90, 94, 97, 105, 106, 107, 108, 109, 110, 120, 147], "averoom": [38, 48, 94], "avg": 43, "avoid": [9, 11, 27, 38, 39, 89, 116, 119], "avx2": [37, 38], "avx512f": 38, "awai": [38, 59], "await": 3, "awak": [70, 73], "awar": 74, "ax": [14, 19, 20, 26, 27, 38, 48, 51, 55, 126, 127, 128, 131, 132, 137, 138], "axhlin": 48, "axi": [11, 12, 14, 15, 17, 18, 19, 20, 25, 26, 27, 28, 31, 38, 39, 52, 53, 55, 62, 63, 66, 75, 114, 126, 127, 128, 132, 138, 141], "axis_color": [127, 128, 138, 140], "axolotl": 33, "azab": 48, "azur": 157, "b": [11, 32, 42, 50, 63, 74, 77, 138], "b3f55dfdb8af9812fdb9baf70cacf3b9e82e505b2bd4324d588888b81202": 47, "b6e1d69": 25, "b9": 47, "b98c3ef2fd6b": 33, "baboon": 33, "back": [41, 43, 74, 80], "backed_sandpip": 33, "backend": [30, 71], "background": [3, 8, 13, 15, 17, 32, 34, 35, 37, 38, 46, 48, 50, 54, 55, 56, 71, 72, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 98, 105, 106, 107, 108, 109, 110, 115, 116, 119, 141, 142, 153], "background_adult": 38, "backpack": 33, "backward": 37, "bad": [43, 62], "badger": 33, "bagel": 33, "bakeri": 33, "balanc": [4, 43, 48, 88], "balance_beam": 33, "bald_eagl": 33, "ball": 27, "balloon": 33, "ballplay": 33, "ballpoint": 33, "banana": 33, "band_aid": 33, "banded_gecko": 33, "banjo": 33, "bannist": 33, "bar": [1, 4, 5, 6, 8, 10, 12, 15, 38, 39, 40, 42, 45, 46, 54, 61, 63, 70, 76, 86, 90, 127, 128, 140], "barbel": 33, "barber_chair": 33, "barbershop": 33, "barn": [33, 68], "barn_spid": 33, "baromet": 33, "barracouta": 33, "barrel": [33, 43], "barren": 68, "barrow": 33, "bart": 162, "bart_label": 75, "bart_label_map": 75, "bartforsequenceclassif": 75, "base": [4, 5, 6, 12, 15, 16, 20, 24, 25, 26, 27, 38, 39, 40, 47, 49, 51, 53, 54, 55, 56, 57, 62, 63, 70, 73, 74, 84, 85, 86, 88, 90, 91, 96, 100, 113, 114, 115, 118, 122, 123, 124, 127, 128, 138, 140, 158], "base_offset": 56, "base_param": 64, "base_scor": [5, 52, 55, 59, 62], "base_valu": [8, 11, 12, 33, 38, 47, 49, 51, 52, 57, 75, 83, 128, 130], "basebal": 33, "baseestim": 39, "baselin": [38, 40, 97], "basenji": 33, "basic": [39, 59, 73, 137, 161], "basketbal": [26, 33], "basset": 33, "bassinet": 33, "bassoon": 33, "batch": [37, 71, 80, 122, 123, 124], "batch_ev": 89, "batch_idx": 37, "batch_siz": [13, 18, 19, 26, 27, 28, 29, 32, 33, 34, 35, 37, 38, 51, 71, 78, 81, 85, 87, 88, 89, 108, 122, 124, 142], "bath_towel": 33, "bathing_cap": 33, "bathroom": 15, "bathtub": 33, "bayonn": 74, "bb1102591c6230bd78813e229d5dd4c7fbf4fc478cec28f298761eb69e5b537c": 75, "bbc": 74, "beach_wagon": 33, "beacon": 33, "beagl": 33, "beaker": 33, "bearskin": 33, "beauti": 43, "beautifulli": 39, "beaver": 33, "becam": 74, "becaus": [4, 6, 11, 15, 26, 27, 29, 30, 31, 33, 38, 39, 40, 41, 43, 44, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 69, 71, 72, 89, 90, 98, 160], "becom": [16, 38, 39, 66, 77], "become0": 77, "become1": 77, "bedlington_terri": 33, "bedroom": [38, 94], "bee": 33, "bee_eat": 33, "been": [3, 5, 11, 15, 17, 26, 27, 29, 32, 33, 40, 43, 45, 46, 47, 50, 51, 53, 54, 55, 59, 60, 61, 62, 63, 71, 74, 116, 119, 126, 127, 128, 130, 132, 133, 138, 140, 141], "beer_bottl": 33, "beer_glass": 33, "beeswarm": [1, 7, 8, 38, 43, 44, 52, 53, 60, 61], "befor": [3, 5, 8, 10, 11, 14, 15, 17, 26, 38, 40, 43, 45, 46, 63, 126, 127, 128, 130, 132, 133, 138, 140, 141], "begin": [11, 39, 42, 43, 123], "behav": [38, 39, 59, 87, 88], "behavior": [11, 38, 40, 44, 59, 70, 74, 77, 80, 87, 136], "behaviour": [48, 84, 91, 153], "behind": [38, 66, 161], "behviour": 15, "being": [3, 15, 16, 26, 27, 29, 33, 38, 40, 43, 50, 57, 60, 63, 70, 72, 73, 74, 75, 86, 90, 111, 112, 115, 117, 121, 122, 123, 124, 125, 127, 133, 138, 140], "believ": [15, 43], "bell_cot": 33, "bell_pepp": 33, "below": [3, 4, 5, 6, 9, 10, 11, 12, 14, 15, 17, 26, 38, 39, 40, 43, 50, 53, 54, 55, 57, 59, 60, 62, 63, 68, 70, 73, 74, 76], "ben": 72, "bench": 27, "benchmark": [105, 108, 109, 158], "benefit": [54, 55], "bernese_mountain_dog": 33, "bernoulli": [39, 64], "bert": [15, 24, 38, 70, 73], "bertforpretrain": 75, "bertforsequenceclassif": 75, "best": [11, 15, 20, 26, 27, 39, 40, 43, 59, 72, 80, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110, 128], "best_score_": 11, "bet": 15, "beta": [42, 49, 59], "beta_i": 43, "better": [15, 30, 31, 38, 39, 40, 43, 44, 48, 50, 70, 89, 120], "between": [4, 6, 9, 14, 15, 24, 26, 27, 31, 32, 38, 39, 43, 57, 59, 62, 63, 67, 80, 81, 82, 84, 85, 86, 87, 89, 90, 91, 105, 106, 107, 108, 109, 110, 129, 131, 138, 147], "beyond": 7, "bia": [39, 65, 67], "bias": 59, "bib": 33, "bic": [86, 90], "bicycl": 33, "big": [15, 47], "bighorn": 33, "bikini": 33, "bill": 72, "billion": 43, "bin": [5, 14, 138, 144, 152], "binari": [4, 6, 7, 11, 32, 37, 38, 39, 40, 48, 52, 53, 54, 55, 57, 62, 64, 78, 81, 82, 84, 86, 87, 88, 89, 90, 91, 93, 99, 105, 106, 107, 108, 109, 110, 128, 142], "binary_crossentropi": [51, 56, 71], "binary_logloss": [11, 54], "binary_mask": [87, 89], "binary_winter_valu": 48, "binaryop": [74, 77], "binder": 33, "binocular": 33, "binom": 49, "bird": [26, 27, 29, 33], "birdhous": 33, "bison": 33, "bit": [38, 39, 43, 70, 85], "bittern": 33, "bizarr": 43, "black": [33, 39, 40], "black_and_gold_garden_spid": 33, "black_grous": 33, "black_stork": 33, "black_swan": 33, "black_widow": 33, "blaze": 15, "bleed": 15, "blend": 128, "blenheim_spaniel": 33, "blob": [25, 27, 32, 71], "block": [38, 53, 94], "blockbust": 43, "blood": [63, 97], "bloodhound": 33, "blow": 43, "blue": [10, 15, 16, 17, 25, 38, 39, 43, 48, 53, 55, 60, 66, 74, 76], "blue_rgb": 39, "bluetick": 33, "blur": [13, 26, 27, 28, 29, 33, 34, 35, 114], "bl\u00f6baum": [84, 91], "bmi": [45, 63, 97], "bmp": 26, "boa_constrictor": 33, "board": [74, 75], "boat": [29, 33], "boathous": 33, "bob": 43, "bobsl": 33, "bodi": [74, 97], "boi": 75, "bold": [15, 48], "bolet": 33, "bolo_ti": 33, "bolt": 15, "bonnet": 33, "boo": 16, "book_jacket": 33, "bookcas": 33, "bookshop": 33, "bool": [65, 81, 84, 86, 90, 91, 93, 101, 103, 107, 110, 126, 127, 128, 130, 132, 133, 138, 139, 140, 141, 151], "boolean": [65, 99, 131], "boost": [53, 54, 55, 56, 59, 62, 161], "boost_from_averag": [11, 54], "booster": [5, 59, 64], "boosting_list": 64, "boosting_typ": [11, 54], "bootstrap": [17, 59], "bootstrap_typ": 64, "border_colli": 33, "border_terri": 33, "borderpad": 48, "borzoi": 33, "boss": 15, "boston_bul": 33, "bot": 3, "both": [3, 9, 11, 14, 15, 19, 25, 29, 33, 38, 39, 40, 43, 48, 50, 57, 62, 73, 80, 85, 87, 89, 108, 113, 118], "bottlecap": 33, "bottom": [11, 14, 15, 17, 20, 39, 75, 141], "bought": 62, "bound": [48, 50, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 139], "bouvier_des_flandr": 33, "bow": 33, "bow_ti": 33, "box": [25, 40, 68], "box_turtl": 33, "boxer": 33, "boyfriend": 43, "bp": [63, 97], "br": [15, 38, 43], "brabancon_griffon": 33, "bracelet": 15, "bracket": 9, "brad": 43, "brain_cor": 33, "brambl": 33, "branch": [3, 26, 27, 65], "brand": 40, "brandx_purchase_scor": 40, "brass": 33, "brassier": 33, "braycurti": 119, "break": [3, 39, 65, 69, 77, 84, 87, 91, 120], "breakwat": 33, "breasted_mergans": 33, "breastplat": 33, "briard": 33, "bridg": 75, "briefli": [42, 43, 63], "brightest": 15, "brilliant": [15, 43], "bring": [15, 40, 74], "bristish": 72, "british": 74, "brittany_spaniel": 33, "broad": 10, "broccoli": 33, "broken": [88, 153], "bromwel": 15, "brook": 15, "broom": 33, "brother": 15, "brought": 43, "brown_bear": 33, "brows": 3, "browser": [3, 54, 55], "bruce": 43, "brute": 42, "bst": [16, 60, 64, 65, 66], "bu": 38, "bubbl": 33, "buck": 74, "bucket": 33, "buckey": 33, "buckl": 33, "buckmast": 43, "bug": 39, "bugfix": 3, "bui": 39, "build": [4, 5, 6, 9, 15, 17, 26, 27, 29, 33, 38, 39, 40, 47, 48, 50, 51, 52, 56, 62, 67, 71, 73, 77, 78, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 114, 115, 116, 119, 120, 122, 124, 125, 149], "build_partition_hierarchi": 48, "build_partition_tre": 114, "build_wheel": 3, "built": [3, 33, 38, 47, 88, 160], "bulbul": 33, "bull_mastiff": 33, "bullet_train": 33, "bulletproof_vest": 33, "bullfrog": 33, "bump": [29, 33], "bumpi": 43, "bundl": 40, "burden": 3, "burn": 15, "burrito": 33, "busi": 39, "bustard": 33, "butcher_shop": 33, "butternut_squash": 33, "button": 3, "by_label": 48, "c": [3, 11, 14, 25, 32, 39, 43, 48, 50, 51, 53, 54, 55, 59, 62, 63, 68, 75, 91, 158], "c2": 47, "c5b95cddae15be80f8e58b25edceca105aa83c0b8c86a1edad24a6af80d3": 47, "c_statistic_harrel": 63, "cab": 33, "cabbage_butterfli": 33, "cach": [13, 18, 19, 28, 29, 30, 31, 33, 34, 35, 38, 47, 70, 72, 73, 74, 75, 122, 124], "cacul": 48, "caddi": 72, "cage": 68, "cairn": 33, "calcuat": 55, "calcul": [30, 31, 42, 44, 47, 53, 122, 123, 124, 138, 147, 161], "caldron": 33, "calibr": 63, "california": [21, 38, 41, 53, 60, 61, 68, 161], "call": [3, 4, 8, 9, 14, 26, 27, 29, 32, 33, 39, 40, 48, 54, 65, 67, 71, 84, 91, 111, 112, 115, 117, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130, 132, 133, 138, 140, 141, 142, 153], "call_arg": [88, 89, 108], "callabl": [77, 78, 81, 82, 87, 89, 120, 121], "callback": [36, 47, 51], "came": [39, 40], "camera": 43, "can": [3, 4, 5, 6, 7, 9, 10, 11, 12, 14, 15, 16, 17, 20, 21, 26, 27, 29, 30, 31, 33, 36, 38, 41, 42, 43, 44, 46, 47, 48, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 112, 119, 128, 129, 130, 132, 136, 138, 139, 142, 149, 153, 158, 161], "can_open": 33, "canberra": 119, "candid": 39, "candl": 33, "cannon": [15, 33], "cannot": [11, 43], "cano": 33, "capabl": [14, 38, 43], "capit": [11, 12, 14, 17, 38, 51, 54, 55, 93], "captial": [9, 17, 44, 55], "caption": 158, "captur": [16, 20, 30, 31, 39, 40, 43, 62, 63, 66], "capuchin": 33, "car_mirror": 33, "car_wheel": 33, "carbonara": 33, "cardiff": 74, "cardigan": 33, "cardoon": 33, "care": [3, 43, 50, 63, 70, 73, 91, 158, 159], "carefulli": [17, 40], "carlin": 15, "carousel": 33, "carp": 43, "carpent": 33, "carton": 33, "cartoon": [15, 43], "case": [11, 14, 15, 16, 19, 25, 39, 40, 47, 55, 57, 60, 66, 74, 82, 84, 86, 87, 90, 91, 105, 106, 107, 108, 109, 110, 119, 122, 123, 130], "cash_machin": 33, "cassett": 33, "cassette_play": 33, "cast": 15, "castl": 33, "cat": [62, 69], "cat_col": 62, "cat_featur": 53, "catamaran": 33, "catboost": [11, 61, 64, 84, 91, 161], "catboostclassifi": 53, "catboostregressor": 53, "catch": [84, 91], "catch_warn": 11, "categor": [14, 53, 93, 138], "categori": [3, 55, 62, 93], "categorical_crossentropi": 32, "categoricaldtyp": [61, 65], "categoris": 3, "catgoriacl": 62, "cauliflow": 33, "caus": [15, 16, 26, 29, 33, 39, 40, 46, 50, 66, 80, 85, 116, 119, 127, 139, 140], "causal": [40, 62, 84, 91, 124, 158, 159], "causal_featur": 39, "causalml": 39, "causat": 39, "caution": [13, 18, 19, 22, 23, 24, 34, 35, 75], "cave": 68, "caveat": 40, "cb": 55, "cbar": 14, "cc": [37, 38], "cccccc": 66, "cd_player": 33, "cdict1": 55, "cdot": 43, "cell": [3, 27, 32, 39, 56, 63, 65], "cello": 33, "cellular_telephon": 33, "cemeteri": 68, "censu": [9, 38, 93, 161], "center": [11, 12, 38, 39, 52, 107, 110, 128], "centiped": 33, "centr": [74, 96, 100], "certain": [26, 43, 66, 76, 93, 98], "certainti": 50, "cg": 46, "chain": [14, 33, 49, 83, 143], "chain_mail": 33, "chain_saw": 33, "chainlink_f": 33, "chairman": 74, "challeng": [40, 67, 87], "chambered_nautilu": 33, "champion": 62, "chanc": [43, 44], "chang": [4, 6, 8, 15, 16, 17, 26, 27, 38, 39, 40, 41, 50, 52, 53, 57, 60, 63, 66, 67, 69, 70, 73, 80, 81, 84, 85, 86, 87, 90, 91, 116, 119, 130, 136, 138, 142, 153, 160], "changelog": [3, 160], "channel": [25, 133, 134], "char": 25, "char_idx": 25, "charact": [15, 25, 43, 72, 75], "chart": [54, 59, 63, 70], "chdir": 27, "cheap": 43, "chebyshev": 119, "check": [5, 20, 26, 27, 28, 39, 40, 48, 61, 65, 67, 84, 91], "check_addit": [25, 80, 84, 91], "check_valid_imag": 26, "checkout": 39, "checkpoint": 75, "cheeseburg": 33, "cheetah": 33, "chesapeake_bay_retriev": 33, "chest": 33, "chickade": 33, "chief": [39, 74], "chiffoni": 33, "chihuahua": 33, "child": 48, "children": [48, 56, 57], "children_default": [56, 65], "children_default1": 56, "children_default2": 56, "children_left": [56, 65], "children_left1": 56, "children_left2": 56, "children_right": [56, 65], "children_right1": 56, "children_right2": 56, "chime": 33, "chimpanze": 33, "chin": 102, "china_cabinet": 33, "chiton": 33, "chocolate_sauc": 33, "choic": [26, 27, 32, 39, 40, 48, 71, 77, 82, 85, 86, 87, 90, 105, 106, 107, 108, 109, 110, 116, 119], "choice0": 77, "choice1": 77, "choice4": 77, "choix": 77, "cholesterol": 97, "choos": [6, 9, 11, 13, 30, 34, 35, 39, 40, 47, 50], "chose": [14, 47, 80], "chosen": [4, 6, 40, 54, 55, 63, 80, 82, 85, 138], "chow": 33, "chri": 43, "christmas_stock": 33, "chuck": 15, "chunk": [15, 139], "church": 33, "churn": 39, "ci": 39, "cibuildwheel": 3, "cicada": 33, "cider": 27, "cinderella": 72, "cinema": 33, "citat": 158, "cite": 99, "citi": 68, "citizen": 15, "cityblock": 119, "civ": 11, "cl": 69, "clarifi": 48, "clariti": 63, "class": [4, 5, 6, 7, 11, 13, 14, 15, 20, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 46, 53, 65, 68, 74, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 98, 101, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 133, 142, 143, 157], "class_count": 11, "class_ind": 140, "class_label": [11, 101], "class_nam": [13, 18, 19, 28, 29, 30, 31, 33, 34, 35, 140], "class_prior_": 56, "classic": [9, 10, 12, 14, 15, 17, 38, 39, 40, 43, 95, 99, 101, 138, 158], "classif": [2, 5, 6, 9, 10, 11, 12, 14, 17, 19, 29, 39, 53, 73, 84, 90, 91, 93, 99, 106, 128, 158, 161, 162], "classifc": 70, "classifi": [11, 28, 29, 33, 39, 40, 56, 70, 72, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110, 157], "classification_report": 43, "classmethod": [78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "clean": [40, 75], "clear": [3, 9, 27, 38, 53, 59, 66], "clearer": 57, "clearli": [38, 40], "cleaver": 33, "cleft": 65, "clever": 43, "cleverli": 43, "clf": 39, "clf_": 39, "click": [3, 11, 15, 70, 73, 139], "clickl": 15, "cliff": 33, "cliff_dwel": 33, "cloak": 33, "clog": 33, "clone": [3, 5, 27, 39], "close": [3, 11, 38, 39, 40, 48, 59, 68], "closer": [15, 30, 31], "closest": 66, "cloth": 15, "cloudpickl": 47, "club": 74, "clumber": 33, "clust": 39, "cluster": [4, 6, 11, 12, 38, 39, 75, 78, 79, 81, 82, 83, 86, 87, 88, 89, 90, 105, 106, 107, 108, 109, 110, 114, 115, 119, 120, 126, 127, 128, 132, 147, 149], "cluster_": 48, "cluster_10": 51, "cluster_11": 51, "cluster_12": 51, "cluster_13": 51, "cluster_14": 51, "cluster_15": 51, "cluster_16": 51, "cluster_17": 51, "cluster_8": 51, "cluster_9": 51, "cluster_dict": 48, "cluster_id": 48, "cluster_matrix": 149, "cluster_threshold": 127, "clustering_cutoff": [4, 6, 9, 38, 39, 126], "cmap": [14, 55, 60, 132, 133, 138, 140], "cmasker": 20, "cmax": 139, "cnn": [32, 37, 71], "cnn_model": 27, "co": [3, 38, 68, 74, 75, 76, 77], "coach": 74, "coalit": [4, 6, 48, 51, 82, 86, 87, 88, 90, 105, 106, 107, 108, 109, 110], "coalitionexplain": [48, 51], "coated_retriev": 33, "coated_wheaten_terri": 33, "coax": 72, "cock": 33, "cocker_spaniel": 33, "cockroach": 33, "cocktail_shak": 33, "coco": 27, "coco_json": 27, "cocotalk": 27, "code": [4, 20, 25, 26, 29, 32, 33, 39, 47, 51, 54, 55, 60, 61, 62, 69, 71, 81, 128], "coef": [87, 107, 110], "coef_": [38, 52], "coeffici": [86, 107, 110], "coffee_mug": 33, "coffeepot": 33, "cognit": 157, "coher": 15, "coho": 33, "cohort": [83, 126], "cohorts2": 79, "coil": 33, "col_a_neg": 79, "col_a_po": 79, "cold_condition_fract": 65, "cold_index": 65, "cold_zero_fract": 65, "cole": 43, "collaps": [15, 17], "collapse_mask_token": [68, 72, 74, 76, 120], "collect": [3, 25, 26, 27, 39, 47, 79, 86, 90, 98], "colli": 33, "collid": 76, "collide0": 76, "collinear": 87, "colobu": 33, "coloni": 68, "color": [3, 11, 12, 15, 16, 38, 39, 48, 53, 54, 55, 59, 61, 62, 63, 66, 76, 127, 128, 129, 130, 132, 133, 138, 139, 140, 161], "color_bar": [127, 128, 140], "color_bar_label": [127, 140], "colorbar": [14, 55], "colormap": [10, 43, 60, 128, 133], "colsample_bylevel": [5, 59], "colsample_bynod": 5, "colsample_bytre": [5, 59], "column": [11, 14, 15, 16, 38, 39, 40, 47, 48, 50, 54, 55, 57, 62, 63, 64, 67, 71, 79, 83, 86, 93, 94, 97, 138], "com": [3, 5, 13, 18, 19, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 62, 71, 104], "combin": [15, 39, 49, 66, 71, 82, 85, 118, 142], "combination_lock": 33, "come": [9, 38, 40, 43, 55, 65, 69, 74, 76, 116, 119], "comedi": [15, 72], "comic_book": 33, "command": [3, 5, 27], "comment": [3, 39, 43, 64, 74], "commit": 3, "common": [11, 15, 38, 39, 41, 50, 68, 71, 86, 89, 106, 107, 110, 131], "common_iguana": 33, "common_newt": 33, "common_runtim": 38, "commun": [3, 11, 68, 95], "compact": 16, "compani": 39, "compar": [2, 15, 20, 26, 27, 31, 36, 40, 42, 49, 57, 63, 64, 66, 71, 107, 110], "comparis": [9, 11], "comparison": [11, 16, 20, 48, 105, 108, 109, 128, 161], "compel": 43, "compil": [3, 5, 32, 36, 37, 38, 47, 51, 71, 91], "complaint": 15, "complementari": 12, "complet": [3, 4, 6, 9, 11, 15, 89, 147], "complex": [4, 11, 38, 40, 48, 80, 83], "compliant": 3, "complic": [38, 40, 62, 66], "compon": [39, 40, 139], "compos": [28, 37, 43], "composit": [20, 113], "compromis": 38, "comput": [4, 5, 6, 7, 9, 10, 11, 12, 14, 15, 16, 17, 20, 26, 27, 30, 31, 38, 39, 40, 42, 52, 54, 55, 58, 62, 65, 67, 78, 81, 82, 83, 85, 86, 87, 88, 90, 105, 106, 107, 108, 109, 110, 111, 120, 122, 123, 124, 139, 142], "computation": 87, "compute_expect": 65, "compute_tim": 83, "computer_keyboard": 33, "computetim": 20, "concat": [62, 67], "concaten": [36, 51, 75], "concentr": 43, "concept": [11, 63], "concern": [39, 40, 123], "conch": 33, "conclus": [39, 59, 63], "conda": [3, 53, 158], "condit": [38, 42, 65, 67, 80, 84, 87, 91], "condition_featur": 65, "condition_fract": 65, "confectioneri": 33, "confer": [84, 91], "confid": 11, "config": [24, 40, 71, 73, 76], "configur": [3, 19, 22, 23, 24, 70, 71, 73, 74, 76, 160], "confirm": [3, 47, 76], "confirmed0": 76, "conform": 73, "connect": [15, 38, 40, 86, 158], "consecut": 120, "consequ": [3, 39, 40], "consid": [3, 7, 11, 15, 16, 38, 39, 40, 46, 50, 62, 63, 86, 87, 91, 112], "consist": [15, 38, 40, 55, 59, 91, 96, 100, 113, 118, 151, 153], "consomm": 33, "constant": [39, 84, 108], "constrain": [9, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110], "construct": [38, 75], "constructor": [82, 86, 87, 90, 105, 106, 107, 108, 109, 110, 111, 112, 115, 117, 121, 122, 123, 124, 125], "consumm": 43, "contact": 74, "contain": [0, 3, 11, 15, 19, 25, 39, 60, 62, 69, 85, 93, 99, 102, 122, 124, 127, 128, 141], "container_ship": 33, "content": [11, 26], "context": [3, 11, 15, 26, 27, 39, 40, 54, 55, 62, 69], "contextlib": 27, "contextmanag": 27, "contextu": 8, "continu": [25, 40, 62, 63], "contourpi": 25, "contract": 74, "contradict": [55, 75], "contrast": [52, 88], "contribut": [11, 17, 38, 46, 48, 52, 53, 67, 68, 74, 76, 128, 130, 158], "contribution_threshold": 130, "contributor": 3, "control": [9, 11, 12, 16, 36, 39, 48, 62, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110, 126, 130], "control_featur": 39, "conv": 36, "conv2": [80, 85], "conv2d": [32, 36, 37], "conv2d_1": 32, "conv_lay": 37, "conveni": [11, 87, 101, 102], "convent": 3, "converg": [11, 51, 71, 85], "convert": [11, 32, 33, 47, 50, 62, 65, 86, 93, 120], "convert_ids_to_token": 120, "convertido": 77, "convict": 43, "convolut": [25, 30, 31], "cool": [10, 14], "coolwarm": 66, "cooper": [38, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110], "copi": [3, 11, 13, 18, 19, 29, 30, 33, 34, 35, 36, 43, 44, 51, 54, 55, 56, 62, 64, 69], "coral_fungu": 33, "coral_reef": 33, "core": [3, 37, 38, 53, 59, 65], "corkscrew": 33, "corn": [15, 33], "cornet": 33, "corpu": 43, "corpus_test": 43, "corpus_train": 43, "correct": [11, 37, 40, 48, 62, 98], "correctli": [27, 28, 39, 40, 48, 55, 59], "correl": [9, 30, 31, 39, 40, 78, 82, 84, 86, 87, 88, 89, 90, 91, 96, 105, 106, 107, 108, 109, 110, 115, 119, 150, 161], "correlation_depend": [42, 87], "correspond": [1, 11, 14, 15, 38, 48, 50, 66, 70, 79, 85, 86, 90, 122, 124, 139], "correspondingli": 52, "coryroyc": 47, "cosin": [119, 147], "cost": 40, "costner": 72, "coucal": 33, "cougar": 33, "could": [3, 4, 6, 9, 26, 27, 37, 39, 40, 43, 46, 47, 50, 57, 66, 71, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110, 122], "couldn": 43, "count": [11, 63], "counter": 39, "counteract": 40, "counterfactu": 39, "countri": [11, 51, 76, 93], "coupl": [48, 51, 63], "cours": [40, 66], "cov": [52, 87, 115], "covari": [42, 87], "cover": [3, 52, 55, 139], "coverag": [54, 55], "cowboy_boot": 33, "cowboy_hat": 33, "cox": 63, "coyot": 33, "cp37": 47, "cp37m": 47, "cpp": [74, 77], "cpu": [15, 27, 28, 37, 38, 64, 73, 75, 122, 123, 124], "cpu_feature_guard": [37, 38], "cpudispatch": [81, 82, 87, 88, 89, 108], "cradl": 33, "craft": 3, "crane": [29, 33], "crap": 15, "crash_helmet": 33, "crate": 33, "crayfish": 33, "creat": [8, 9, 10, 11, 12, 15, 28, 29, 30, 31, 33, 38, 39, 40, 48, 53, 54, 55, 60, 61, 62, 113, 118, 119, 123, 126, 127, 128, 130, 132, 133, 136, 138, 140, 141], "create_paramet": 64, "create_path": 64, "credit": [38, 39, 40, 57, 87, 88, 112, 158], "credit_inquiri": 40, "creep": 43, "crested_cockatoo": 33, "crib": 33, "cricket": 33, "cright": 65, "crime": [11, 95], "crimin": 43, "crit": 27, "critic": [37, 38, 39, 40, 71], "crock_pot": 33, "croquet_bal": 33, "crossword_puzzl": 33, "crown": 62, "crucial": 43, "cruel": 74, "crush": 15, "crutch": 33, "csr": [92, 149], "csr_matrix": [87, 92, 104], "csv": [62, 64], "ct": 20, "cuadro": 15, "cuatro": 15, "cube": 128, "cucumb": 33, "cuda": [3, 5, 15, 26, 27, 28, 38, 68, 70, 73, 74, 76, 77, 84, 122, 123, 124], "cuda_path": [5, 84], "cue": 74, "cuirass": 33, "cultur": 43, "cumul": 128, "cup": [33, 42], "curli": 33, "current": [3, 5, 16, 26, 38, 47, 57, 62, 63, 74, 77, 80, 84, 85, 89, 91, 126, 127, 132, 140, 141, 142], "current_label": 47, "current_r": 64, "curv": [19, 138], "curve_i": 21, "curve_x": 21, "custard_appl": 33, "custom": [1, 3, 19, 22, 23, 24, 39, 40, 47, 48, 60, 63, 70, 74, 80, 85, 124, 126, 127, 128, 130, 132, 133, 138, 140, 141, 161, 162], "custom_cmap": 14, "custom_mask": 7, "custom_token": 73, "customer_qu": 40, "cut": [39, 71], "cute": 76, "cute0": 76, "cute4": 76, "cutoff": [11, 56, 128], "cv": 11, "cycl": [3, 89], "cycler": 25, "cypu": 60, "d": [50, 69, 74], "d4d0a19e515d857230caed0cc9bd7ad48017557ad8d72898297455efe78376ea": 47, "d_test": [11, 54, 55], "d_train": [11, 54, 55], "dai": [15, 39, 76], "daisi": 33, "dalmatian": 33, "dam": 33, "damag": 62, "damn": [70, 73], "damselfli": 33, "dan": 74, "dancer": 15, "dandie_dinmont": 33, "danger": 40, "dark": [60, 68], "dash": [11, 39], "data": [2, 3, 7, 8, 9, 10, 11, 12, 14, 16, 17, 19, 32, 36, 37, 38, 39, 40, 41, 43, 50, 51, 52, 54, 55, 56, 57, 59, 62, 64, 65, 66, 67, 69, 70, 71, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 113, 115, 116, 119, 120, 126, 128, 129, 132, 137, 138, 141, 153, 156, 157, 161, 162], "data_filenam": 25, "data_transform": [111, 120], "datafram": [4, 6, 24, 39, 40, 47, 50, 57, 62, 64, 65, 67, 70, 73, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 115, 116, 119, 128, 136, 140, 153], "dataload": [27, 37], "dataloaderraw": 27, "datapoint": 62, "dataset": [2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 44, 45, 46, 47, 48, 50, 53, 56, 58, 60, 61, 64, 66, 67, 70, 71, 73, 74, 75, 80, 82, 84, 85, 86, 87, 89, 90, 91, 105, 106, 107, 108, 109, 110, 114, 115, 116, 119, 129, 132, 138, 153, 158], "date": [3, 43, 47], "datetim": 64, "dateutil": [25, 47], "davi": 74, "david": [43, 74], "db919b12f750e5844402153233249bb3d24e9e9a": 25, "de": 77, "deal": [43, 74], "dealt": 62, "death": [57, 62, 63], "debia": 40, "debias": [39, 86, 90], "debug": [2, 3, 11, 58], "debug_mod": 19, "debut": 72, "decemb": 74, "decend": 70, "decid": [15, 43, 84, 91], "decis": [1, 9, 39, 40, 65, 83], "decision_plot": [11, 128], "decisionplotresult": 128, "decisiontreeclassifi": 46, "decisiontreeregressor": [9, 45, 56, 67], "decisiontreeregressordecisiontreeregressor": 56, "decod": [25, 69, 74, 75, 76, 120, 122], "decompos": [40, 131], "decomposit": [40, 41, 55], "deconfound": 39, "decreas": [15, 29, 33, 57, 71], "deep": [13, 18, 19, 28, 29, 30, 31, 33, 34, 35, 38, 47, 68, 80, 157], "deep_tf": 32, "deeper": [17, 39], "deepexplain": [37, 156, 157, 158], "deepli": 40, "deeplift": [25, 80], "def": [7, 9, 11, 13, 15, 18, 19, 20, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 44, 45, 46, 47, 48, 49, 50, 51, 63, 64, 65, 69, 73, 74, 75], "default": [4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 26, 27, 30, 31, 34, 35, 36, 38, 60, 70, 73, 74, 80, 81, 82, 84, 86, 87, 88, 89, 90, 91, 92, 96, 100, 101, 103, 105, 106, 107, 108, 109, 110, 120, 122, 123, 124, 125, 126, 127, 128, 130, 132, 138, 139, 140, 141, 147], "default_r": 40, "default_rate_sex_impact": 40, "default_rng": 57, "defaultdict": 26, "defin": [3, 9, 11, 13, 15, 20, 25, 26, 27, 28, 29, 33, 34, 35, 36, 38, 39, 40, 47, 51, 54, 55, 56, 57, 62, 69, 72, 74, 77, 84, 88, 120, 147, 148], "definit": [40, 42, 43], "degre": 53, "del": 27, "delet": 26, "deliv": 39, "delta": 64, "delta_train": 64, "demarc": 128, "demo": [18, 19, 21, 22, 23, 24, 68, 76, 77, 161], "demo_mnist_convnet": 32, "demograph": 40, "demolit": 15, "demonstr": [0, 1, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 29, 33, 36, 38, 40, 48, 54, 55, 57, 59, 69, 70, 72, 73, 74, 75, 76, 77, 161], "demostr": 68, "dendrogram": [39, 48], "denot": [42, 138], "dens": [10, 14, 32, 36, 47, 51, 71], "dense_test": 64, "densedata": [86, 87], "densiti": [10, 16, 54, 55, 62, 97, 129, 138, 161], "depend": [7, 11, 16, 25, 26, 27, 39, 40, 41, 42, 44, 48, 51, 52, 53, 58, 61, 62, 66, 69, 80, 84, 85, 86, 87, 88, 90, 91, 137, 138], "dependence_plot": [11, 14, 45, 52, 53, 54, 55, 59, 62, 63], "depos": 74, "deprec": [3, 15, 38, 61, 65, 74, 77, 84, 86, 87, 90, 91], "deprecationwarn": [3, 59], "depth": [38, 40, 64, 65], "depth_left": 65, "depth_list": 64, "depth_right": 65, "deriv": 128, "desc": 155, "descend": [11, 14, 128, 139], "describ": [3, 11, 15, 43], "descript": [3, 11, 19, 26, 47], "desert": 68, "design": [5, 9, 10, 12, 13, 14, 15, 16, 17, 38, 39, 40, 63, 85, 86, 90, 132, 141], "desir": [38, 41, 138], "desk": 33, "desktop_comput": 33, "desper": 43, "despit": 43, "detach": [15, 24, 38, 69, 73, 75], "detail": [3, 11, 15, 27, 29, 33, 40, 47, 63, 69, 81, 82, 86, 87, 90, 97, 102, 105, 106, 107, 108, 109, 110, 158], "detect": [39, 40, 138], "determin": [3, 10, 11, 39, 40, 52, 65, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 128, 153], "dev": 26, "dev0": 47, "develop": 130, "devenu": 77, "deviat": [30, 31], "devic": [27, 28, 37, 38, 64, 70, 74, 122, 123, 124], "devnul": 27, "df": 67, "df_featur": 47, "df_label": 47, "dhole": 33, "di": [57, 62], "diabet": [16, 66, 161], "diagnos": 39, "diagon": [52, 63, 84, 91], "dial_telephon": 33, "diamondback": 33, "diaper": 33, "dice": 119, "dict": [30, 48, 64, 79, 122, 123, 124, 138], "dictat": [84, 91], "dictionari": [9, 48, 79, 111, 112, 115, 117, 120, 121, 122, 123, 124, 125, 126, 138], "did": [15, 39, 43, 57, 59, 72], "didn": [39, 43, 70], "didnt": 73, "die": 62, "differ": [2, 6, 11, 15, 19, 20, 26, 27, 38, 39, 40, 45, 46, 47, 50, 51, 53, 54, 55, 57, 60, 62, 63, 66, 67, 68, 71, 77, 80, 81, 82, 84, 85, 86, 87, 89, 90, 91, 105, 106, 107, 108, 109, 110, 111, 128, 131], "differenti": [19, 80, 85], "difficult": [11, 39], "dig": 39, "digger": 15, "digital_clock": 33, "digital_watch": 33, "digraph": [39, 48], "dillon": 39, "dim": [28, 37, 75], "dime": 72, "dimens": [11, 16, 25, 26, 65, 66, 129, 153], "dimension": [11, 80, 85, 141], "dingo": 33, "dining_t": 33, "dinuc_shuff_explain": 25, "dinuc_shuff_explan": 25, "dinuc_shuffl": 25, "dinucleotid": 25, "dir": [26, 27], "dir_mask": [26, 27], "dir_reshap": 26, "direct": [9, 11, 15, 16, 39, 40, 43, 70, 76, 89, 126, 132], "directli": [3, 8, 32, 36, 39, 40, 44, 50, 52, 54, 55, 69, 70, 71, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110], "director": [15, 43, 72], "directori": [3, 26, 27, 47, 88], "disagre": 43, "disc": 38, "discern": 11, "disciplinari": 74, "discontinu": 39, "discount": 39, "discov": 68, "discovered0": 68, "discret": 138, "discuss": [3, 32, 39], "diseas": 11, "disentangl": [39, 40], "dishonest": 15, "dishrag": 33, "dishwash": 33, "disk": 11, "disk_brak": 33, "dismiss": 74, "dispar": 40, "dispers": [14, 53, 54, 55, 59, 62, 63, 138], "displai": [10, 14, 16, 17, 24, 26, 38, 44, 47, 48, 51, 52, 54, 55, 57, 60, 62, 63, 66, 93, 101, 103, 126, 127, 128, 130, 132, 136, 138, 139, 140, 141], "display_data": [14, 38, 83], "display_featur": [54, 55, 63, 138], "display_grid_plot": 26, "dispres": 59, "disproportion": 40, "disput": 74, "dist": 47, "distanc": [9, 48, 75, 119, 147], "distict": 40, "distigush": [54, 55], "distil": 15, "distilbart": [19, 22, 26, 27, 74], "distilbert": [15, 38], "distilbertforsequenceclassif": [15, 38], "distilberttokenizerfast": [15, 38], "distilgpt2": [26, 27], "distinct": [4, 6, 11, 14, 96], "distinguish": 11, "distort": 11, "distract": 43, "distribut": [7, 14, 16, 30, 31, 38, 39, 42, 53, 66, 84, 91, 98, 108, 140, 141], "district": 94, "disturb": 43, "div": [74, 77], "dive": 17, "divid": [15, 52, 55, 63, 65, 67], "divis": [74, 77], "divorc": 15, "dmatrix": [16, 39, 52, 55, 60, 62, 63, 64, 65, 66], "dmgtoobj": 62, "dmgtoturret": 62, "dml": 39, "dn": 75, "do": [3, 4, 6, 9, 11, 14, 15, 26, 27, 30, 31, 38, 39, 40, 41, 42, 43, 48, 52, 62, 63, 66, 67, 70, 71, 72, 80, 89, 112], "do_sampl": 76, "doberman": 33, "doc": 26, "dock": 33, "docstr": 3, "document": [5, 6, 7, 9, 10, 12, 13, 14, 15, 16, 17, 19, 20, 22, 29, 33, 34, 35, 38, 41, 42, 44, 48, 56, 68, 69, 70, 71, 73, 74, 76, 77, 160], "doe": [3, 6, 15, 26, 27, 38, 39, 41, 43, 48, 49, 50, 54, 55, 56, 62, 66, 88, 91, 105, 120], "doesn": [27, 43, 53], "dog": 76, "dog0": 76, "dog1": 76, "dog5": 76, "dogsl": 33, "domain": [7, 39, 82, 86, 87, 88, 90, 105, 106, 107, 108, 109, 110], "dome": 33, "domest": 43, "domin": [11, 44, 66], "dominik": [84, 91], "domonstr": [5, 6], "don": [5, 9, 11, 14, 15, 17, 38, 39, 43, 44, 46, 50, 52, 53, 54, 55, 57, 62, 66, 112], "done": [3, 15, 26, 27, 42, 47, 72, 74, 81], "dont": 76, "doormat": 33, "dot": [10, 11, 14, 39, 49, 53, 62, 63, 83, 143], "dot_data": [56, 67], "dot_siz": [14, 138], "doubl": [39, 62], "double_ml": 39, "doublekil": 62, "doubleml": 39, "dough": 33, "dowitch": 33, "down": [15, 26, 39, 47, 65, 67, 75, 84, 91], "download": [27, 37, 47, 51, 54, 55, 62, 98], "downsampl": 153, "downstream": [3, 39, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110], "dozen": 72, "dr": 43, "draft": 3, "dragon": 74, "dragonfli": 33, "drake": 33, "drama": 72, "dramat": [15, 17], "drang": 43, "drastic": 42, "draw": [20, 39, 42, 48, 63, 67, 126, 127, 128, 130, 132, 140], "drawn": [16, 66, 126, 127, 130, 132, 138, 140], "drdb": 60, "dream": 43, "drilling_platform": 33, "drive": [14, 27, 39, 40, 44, 62, 63, 68, 76], "driven": [39, 40, 54, 55], "driver": 39, "drop": [3, 11, 15, 39, 42, 47, 53, 62, 93], "dropdown": 47, "dropout": [32, 36, 37, 51, 71, 80], "drum": 33, "drumstick": 33, "dry": [3, 20], "dt": 62, "dtest": 39, "dtrain": [39, 64], "dtree": [45, 46], "dtype": [11, 15, 25, 33, 38, 44, 47, 51, 52, 57, 61, 65, 72, 75], "dub": 72, "due": [26, 40, 52, 62, 75, 160], "dugong": 33, "dumbbel": 33, "dump_imag": 27, "dump_path": 27, "dung_beetl": 33, "dungeness_crab": 33, "duplic": 3, "durat": 62, "dure": [9, 15, 26, 27, 30, 31, 38, 57, 62, 68, 71, 72, 76, 80, 88, 112, 120], "dutch_oven": 33, "dv": 62, "dwell": 94, "dx": 48, "dy": 63, "dynam": [25, 69], "e": [3, 4, 6, 11, 15, 23, 25, 26, 27, 29, 30, 31, 32, 33, 37, 38, 39, 42, 43, 51, 52, 65, 66, 67, 75, 77, 80, 85, 87, 91, 126, 128, 138], "e3": 59, "each": [0, 1, 3, 4, 6, 9, 10, 11, 12, 14, 15, 16, 17, 25, 26, 27, 29, 32, 33, 36, 37, 38, 39, 40, 45, 46, 48, 51, 52, 53, 54, 55, 62, 63, 66, 67, 68, 69, 70, 71, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 96, 99, 100, 105, 106, 107, 108, 109, 110, 120, 126, 127, 128, 132, 133, 134, 138, 139, 140, 141], "eager": 32, "ear": 33, "earli": [3, 11, 39], "earlier": [63, 74], "early_stopping_round": [11, 20, 39, 54, 55, 59, 62], "earn": [55, 62, 93], "earner": 62, "earth": 76, "earthstar": 33, "easi": [46, 52, 65, 67, 89, 125], "easier": [3, 11, 38, 39, 40, 47], "easiest": 38, "easili": [11, 15, 39, 47], "echidna": 33, "econml": 39, "economi": 39, "edg": [39, 66], "edge_color": 48, "edit": 3, "edu": [16, 95, 99], "educ": [11, 14, 44, 51, 93], "eel": 33, "effect": [15, 38, 40, 41, 52, 53, 54, 55, 57, 61, 62, 63, 66, 67, 70, 72, 74, 78, 81, 82, 84, 86, 87, 89, 90, 91, 105, 106, 107, 108, 109, 110, 138, 139, 142, 161], "effect_infer": 39, "effici": [6, 89, 90], "effort": 3, "eft": 33, "eg": [113, 118], "eggnog": 33, "egret": [29, 33], "egyptian_cat": 33, "eight": [26, 27, 39], "either": [9, 11, 15, 16, 26, 39, 43, 66, 73, 80, 85, 87, 91, 120, 129, 158], "el": 77, "eleanor": 39, "elecci\u00f3n": 77, "elect": [15, 74], "electric_fan": 33, "electric_guitar": 33, "electric_locomot": 33, "electric_rai": 33, "element": 85, "elif": [25, 26, 28, 32, 64, 65, 73], "elimin": [26, 27], "els": [9, 15, 25, 26, 27, 28, 32, 33, 43, 48, 51, 64, 65, 67, 69, 75, 147], "email": 39, "emb": 139, "embed": [25, 51, 71], "embroil": 74, "emerg": 40, "emot": [2, 72, 73, 162], "emphasi": 10, "employ": 93, "empoi": 11, "empti": [26, 27, 111, 112, 115, 117, 121, 122, 123, 124, 125, 139], "empty_cach": 27, "emul": 74, "en": [3, 15, 23, 26, 48, 51, 77], "en7": 15, "enabl": [3, 37, 38, 63], "encod": [12, 14, 15, 24, 25, 38, 73, 75, 76, 93, 101, 122, 147], "encoded_el": 51, "encount": [39, 52, 55, 59], "encourag": [5, 6, 7, 9, 10, 12, 13, 14, 15, 16, 17, 20, 29, 33, 34, 35, 38, 39, 41, 44, 68, 69, 70, 73, 74, 76, 77], "encout": 39, "end": [11, 15, 39, 42, 43, 73, 74, 75, 123, 162], "end_color": 14, "end_logit": 69, "endpoint": 26, "endswith": 65, "enemi": 62, "enemyjunglekil": 62, "enforc": [4, 6, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110], "engin": 39, "english": [15, 38], "english_foxhound": 33, "english_sett": 33, "english_spring": 33, "enh": 3, "enhanc": [3, 40, 48, 80], "enjoi": 76, "enjoy0": 76, "enough": 74, "ensembl": [11, 20, 45, 46, 54, 55, 56, 59, 65, 91], "ensemble_base_valu": 11, "ensemble_predict": 11, "ensemble_shap_valu": 11, "ensur": [3, 5, 6, 52, 62, 69, 74, 80, 153], "entail": 158, "enter": [26, 47], "entertain": [15, 43], "entertainment_cent": 33, "enthral": 72, "entir": [11, 14, 20, 38, 40, 44, 46, 49, 52, 53, 54, 55, 70, 72, 73, 80, 89, 92, 98, 103, 120, 139], "entlebuch": 33, "entri": [84, 91, 120], "enumer": [4, 11, 15, 20, 25, 37, 39, 48, 49, 67, 81, 86, 90], "env": 25, "envelop": 33, "environ": [5, 56, 65, 75, 84, 135], "eos_token_id": 76, "epidemiolog": 63, "episod": 15, "epoch": [32, 36, 37, 47, 51, 71], "epsilon_norm": 64, "eq": 37, "equal": [15, 39, 40, 56, 57, 67, 84, 91, 133, 151], "equat": [30, 31, 42], "equip": 74, "er": 77, "erik": 90, "ern": 38, "error": [3, 20, 38, 43, 45, 46, 47, 50, 51, 52, 53, 54, 55, 59, 60, 61, 62, 71, 84, 91], "error_bound": [78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110], "error_std": 83, "eskimo_dog": 33, "especi": 43, "espresso": 33, "espresso_mak": 33, "essenti": [3, 15], "est": [15, 39], "establish": 11, "estim": [11, 13, 26, 27, 28, 29, 33, 34, 35, 45, 46, 48, 51, 66, 80, 82, 84, 85, 86, 87, 89, 90, 91, 105, 106, 107, 108, 109, 110, 147], "estimators_": [56, 65], "et": 85, "eta": [39, 52, 55, 63], "etc": [26, 27, 61, 63, 71], "ethic": 40, "ethnic": 93, "euclidean": 119, "european_fire_salamand": 33, "european_gallinul": 33, "ev_": 40, "ev_a": 40, "ev_b": 40, "ev_c": 40, "ev_d": 40, "ev_f": 40, "ev_g": 40, "evacu": 57, "eval": [26, 27, 28, 31, 37, 39, 55, 62, 63], "eval_metr": [38, 55, 59, 62], "eval_set": [11, 20, 59], "eval_split": 27, "eval_util": 27, "evalu": [6, 11, 13, 15, 18, 20, 21, 22, 23, 24, 26, 27, 28, 32, 34, 35, 38, 40, 47, 48, 51, 64, 71, 78, 81, 82, 86, 87, 88, 89, 90, 105, 106, 107, 108, 109, 110, 116, 119, 124, 142], "even": [39, 40, 43, 44, 50, 57, 59, 90, 153], "evenli": [16, 66], "eventu": 14, "ever": [15, 43, 72, 76], "everi": [3, 15, 27, 38, 53, 62, 63, 122, 123, 124], "everyon": [39, 43], "everyth": [3, 15, 16, 40, 66], "evid": [39, 40, 50, 70, 141], "ex": [15, 26, 27, 45, 65], "exact": [1, 5, 6, 15, 20, 48, 49, 52, 54, 55, 62, 63, 66, 81, 88, 89, 91], "exact_explain": 48, "exact_shap_valu": 48, "exactexplain": [3, 20, 48], "exactli": [4, 6, 38, 52, 56, 72, 75], "examin": [11, 57], "exampl": [0, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 26, 27, 28, 29, 30, 31, 33, 34, 35, 38, 40, 41, 43, 44, 45, 47, 50, 53, 58, 62, 63, 66, 69, 71, 73, 75, 77, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 126, 127, 128, 131, 132, 133, 138, 139, 140, 141], "example_ind": 75, "exce": 141, "except": [16, 33, 43, 57, 89, 140], "exclud": [3, 11], "execut": [3, 6, 29, 33, 40, 74, 78, 81, 89], "exemplar": 11, "exercis": [39, 102], "exhibit": 39, "exist": [26, 27, 38, 39, 43, 64, 138], "exp": [11, 15, 20, 24, 38, 62, 73, 75, 79, 83], "expand": 128, "expand_dim": 32, "expect": [8, 11, 15, 16, 17, 30, 31, 32, 38, 39, 40, 42, 43, 45, 46, 51, 57, 59, 62, 63, 66, 67, 75, 80, 81, 82, 84, 85, 86, 87, 89, 90, 91, 105, 106, 107, 108, 109, 110, 111, 112, 120, 122, 123, 125, 128, 129, 141], "expected_valu": [11, 38, 40, 45, 46, 47, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 62, 71, 84, 86, 87, 89, 90, 91, 128, 130], "expens": 80, "experi": [26, 27, 29, 33, 38, 39, 40, 43], "experiment": [26, 27, 39, 84], "expir": 39, "expit": [39, 50], "explain": [2, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 32, 34, 35, 39, 42, 47, 49, 53, 60, 61, 66, 75, 78, 79, 80, 81, 84, 85, 86, 87, 88, 89, 90, 91, 98, 112, 116, 119, 120, 122, 124, 128, 130, 133, 136, 139, 153, 156, 157, 158, 159, 161, 162], "explain_row": [78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110], "explainableboostingregressor": 38, "explainer2": [5, 56, 72], "explainer_answ": 69, "explainer_blur": [29, 33], "explainer_ebm": 38, "explainer_end": 69, "explainer_log_odd": 38, "explainer_logist": 50, "explainer_model_agnost": 74, "explainer_start": 69, "explainer_xgb": 38, "explan": [1, 2, 4, 5, 6, 7, 9, 10, 12, 13, 14, 17, 19, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 43, 47, 48, 51, 52, 53, 56, 57, 60, 61, 70, 71, 72, 73, 78, 79, 80, 81, 82, 86, 87, 88, 90, 105, 106, 107, 108, 109, 110, 122, 123, 124, 125, 126, 127, 130, 132, 133, 138, 139, 140, 141, 143, 157, 158, 162], "explanationerror": 20, "explant": 12, "explicit": [42, 73], "explicitli": [4, 6, 9, 14, 39, 73, 79], "exploit": 39, "explor": [26, 27, 39, 40, 47, 53], "explos": 43, "exponenti": [42, 88], "export": 5, "export_graphviz": [56, 67], "expos": [11, 79], "expplan": 74, "extend": [47, 48, 65, 78], "extend_path": 65, "extens": [3, 26, 43, 46, 47, 50, 51, 53, 54, 55, 59, 60, 61, 62, 65, 71, 85, 90, 91, 138, 158], "extent": [11, 67, 128], "extern": [26, 27, 91], "extra": [3, 67], "extract": [56, 62, 68], "extrem": [57, 74, 75], "ey": 43, "f": [9, 11, 13, 15, 18, 19, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 57, 60, 64, 67, 69, 73, 74, 75, 80], "f0": 52, "f00": 88, "f1": [43, 52], "f11": 88, "f2": 52, "f4": 47, "f5": 47, "f9abaabb5e2b2a1e765c25417264722d31877b34ec34b437c53242f6e5c30d6d": 74, "f_": [70, 73], "f_answer": 69, "f_end": 69, "f_logist": 50, "f_start": 69, "fabul": 43, "face": [15, 39, 68, 74, 76], "face_powd": 33, "facebook": 162, "facilit": [3, 11], "fact": [39, 42, 59], "factor": [39, 40, 62, 63], "fail": [5, 27, 39, 40, 78], "fair": [38, 131, 158, 159], "fairli": [36, 39, 46], "faith": 43, "fall": [15, 40, 80], "fals": [11, 14, 20, 25, 26, 27, 28, 32, 37, 38, 39, 40, 43, 48, 51, 53, 57, 62, 63, 64, 69, 72, 75, 80, 84, 85, 86, 89, 90, 91, 93, 99, 101, 103, 107, 108, 110, 120, 125, 126, 127, 128, 130, 131, 132, 133, 137, 138, 140, 141, 148, 155], "famili": 72, "familiar": 43, "famou": 43, "fan": [43, 72], "fanci": 39, "fancybox": 48, "fantast": [15, 43], "far": [15, 68], "farg": [78, 81], "farm": 68, "fast": [45, 54, 55, 63, 91], "faster": [4, 6, 26, 29, 30, 31, 33, 48, 71], "father": [15, 43], "favor": 87, "favorit": 15, "fc": 27, "fc_layer": 37, "fear": [70, 73], "feat_nam": 16, "feather_boa": 33, "featur": [3, 4, 6, 7, 8, 15, 16, 17, 20, 26, 27, 30, 31, 32, 37, 39, 44, 46, 47, 51, 52, 53, 56, 57, 61, 63, 65, 66, 70, 71, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 115, 116, 119, 120, 126, 127, 128, 129, 130, 131, 132, 136, 138, 140, 141, 144, 147, 152, 161], "feature_01": 47, "feature_02": 47, "feature_03": 47, "feature_04": 47, "feature_05": 47, "feature_06": 47, "feature_07": 47, "feature_08": 47, "feature_09": 47, "feature_10": 47, "feature_col": 47, "feature_display_rang": [11, 128], "feature_expected_valu": [38, 137], "feature_extract": 43, "feature_idx": [11, 128], "feature_index": 65, "feature_nam": [11, 16, 43, 62, 78, 79, 81, 82, 83, 84, 86, 88, 89, 91, 108, 120, 128, 129, 130, 131, 136, 137, 138, 140, 144], "feature_ord": [11, 128, 132], "feature_pertub": [84, 91], "feature_perturb": [5, 42, 56, 57, 58, 84, 87, 91], "feature_valu": [12, 132], "features1": 56, "features2": 56, "features_displai": 11, "featuresdata": 64, "feed": [28, 36], "feed_dict": 30, "feedback": [3, 38], "feedforward": 36, "feel": [26, 27, 38, 70, 73], "felt": 74, "femal": [57, 66], "fenc": 27, "fetch": 15, "fetch_california_h": 94, "few": [3, 40, 42, 46, 54, 55, 66, 67, 72], "fewer": [15, 26, 27], "ff0052": 55, "ff5733": 60, "fi": 43, "fiction": 43, "fiddler_crab": 33, "field": 68, "fig": [14, 19, 20, 33, 38, 48, 51, 75], "fight": 15, "figsiz": [14, 19, 20, 39, 48, 55, 63, 75, 130], "figur": [16, 39, 40, 48, 55, 63, 74, 75, 127, 130, 140], "figure_format": 40, "file": [3, 13, 18, 19, 26, 27, 28, 29, 32, 33, 34, 35, 43, 45, 46, 47, 50, 51, 53, 54, 55, 59, 60, 61, 62, 71, 76, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "filenam": 47, "fill": [39, 56, 67, 114], "fill_between": 39, "film": [15, 38, 43, 72], "filter": 20, "filterwarn": 20, "final": [11, 16, 27, 39, 43, 53, 55, 63, 70, 73, 93, 141], "financ": 39, "financi": [15, 39], "find": [9, 10, 11, 14, 37, 39, 40, 43, 44, 52, 63, 65, 68, 80, 98, 160], "finding0": 68, "findit": 73, "fine": [29, 33, 40, 43, 70, 74, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110], "finer": 48, "finetun": [15, 38], "finish_test_preproc": 64, "finish_tim": 64, "finish_train": 64, "fire_engin": 33, "fire_screen": 33, "fireboat": 33, "first": [3, 7, 11, 15, 17, 20, 26, 29, 33, 36, 38, 39, 40, 41, 46, 47, 48, 53, 54, 57, 60, 61, 66, 72, 74, 76, 78, 80, 85, 131, 153], "fischer": 72, "fisher": 15, "fit": [4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 17, 20, 21, 32, 36, 38, 39, 40, 41, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 61, 62, 65, 66, 67, 71, 72, 128, 147, 161], "fit_transform": [41, 43, 55], "fit_xgboost": 39, "five": [11, 32, 74], "fix": [3, 10, 20, 33, 38, 39, 40, 80, 82, 84, 85, 86, 90, 91, 105, 106, 107, 109, 110, 138], "fixabledatafram": 39, "fixed_context": [15, 26, 27, 38, 77, 88, 139], "fl": 11, "flag": [3, 37, 38, 63, 80], "flagpol": 33, "flamingo": [29, 33], "flanker": 74, "flashback": 43, "flat": [15, 33, 39, 48, 59, 68], "flatten": [32, 36, 51, 59, 80, 82, 84, 85, 86, 90, 91, 105, 106, 107, 109, 110], "flatworm": 33, "flaw": 15, "flawless": 43, "flesh": 58, "flexibl": [14, 39, 69], "flick": 72, "flight": 15, "flip": [13, 18, 19, 28, 29, 33, 34, 35, 70], "float": [16, 31, 50, 86, 90, 93, 94, 97, 126, 127, 128, 129, 130, 133, 138, 139, 140], "float32": [32, 36, 47, 51, 52, 56, 57, 64], "float64": [51, 55, 56, 65, 67], "flood": 68, "floor": [69, 74, 77], "floor0": 69, "floor1": 69, "floor_divid": [74, 77], "flower": 101, "flute": 33, "fly": [33, 74], "fm": 88, "fma": [37, 38], "fname": [30, 31, 64], "fnlwgt": 93, "focu": [38, 44, 70, 73], "focus": 40, "fold": 11, "folder_path": [27, 62], "folding_chair": 33, "follow": [3, 9, 11, 14, 15, 25, 26, 37, 38, 39, 42, 62, 65, 72, 74, 84, 88, 91, 93, 94, 151], "followup": 63, "font": 48, "font_siz": 48, "font_weight": 48, "fontsiz": [14, 39, 48], "fonttool": 25, "fontweight": 48, "football_helmet": 33, "footed_ferret": 33, "for0": 77, "for1": 77, "for12": 77, "for5": 77, "for9": 77, "forc": [3, 11, 15, 26, 27, 39, 42, 43, 47, 53, 54, 55, 57, 61, 76, 122, 135, 161], "force_plot": [11, 45, 46, 47, 50, 51, 54, 55, 59, 62, 71], "forehead": 15, "forest": 68, "forg": [3, 53, 158], "forklift": 33, "form": [3, 15, 38, 40, 42, 43, 47, 74, 75, 78, 81, 82, 86, 87, 88, 89, 90, 105, 106, 107, 108, 109, 110, 129], "format": [11, 14, 26, 47, 53, 86, 88, 92, 93, 94, 125, 138], "former": [74, 77], "formul": [38, 39, 89], "formula": 53, "forum": 3, "forward": [6, 36, 37, 69, 89], "foul": 43, "found": [3, 5, 11, 15, 26, 27, 48, 51], "fountain": [29, 33], "fountain_pen": 33, "four": [15, 33, 37, 40, 52], "fox_squirrel": 33, "fr": 77, "frac": 42, "fraction": [39, 62, 65, 139], "frailti": 72, "frame": [40, 55, 65], "frameon": 48, "framework": [32, 80, 85], "franc": 74, "frankenstein": 15, "free": [26, 27], "freight_car": 33, "french": 74, "french_bulldog": 33, "french_horn": 33, "french_loaf": 33, "frequent": [3, 16], "friend": 72, "friendli": [62, 72], "frilled_lizard": 33, "frog": 69, "frog0": 69, "from": [2, 4, 5, 6, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 43, 44, 47, 48, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 95, 97, 98, 104, 105, 106, 107, 108, 109, 110, 113, 114, 116, 118, 119, 120, 122, 123, 124, 128, 130, 133, 141, 149, 153, 156, 157, 158, 159, 161, 162], "from_cal": [84, 91], "from_iter": 49, "from_list": 14, "from_pretrain": [15, 19, 22, 23, 24, 26, 27, 38, 68, 70, 73, 74, 75, 76, 77], "from_product": 67, "front": [27, 62, 157, 161], "frozen": 68, "frying_pan": 33, "fstr_type": 64, "fucntion": 74, "full": [3, 26, 27, 38, 39, 47, 49, 55, 58, 63, 70, 73, 74, 87, 99, 119, 138], "full_nam": 62, "fulli": [4, 9, 20, 40, 43, 73, 108], "fume": 15, "function": [0, 1, 3, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 21, 25, 26, 27, 29, 33, 34, 35, 37, 38, 39, 40, 42, 44, 47, 48, 51, 53, 58, 59, 67, 74, 75, 77, 78, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 96, 100, 105, 106, 107, 108, 109, 110, 112, 119, 122, 123, 124, 126, 128, 132, 136, 137, 142, 149, 153, 161, 162], "function_bas": 59, "fund": 74, "fundament": [38, 39], "funni": [15, 43], "fur_coat": 33, "further": [3, 11, 39, 76, 126, 127, 128, 130, 132, 133, 138, 139, 140, 141], "futur": [15, 26, 27, 38, 39, 43, 59, 61, 65, 74, 77, 78, 84, 87, 91, 130], "g": [3, 14, 25, 39, 40, 48, 52, 66, 74, 75, 91, 128], "ga": 26, "gain": [5, 9, 11, 12, 14, 17, 38, 44, 51, 52, 54, 55, 93, 109], "gam": 38, "game": [4, 6, 38, 62, 72, 78, 81, 82, 85, 86, 87, 88, 89, 90, 105, 106, 107, 108, 109, 110, 158], "gamma": [5, 59], "gap": 63, "gar": 33, "garbag": [86, 90], "garbage_truck": 33, "garden": 68, "garden_spid": 33, "gareth": 74, "garter_snak": 33, "gas_pump": 33, "gasmask": 33, "gata_disc1": 25, "gather": 43, "gatland": 74, "gaurente": 55, "gaussian": [96, 100, 115], "gave": 15, "gazel": 33, "gb_type": 64, "gbdt": [11, 54], "gbm": 54, "gbtree": [5, 59], "gc": 27, "gc_collect": [86, 90], "gca": [39, 48, 55, 63, 127, 141], "gcc": 3, "gcf": 48, "geforc": 38, "gender": 93, "gener": [2, 4, 6, 11, 15, 16, 21, 25, 26, 27, 38, 39, 40, 47, 53, 60, 63, 66, 68, 74, 78, 81, 82, 86, 87, 90, 96, 100, 105, 106, 107, 108, 109, 110, 114, 118, 122, 123, 124, 128, 153, 156, 157, 158, 159, 161], "generate_topk_token_id": 124, "generation_function_for_topk_token_id": 124, "generative_model": 39, "genom": 158, "genomics_simul": 25, "gent": 38, "georg": 15, "german": 76, "german0": 76, "german_shepherd": 33, "german_short": 33, "get": [3, 4, 5, 6, 9, 11, 12, 14, 15, 16, 19, 20, 24, 26, 28, 29, 30, 31, 33, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 48, 49, 50, 53, 55, 62, 63, 67, 68, 70, 71, 73, 74, 75, 76, 78, 87, 89, 93, 94, 95, 97, 98, 99, 101, 102, 122, 124], "get_capt": [26, 27], "get_cmap": [10, 14], "get_dataset": 47, "get_dump": 52, "get_ensemble_shap_valu": 11, "get_feature_import": 64, "get_feature_names_out": 43, "get_input": [122, 123, 124], "get_legend_handles_label": 48, "get_lm_logit": 124, "get_loc": 11, "get_logodd": [122, 124], "get_model": 47, "get_output": 122, "get_output_nam": 122, "get_output_names_and_update_topk_token_id": 124, "get_sess": 30, "get_teacher_forced_logit": 122, "get_word_index": 71, "getdescript": 25, "geyser": 33, "ghetto": 15, "giant": 68, "giant_panda": 33, "giant_schnauz": 33, "gibbon": 33, "gif": 26, "gila_monst": 33, "gilliam": 43, "gini": 109, "git": [3, 5, 27], "github": [1, 2, 3, 5, 25, 26, 27, 32, 39, 43, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 59, 60, 61, 62, 65, 71, 104, 156, 157, 159, 161, 162], "githubusercont": 25, "give": [12, 15, 26, 27, 30, 31, 39, 43, 45, 54, 55, 58, 63, 66, 67, 80, 87], "given": [3, 4, 5, 6, 9, 10, 14, 15, 25, 26, 29, 33, 38, 39, 40, 43, 48, 51, 54, 55, 57, 62, 69, 76, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 130, 132, 136, 138, 141, 143, 144, 147, 149, 151, 152], "glabel": 40, "glanc": 39, "glass": 26, "glassbox": 38, "global": [15, 26, 27, 38, 39, 40, 44, 55, 71, 76, 109, 126, 132], "gnpr": 60, "go": [15, 32, 33, 37, 43, 50, 59, 62, 64, 70, 73, 74], "goal": [38, 39, 40], "goblet": 33, "goddard": 15, "goe": [36, 57], "goin": 43, "gold": [14, 39, 62], "goldearn": 62, "golden_retriev": 33, "goldfinch": 33, "goldfish": 33, "goldspent": 62, "golf": 72, "golf_bal": 33, "golfcart": 33, "gondola": 33, "gong": 33, "good": [3, 15, 26, 27, 38, 39, 43, 48, 62, 72, 80, 84, 90, 91], "googl": [27, 98], "goos": 33, "gordon_sett": 33, "gorilla": 33, "got": [15, 39, 43, 69], "gothic": 72, "gov": 11, "govern": 74, "gown": 33, "gpt2": [68, 162], "gpu": [5, 29, 33, 38, 64, 84, 122, 123, 124], "gpu_devic": [38, 64], "gpu_device_id": 64, "gpu_hist": 64, "gpu_id": [5, 64], "gputre": [1, 84], "grab": [70, 73], "gradient": [30, 31, 53, 54, 55, 56, 59, 62, 85, 157, 161], "gradientboostingclassifi": 56, "gradientboostingclassifiergradientboostingclassifi": 56, "gradientboostingregressor": 20, "gradientexplain": [30, 31], "grai": [9, 14, 15, 17, 38, 48, 81], "grain": [48, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110], "grand": 72, "grand_piano": 33, "granny_smith": 33, "granular": [26, 27, 29, 33], "graph": [32, 39, 48, 56, 67, 80], "graphviz": [39, 56, 67], "grass": [26, 68], "grasshopp": 33, "great": [38, 43, 74], "great_dan": 33, "great_grey_owl": 33, "great_pyrene": 33, "great_white_shark": 33, "greater": [26, 50, 59], "greater_swiss_mountain_dog": 33, "greatest": 72, "greedi": [70, 73, 81], "greek": 76, "greek0": 76, "green": [3, 25, 48, 55], "green_lizard": 33, "green_mamba": 33, "green_snak": 33, "greenhous": [33, 68], "greensid": 80, "grei": [4, 14, 48, 138], "grey_fox": 33, "grey_whal": 33, "grid": [14, 26, 48], "grill": 33, "grocery_stor": 33, "groenendael": 33, "groom": 33, "ground": 25, "ground_beetl": 33, "group": [4, 6, 9, 11, 12, 15, 26, 27, 38, 39, 40, 48, 53, 55, 57, 68, 71, 88, 96, 131, 139, 141], "group_difference_plot": 40, "group_mask": 131, "group_remaining_featur": 127, "grouping_threshold": 139, "grow": 38, "gruop": 15, "gt": [15, 25, 32, 33, 36, 38, 43, 47, 51, 53, 75], "guacamol": 33, "guarante": [43, 89, 91], "guassian": 42, "guenon": 33, "guess": [14, 43, 67], "gui": 74, "guid": [39, 158], "guillotin": 33, "guinea_pig": 33, "gwent": 74, "gyromitra": 33, "gz": [25, 47, 99], "gzip": 25, "h5": 25, "ha": [1, 3, 4, 6, 11, 14, 15, 26, 27, 29, 31, 32, 33, 36, 38, 39, 40, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 65, 66, 67, 71, 74, 78, 80, 88, 116, 119, 122, 123, 124, 126, 127, 128, 130, 132, 133, 134, 138, 139, 140, 141], "had": [3, 15, 40, 43, 47, 88], "hai": [15, 33], "hair_slid": 33, "hair_sprai": 33, "haired_fox_terri": 33, "haired_point": 33, "half": [40, 63, 74], "half_track": 33, "halv": [26, 27], "ham": 119, "hammer": 33, "hammerhead": 33, "hamper": 33, "hamster": 33, "han": 77, "hand": [3, 11, 12, 15, 33, 38, 39, 40, 55], "hand_blow": 33, "handkerchief": 33, "handl": [38, 48, 78, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110], "happen": [5, 15, 17, 38, 39, 40, 43, 50, 57], "happi": [54, 55], "hard": [38, 39, 43, 67, 128], "hard_disc": 33, "harder": [30, 31, 39, 52, 60], "hardest": 39, "hardship": 43, "hare": 33, "harmonica": 33, "harp": 33, "hartebeest": 33, "harvest": 33, "harvestman": 33, "hash": 53, "hasn": 59, "hat": 74, "hatchet": 33, "have": [3, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 25, 26, 27, 29, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 64, 65, 68, 69, 70, 71, 73, 74, 76, 77, 80, 81, 82, 86, 87, 88, 90, 91, 98, 105, 106, 107, 108, 109, 110, 116, 119, 120, 129, 138, 142, 144, 152], "have0": 77, "have1": 77, "have12": 77, "have4": 77, "haven": [43, 74], "hazard": 63, "hclust": [4, 6, 9, 11, 12, 38, 39, 126, 128, 132], "hclust_ord": 132, "hcluster": [78, 81, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110], "hdl": 97, "he": [15, 43, 72, 74], "he_uniform": 47, "head": [26, 27, 47, 57], "head_cabbag": 33, "header": 26, "heal": 62, "health": 39, "heart": 11, "heart_base_valu": 11, "heart_feature_nam": 11, "heart_predict": 11, "heart_shap_valu": 11, "heatmap": [1, 15, 38, 44, 75], "heavi": 43, "height": [25, 133, 134, 138], "held_comput": 33, "help": [4, 5, 6, 7, 9, 10, 12, 13, 14, 15, 16, 17, 20, 29, 33, 34, 35, 38, 41, 43, 44, 50, 62, 68, 69, 70, 73, 74, 76, 77, 84, 91, 112, 130, 136], "helper": 39, "helsinki": [15, 23, 77], "hen": 33, "henc": [11, 26, 27, 29, 33, 40, 42, 46, 52, 57, 66, 67, 69, 80], "her": 15, "herarch": 114, "herarchi": [4, 6], "herd": 68, "herd0": 68, "here": [1, 3, 4, 6, 7, 11, 13, 14, 15, 20, 21, 26, 27, 28, 29, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 46, 47, 51, 53, 54, 55, 56, 62, 64, 66, 67, 68, 69, 70, 71, 72, 73, 80, 85, 120, 128, 160], "hermana": 15, "hermano": 15, "hermit_crab": 33, "hero": 74, "heron": [29, 33], "hex": [60, 130], "hi": [15, 43, 72, 74], "hidden": [3, 39, 78, 81, 82, 86, 87, 88, 89, 90, 105, 106, 107, 108, 109, 110, 114], "hidden_layer_s": [45, 46], "hide": [14, 15, 39, 40, 66, 69, 73, 86, 90], "hierarch": [9, 11, 12, 15, 82, 86, 87, 88, 89, 90, 105, 106, 107, 108, 109, 110, 119, 128, 147], "hierarchi": [48, 75, 88, 147], "hierarchical_trees_and_shap_plot": 48, "hierarchical_valu": [15, 83], "hierarchy_binari": 48, "hierarchy_flat": 48, "hierarchy_nonbinari": 48, "hierarchy_nonbinary2": 48, "hierarchy_po": 48, "high": [3, 9, 10, 11, 12, 14, 15, 16, 38, 39, 40, 53, 62, 63, 66, 68, 76, 79, 97, 127, 140], "higher": [15, 16, 30, 31, 39, 40, 43, 53, 63, 89], "highest": 93, "highight": 38, "highli": [3, 38, 39], "highlight": [3, 11, 25, 29, 33, 39, 40, 54, 55, 57, 63, 128], "hilar": 43, "hilari": 43, "him": [39, 43], "himself": 43, "hip": 33, "hippopotamu": 33, "hist": [137, 138], "histogram": [14, 38, 138], "histori": [3, 36, 40, 43, 47, 51], "hit": 50, "hive": 68, "hobo": 15, "hog": 33, "hognose_snak": 33, "hold": 43, "hole": 68, "hollow": 68, "holster": 33, "home": [3, 15, 25, 38, 53, 68, 69, 70, 72, 73, 74], "home_theat": 33, "homeless": 15, "honest": 43, "honestli": 43, "honeycomb": 33, "hook": [3, 33], "hoopskirt": 33, "hope": [40, 70, 73], "hopeless": [70, 73], "horizont": [11, 38, 48, 53, 55], "horizontal_bar": 33, "horizontalalign": 63, "hornbil": 33, "horned_beetl": 33, "horned_vip": 33, "horror": 72, "hors": [26, 27], "horse_cart": 33, "hospit": 15, "host": 3, "hot": [25, 65, 68], "hot_condition_fract": 65, "hot_index": 65, "hot_pot": 33, "hot_zero_fract": 65, "hotdog": 33, "hour": [3, 11, 51, 93], "hourglass": 33, "hous": [38, 53, 68, 94], "house_finch": 33, "houseag": [38, 48, 53, 94], "housecharacterist": 48, "household": 38, "houseless": 15, "hover": [15, 68, 70, 73], "how": [0, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 36, 37, 38, 39, 41, 43, 44, 45, 46, 48, 52, 53, 54, 55, 56, 57, 58, 59, 63, 67, 68, 69, 70, 71, 73, 74, 75, 76, 80, 81, 82, 84, 85, 86, 87, 88, 90, 91, 105, 106, 107, 108, 109, 110, 126, 127, 129, 133, 138, 140, 141, 144, 152, 161, 162], "howard": 15, "howev": [4, 10, 11, 16, 26, 39, 40, 50, 54, 55, 59, 60, 66, 119, 130], "howler_monkei": 33, "hspace": [33, 133], "hstack": 83, "html": [3, 16, 48, 51, 56, 65, 130, 139], "http": [3, 5, 13, 16, 18, 19, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 47, 48, 51, 62, 68, 71, 74, 75, 76, 77, 95, 99, 104], "hug": [68, 74, 76], "huge": 68, "huggingfac": [38, 68, 70, 72, 73, 74, 75, 76, 77, 120], "human": [15, 40, 43, 63, 68], "humbl": 72, "humili": [70, 73], "hummingbird": 33, "hurt": 74, "husband": 11, "hyena": 33, "hyperlink": 3, "hypothesi": 75, "hypothet": [11, 40], "hypothetical_predict": 11, "hypothetical_shap_valu": 11, "i": [3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 136, 138, 139, 140, 141, 142, 147, 148, 149, 151, 153, 158, 160, 161], "i0": 74, "ibex": 33, "ibizan_hound": 33, "ic": [38, 95, 137], "ice_bear": 33, "ice_cream": 33, "ice_lolli": 33, "id": [13, 24, 27, 34, 35, 38, 62, 69, 83, 120, 122, 123, 124], "id2label": 24, "idea": [3, 5, 6, 7, 9, 10, 12, 13, 14, 15, 16, 17, 20, 29, 30, 31, 33, 34, 35, 38, 41, 43, 44, 54, 55, 68, 69, 70, 73, 74, 76, 77], "ideal": 43, "ident": [11, 16, 40, 47, 75, 81, 82, 86, 87, 88, 89, 90, 105, 106, 107, 108, 109, 110, 128, 130], "identifi": [39, 40, 54, 55], "idf": [43, 71], "idiot": 15, "idol": 72, "ids_to_load": 25, "idx": [11, 25, 67, 69], "idx1": 48, "idx2": 48, "ignor": [11, 20, 43, 75], "ignore_warn": 128, "igor": 90, "illustr": [11, 39, 46, 62, 63], "iloc": [11, 44, 45, 46, 47, 50, 51, 53, 54, 55, 56, 58, 62, 63, 65, 66], "im": [70, 73, 90], "imag": [1, 30, 31, 32, 34, 35, 37, 82, 86, 87, 88, 90, 98, 105, 106, 107, 108, 109, 110, 113, 118, 122, 134, 149, 158], "image_count": [26, 27], "image_fold": 27, "image_plot": [13, 18, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37], "imagecapt": 27, "imagecaptioningpytorchmodel": 27, "imagemask": [82, 86, 87, 90, 105, 106, 107, 108, 109, 110], "imagenet": [13, 18, 19, 28, 29, 98, 157], "imagenet50": [13, 18, 19, 28, 29, 30, 31, 33, 34, 35], "imagenet_class_index": [13, 18, 19, 28, 29, 30, 31, 33, 34, 35], "imagenet_weight": 27, "imagin": [39, 43], "imdb": [15, 38, 162], "imdb_lstm": 71, "imdb_train": [15, 38], "img": 28, "iml": [86, 87, 106], "immedi": [3, 11, 15], "impact": [3, 10, 12, 14, 15, 16, 17, 38, 39, 40, 42, 44, 50, 53, 54, 55, 57, 67, 76, 86, 90, 136, 141], "impala": 33, "implement": [45, 49, 52, 54, 55, 62, 63, 65, 78, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 111, 144, 152], "impli": 17, "implicitli": [4, 6, 39, 73], "import": [3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 86, 109, 126, 128, 161], "importance_typ": [5, 55], "impos": 39, "imposs": [39, 40], "impress": [15, 74], "improv": [3, 5, 11, 26, 27, 59], "imput": [39, 87], "imshow": [19, 63], "in0": 68, "in1": 68, "in2": 68, "in3": 68, "in4": 68, "in5": 68, "in_fil": [78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "inch": [16, 127, 140], "includ": [3, 7, 8, 9, 11, 15, 39, 43, 52, 62, 93, 94, 101, 102, 120, 126, 127, 128, 140, 151], "include_brandx_purchase_scor": 40, "include_sex": 40, "include_top": 30, "incom": [4, 5, 6, 9, 10, 11, 12, 14, 17, 38, 53, 94, 161], "income_amount": 40, "income_sex_impact": 40, "income_st": 40, "incoming_one_fract": 65, "incoming_zero_fract": 65, "incompat": 40, "inconveni": 130, "incorrect": [59, 74, 77, 78], "incorrectli": 40, "increas": [9, 12, 14, 15, 16, 26, 27, 29, 33, 39, 40, 43, 44, 48, 53, 57, 66, 138], "incredibli": 43, "increment": 3, "ind": [14, 43, 56, 63, 129, 136, 137, 142, 145], "inde": [43, 52, 66], "independ": [9, 20, 21, 38, 39, 40, 43, 52, 58, 87, 90, 100, 115, 119], "independentmask": 21, "index": [3, 11, 14, 19, 26, 27, 30, 31, 37, 38, 44, 46, 47, 48, 51, 62, 63, 64, 65, 67, 71, 80, 85, 97, 128, 129, 136, 144, 151, 152], "index_list": [18, 19], "index_mask": 151, "index_nam": [30, 31], "indian": 76, "indian0": 76, "indian_cobra": 33, "indian_eleph": 33, "indic": [11, 16, 19, 25, 38, 63, 66, 76, 80, 93, 99, 128], "indiffer": 15, "indigo_bunt": 33, "indirect": 39, "individu": [10, 11, 16, 17, 19, 40, 44, 47, 48, 51, 54, 55, 66, 70, 90, 93, 102], "indri": 33, "infer": [54, 55, 73, 74, 84, 91, 122, 123, 124], "inferenc": [122, 124], "infil": [68, 74], "infinit": [44, 85], "inflat": 15, "influenc": [39, 40, 43, 47], "info": [3, 16, 27], "inform": [3, 4, 6, 8, 10, 11, 15, 39, 40, 43, 50, 56, 57, 62, 63, 70, 72, 78, 104, 127, 147], "infos_fc_nsc": 27, "infos_path": 27, "infrequ": 38, "ingest": 56, "ingredi": 39, "inhabit": 76, "inher": [39, 40, 66], "inhibitor": 62, "inhibkil": 62, "init": 71, "init_": 56, "initi": [3, 27, 48, 68, 75, 79, 135, 139], "initj": [43, 45, 46, 47, 50, 51, 53, 54, 55, 59, 60, 61, 62, 71], "inlin": [19, 25], "inlinebackend": 40, "inn": 15, "inner1d": 59, "inpaint": [18, 26, 27, 29, 33, 114], "inpaint_n": [26, 27, 29, 33, 114], "inpaint_telea": [13, 18, 19, 26, 27, 29, 33, 34, 35, 114], "input": [3, 4, 6, 7, 9, 12, 13, 15, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 44, 47, 51, 54, 55, 56, 57, 69, 70, 73, 74, 76, 77, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 118, 120, 122, 123, 124, 131, 132, 133, 134, 139, 142, 153, 157, 162], "input1": 36, "input2": 36, "input2c": 36, "input_dim": 47, "input_dtyp": 56, "input_el": 51, "input_id": [69, 73, 75, 120], "input_json": 27, "input_nam": 145, "input_shap": 32, "input_token": 139, "inputs0": [68, 69, 70, 73, 74, 76, 77], "inputs1": [76, 77], "inputs5": 77, "inputs7": 77, "inquiri": 40, "insan": 43, "insert": 25, "insid": [43, 60, 66, 91], "insight": [15, 16, 43, 47, 63, 158, 159], "insist": 74, "inspect": [3, 11], "inspector": 15, "inspir": [15, 43], "instal": [5, 25, 27, 47, 53, 135], "instanc": [9, 10, 12, 16, 25, 27, 38, 51, 65, 72, 75, 83, 143], "instance_nam": 83, "instance_ord": [12, 132], "instanti": [78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "instead": [10, 11, 12, 15, 26, 27, 29, 33, 38, 39, 40, 44, 52, 55, 58, 61, 63, 65, 66, 72, 78, 81, 82, 84, 86, 87, 88, 89, 90, 91, 103, 105, 106, 107, 108, 109, 110, 112, 114, 130, 138], "instig": 74, "institut": 43, "instruct": [5, 37, 38], "instrument": 39, "int": [19, 26, 48, 64, 80, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 116, 119, 120, 122, 124, 126, 127, 128, 129, 132, 133, 136, 139, 140, 141, 147, 153, 154], "int32": [62, 65], "int64": [24, 65, 73], "int8": [25, 51], "integ": [38, 80, 83, 85, 101, 120, 128], "integr": [30, 31, 38, 39, 54, 55, 71, 80, 84, 85, 86, 90, 91, 116, 119], "intellig": [43, 84, 91], "intens": [76, 86, 90], "inter": [15, 59, 87], "interact": [15, 16, 38, 39, 53, 59, 62, 66, 81, 84, 89, 91, 127, 128, 135, 138, 139, 144, 152, 161], "interaction_constraint": 5, "interaction_contrib": [144, 152], "interaction_index": [11, 53, 62], "interaction_matrix": 63, "interaction_shap_valu": 5, "intercept": [11, 87], "interest": [3, 16, 17, 36, 38, 39, 43, 46, 54, 55, 63], "interestingli": 40, "interfac": [79, 82, 89, 106, 107, 110], "intermedi": 157, "intern": [59, 65, 74, 77, 79, 84, 91, 139], "internal_dtyp": 56, "interpet": 38, "interpol": 85, "interpret": [11, 16, 38, 40, 52, 62, 63, 158, 159], "interpretml": 38, "intersect": 38, "interv": 11, "interven": [38, 87], "intervent": [39, 42, 56, 57, 58, 84, 87, 91], "intract": 42, "intrigu": 43, "introduc": [8, 39, 67], "introduct": [39, 159], "intuit": [11, 39, 40, 57, 67], "inv_transform": 28, "invad": 15, "invalid": [26, 52, 55, 59], "invari": [38, 116, 119, 120, 142], "investig": 40, "involv": [11, 17, 63, 132], "io": [3, 48, 51], "ipod": 33, "iprogress": [48, 51], "ipynb": [3, 19, 25], "ipython": [33, 57, 60, 135], "ipywidget": [47, 48, 51], "iraq": 15, "iri": 161, "irish": [43, 74], "irish_sett": 33, "irish_terri": 33, "irish_water_spaniel": 33, "irish_wolfhound": 33, "iron": 33, "is_avail": 28, "is_categorical_dtyp": [61, 65], "is_decod": 76, "is_empti": [26, 27], "is_encoder_decod": 76, "is_femal": 57, "is_spars": [61, 65], "is_young": 57, "isfil": [26, 27], "isinst": [11, 26, 39, 48, 61, 64, 65], "isn": [3, 11, 15, 43, 53, 66, 74], "isol": [3, 40], "isopod": 33, "issu": [5, 15, 26, 27, 38, 40], "italian": [15, 76], "italian0": 76, "italian_greyhound": 33, "item": [11, 37, 48, 64, 75], "iter": [6, 11, 26, 27, 37, 49, 53, 59, 74, 82, 86, 87, 89, 90, 105, 106, 107, 108, 109, 110, 155], "itertool": 49, "ith": 87, "its": [1, 11, 15, 38, 39, 43, 48, 50, 52, 62, 76, 153], "itself": [11, 39, 40, 43, 63, 67], "ix": 27, "ix_to_word": 27, "j": [47, 51, 52, 54, 55, 60, 63, 71], "jacamar": 33, "jaccard": 119, "jack": 33, "jackfruit": 33, "jacob": 39, "jaguar": 33, "jai": 33, "jake": 72, "jame": 43, "jami": 74, "janet": 43, "janz": [84, 91], "japanese_spaniel": 33, "jargon": 48, "javascript": [43, 45, 46, 47, 50, 51, 53, 54, 55, 59, 60, 61, 62, 71, 130, 135], "jean": 33, "jeep": 33, "jefferi": 15, "jeffrei": [15, 43], "jellyfish": 33, "jensenshannon": 119, "jersei": 33, "jet\u00e9": 43, "jfif": 26, "jigsaw_puzzl": 33, "jinrikisha": 33, "jit": 65, "jitter": 138, "jmlr": 90, "job": [38, 39, 40, 43], "job_histori": 40, "job_history_sex_impact": 40, "joblib": 47, "jocelinsu": 75, "joi": [70, 73], "join": [26, 27, 38, 64, 74, 139], "joint": [36, 39], "joke": 15, "jonathan": 39, "joystick": 33, "jpeg": 26, "jpg": [26, 27], "json": [13, 18, 19, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35], "judgement": 40, "judgment": 40, "jump": [43, 59, 75, 102], "junco": 33, "jungl": [62, 68], "jupyt": [2, 27, 48, 51, 56, 65, 156, 157, 159, 161, 162], "jupyterlab": [43, 46, 47, 50, 51, 53, 54, 55, 59, 60, 61, 62, 71], "just": [4, 5, 6, 7, 10, 14, 15, 20, 30, 31, 38, 39, 40, 42, 43, 44, 47, 50, 52, 62, 67, 69, 70, 73, 74, 77, 82, 84, 86, 87, 90, 91, 105, 106, 107, 108, 109, 110, 111, 112, 115, 117, 121, 122, 123, 124, 125, 144, 152], "justin": 74, "k": [20, 26, 27, 30, 48, 50, 51, 69, 124], "kaggl": 62, "kane": 15, "kart": 33, "kathryn": 43, "kb": 32, "keen": 74, "keep": [3, 11, 14, 18, 19, 20, 21, 22, 23, 24, 36, 38, 39, 43, 47, 54, 55, 63, 74, 75, 77, 148], "keepdim": 37, "keeshond": 33, "kei": [24, 26, 39, 48, 64, 71, 73], "kelpi": 33, "kept": 3, "kera": [13, 18, 19, 29, 30, 31, 32, 33, 34, 35, 36, 47, 80, 85, 161, 162], "keras2_conv1d_record_5_model_pqzyq_modeljson": 25, "keras2_conv1d_record_5_model_pqzyq_modelweight": 25, "keras_model": 25, "keras_model_json": 25, "keras_model_weight": 25, "kernalexplain": 89, "kernel": [3, 6, 27, 29, 33, 47, 51, 66, 80, 86, 161], "kernel_explain": 51, "kernel_initi": 47, "kernel_s": [32, 36, 37], "kernel_shap": 49, "kernel_xs": [26, 27, 29, 33, 114], "kernelexplain": [45, 46, 47, 48, 50, 51, 88, 90], "kerry_blue_terri": 33, "kevin": 72, "kid": [15, 74], "kill": [15, 62], "killer_whal": 33, "killingspre": 62, "kimono": 33, "kind": 39, "king": 15, "king_crab": 33, "king_penguin": 33, "king_snak": 33, "kit": 44, "kit_fox": 33, "kite": 33, "kiwisolv": 25, "kmean": [45, 46, 50, 86], "knee_pad": 33, "kneighborsclassifi": [44, 46], "knew": [15, 72], "knn": [44, 46], "knn_norm": 44, "knot": 33, "know": [4, 14, 15, 38, 39, 40, 43, 57, 59, 76], "know0": 76, "knowledg": 39, "known": [38, 39, 46, 82, 86, 87, 90, 96, 105, 106, 107, 108, 109, 110], "koala": 33, "komodo_dragon": 33, "komondor": 33, "kononenko": 90, "kulsinski": 119, "kundaj": 80, "kundajelab": 25, "kutcher": 72, "kuvasz": 33, "kwarg": [39, 64, 65, 79, 80, 82, 84, 85, 86, 87, 90, 91, 105, 106, 107, 109, 110, 117], "l": 74, "l1": [86, 90], "l1_reg": [86, 90], "l2": 43, "la": 43, "lab": [63, 68, 75], "lab_coat": 33, "label": [4, 6, 11, 16, 19, 25, 28, 33, 38, 39, 47, 48, 52, 54, 55, 58, 60, 62, 63, 64, 65, 66, 70, 72, 73, 75, 80, 82, 84, 85, 86, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 109, 110, 112, 126, 128, 130, 133, 139], "label2id": [24, 73], "label_col": 47, "labelpad": [33, 133], "labels": 14, "labels_01": 47, "labels_02": 47, "labels_03": 47, "labels_04": 47, "labels_05": 47, "labels_arr": 75, "labit": 74, "labl": 47, "laboratori": 68, "labrador_retriev": 33, "lacew": 33, "lack": 59, "ladi": 15, "ladl": 33, "ladybug": 33, "lake": 68, "lakeland_terri": 33, "lakesid": 33, "lambda": [20, 28, 30, 31, 52], "lambdarank": 104, "lampshad": 33, "languag": 158, "language_ev": 27, "languagemodelcriterion": 27, "langur": 33, "lantern": 33, "laptop": 33, "larg": [4, 6, 15, 16, 26, 39, 47, 48, 49, 50, 54, 55, 62, 66, 67, 68, 75, 90, 128, 129, 138, 149], "larger": [38, 39, 44, 50, 70, 86, 97, 116, 119, 130], "largest": [14, 15], "larivier": 39, "larri": 15, "lasso": [86, 90], "last": [11, 32, 33, 39, 62, 65, 66, 72, 75, 128], "late_pay": 40, "late_payments_sex_impact": 40, "later": [15, 39, 63, 74], "latest": 160, "latitud": [38, 48, 61, 94], "laugh": 43, "laughter": 72, "laurent": 74, "law": 40, "lawn_mow": 33, "lawyer": 15, "layabout": 43, "layer": [32, 36, 47, 51, 71, 80, 85, 157], "layer1": 51, "layered_violin": [16, 66, 140], "layered_violin_max_num_bin": [66, 140], "layout": [15, 48, 75, 130], "lbfg": [45, 46], "ldl": 97, "le": 77, "lead": [15, 38, 39, 42, 43, 55, 59, 63, 74, 85, 86, 87, 90], "leaf": [9, 52, 56, 65, 84, 91, 148], "leaf_beetl": 33, "leafhopp": 33, "leagu": 161, "learn": [5, 11, 13, 16, 18, 19, 28, 29, 30, 31, 33, 34, 35, 38, 39, 40, 47, 50, 56, 59, 61, 68, 80, 82, 84, 91, 95, 97, 107, 110, 131, 153, 156, 157, 158, 161, 162], "learning_phase_flag": [32, 80], "learning_r": [5, 11, 16, 40, 53, 54, 56, 57, 59, 60, 64, 65, 66], "least": [3, 17, 19, 39, 53, 62], "leatherback_turtl": 33, "leav": [25, 39, 40, 48, 67, 74, 112], "lee": 80, "left": [9, 15, 16, 32, 37, 39, 42, 48, 63, 75, 127, 128, 139, 140], "left_on": 62, "left_weight": 65, "leg": 15, "legaci": [8, 89], "legal": 40, "legend": [11, 19, 39, 48, 127, 128, 140, 161], "legend_label": [11, 128], "legend_loc": [11, 128], "legendari": 62, "legendarykil": 62, "lemon": 33, "len": [7, 11, 18, 19, 20, 25, 26, 27, 28, 29, 33, 36, 37, 39, 46, 47, 48, 49, 63, 65, 71, 73, 75, 151], "length": [15, 38, 55, 69, 80, 85, 101, 123, 133, 136, 140], "lenon": [84, 91], "lens_cap": 33, "lens_list": 64, "leonberg": 33, "leopard": 33, "leslei": 15, "less": [10, 11, 14, 17, 39, 40, 50, 62, 66, 69, 81, 86, 90, 130, 139], "lesser_panda": 33, "lesson": 15, "let": [11, 16, 29, 33, 39, 42, 45, 46, 52, 53, 66, 74], "letter": 25, "letter_open": 33, "level": [14, 15, 39, 43, 48, 93, 97, 131], "lgb": [11, 54, 64], "lgbmclassifi": 11, "lhasa": 33, "li": 65, "liam": 74, "lib": [25, 47, 48, 51, 59], "librari": [3, 5, 16, 33, 38, 43, 45, 46, 47, 50, 51, 53, 54, 55, 59, 60, 61, 62, 71, 82, 135, 161], "licens": 98, "lie": [11, 52], "life": [15, 39], "lifeboat": [29, 33], "light": [14, 48, 54, 63, 138], "lighter": 33, "lightgbm": [3, 11, 39, 61, 64, 84, 91, 104, 161], "like": [3, 5, 6, 8, 9, 10, 11, 14, 15, 16, 30, 31, 38, 39, 41, 42, 43, 57, 59, 62, 66, 71, 72, 74, 77, 80, 82, 84, 85, 86, 90, 91, 105, 106, 107, 109, 110, 112, 138, 147, 153], "likelihood": 68, "likewis": [11, 74], "liklihood": 76, "liklilhood": 76, "lil": 86, "lime": 106, "lime_tabular": 106, "limetabularexplain": 106, "limit": [4, 6, 17, 20, 47, 74, 84, 91, 128, 138], "limit_grid": 26, "limousin": 33, "limpkin": 33, "lin_regr": 45, "linalg": [49, 52], "line": [11, 14, 15, 27, 32, 38, 39, 48, 52, 54, 55, 59, 62, 64, 128, 138], "linear": [3, 11, 14, 15, 37, 40, 42, 50, 63, 81, 82, 86, 87, 88, 90, 96, 100, 105, 106, 107, 108, 109, 110, 115, 158], "linear_lr": 46, "linear_model": [38, 41, 43, 45, 46, 52, 86, 87, 90], "lineardml": 39, "linearexplain": 161, "linearize_link": [78, 81, 82, 84, 88, 89, 91, 108, 142], "linearli": [80, 84, 91], "linearregress": [38, 41, 45, 52], "linearsegmentedcolormap": [14, 55, 132, 133, 138, 140], "liner": 33, "linestyl": [14, 48], "linewidth": [14, 39, 48, 55], "link": [11, 17, 27, 44, 47, 62, 74, 78, 81, 82, 84, 86, 87, 88, 89, 90, 91, 98, 105, 106, 107, 108, 109, 110, 128, 130, 142], "linkag": [39, 48, 147], "linspac": [19, 39, 62], "linter": 3, "linux": 3, "linux_x86_64": 47, "lion": [33, 74], "lionfish": 33, "lipoprotein": 97, "lipstick": 33, "list": [11, 15, 16, 26, 27, 29, 33, 36, 37, 38, 39, 44, 47, 48, 49, 51, 53, 60, 70, 73, 75, 79, 80, 82, 83, 84, 85, 86, 87, 89, 90, 91, 99, 101, 105, 106, 107, 108, 109, 110, 113, 119, 122, 123, 124, 125, 128, 129, 130, 131, 133, 134, 136, 138, 139, 140, 151, 153], "list_of_label": 47, "listdir": [26, 27], "liter": [101, 127, 133, 138, 147], "littl": [3, 43, 59, 62], "little_blue_heron": 33, "live": [15, 38, 43, 57, 62, 68], "living0": 68, "living1": 68, "living2": 68, "ll": [15, 72, 76, 79], "llama": 33, "llvmlite": 47, "lm": 124, "lmdbdict": 27, "lo": 77, "load": [13, 15, 19, 25, 30, 31, 32, 34, 35, 36, 38, 47, 50, 53, 59, 60, 61, 69, 70, 71, 73, 77, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 161], "load_data": [32, 36, 71], "load_dataset": [15, 19, 22, 23, 24, 38, 70, 72, 73, 74, 75], "load_diabet": 97, "load_imag": [26, 27], "load_linnerud": 102, "load_model": 64, "load_state_dict": 27, "load_svmlight_fil": [64, 92], "load_weight": 25, "loader": 27, "loafer": 33, "loan": 40, "loc": [11, 39, 48, 57, 62, 79], "local": [11, 47, 56, 68, 86, 89, 91, 126, 158], "local_scratch": 62, "local_smooth": [30, 31, 85], "localhost": 38, "locat": [11, 25, 48, 128, 151], "lock": 43, "log": [3, 11, 14, 17, 20, 26, 27, 37, 38, 40, 43, 44, 55, 62, 63, 68, 74, 81, 82, 84, 86, 87, 90, 91, 97, 105, 106, 107, 108, 109, 110, 122, 124, 128, 130], "log_loss": [58, 84, 91], "log_odd": 56, "log_scal": 127, "logarithm": [84, 91], "loggerhead": 33, "logging_level": 64, "logist": [11, 17, 39, 50, 55, 58, 62, 64, 81, 161], "logisticregress": [38, 43, 46], "logit": [11, 15, 24, 26, 27, 38, 39, 44, 56, 69, 70, 72, 73, 75, 81, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110, 122, 124, 128, 130], "logit_explain": 70, "logit_predict": 20, "logit_shap_valu": 70, "logloss": [38, 55, 59, 62, 64], "logodd": [122, 124], "logreg": 71, "lola": 43, "lone": 11, "long": [3, 33, 39], "longer": [3, 26, 27, 38, 39, 44, 50, 52, 81, 98, 116, 119], "longest": 62, "longesttimespentliv": 62, "longitud": [38, 48, 94], "look": [3, 15, 39, 43, 57, 59, 67, 68, 74, 76, 80], "loos": 43, "lorikeet": 33, "lose": [15, 62], "loss": [9, 11, 20, 27, 32, 36, 37, 38, 47, 51, 55, 71, 80, 82, 84, 85, 86, 90, 91, 93, 105, 106, 107, 109, 110, 112, 136, 161], "loss_funct": 53, "loss_predict": 20, "lost": [15, 39], "lot": [3, 39, 42, 50, 62], "lotion": 33, "loudspeak": 33, "loung": 15, "loup": 33, "lovabl": 15, "love": [15, 43, 70, 73, 76], "low": [9, 11, 14, 16, 17, 36, 53, 62, 63, 66, 79, 97], "low_memori": 62, "lower": [11, 15, 30, 31, 40, 43, 53, 62, 86, 90, 91, 128, 139], "lower_bound": 83, "lp": 77, "lplb": 60, "lr": [37, 52, 64], "lr_pred": 52, "lstm": 162, "lstsq": 49, "lt": [10, 15, 17, 18, 19, 21, 23, 24, 28, 33, 36, 38, 40, 43, 45, 47, 51, 52, 53, 72, 75], "lumbermil": 33, "lundberg": [39, 80], "luxuri": 15, "lycaenid": 33, "lydiat": 74, "lynx": 33, "m": [4, 11, 15, 27, 42, 43, 44, 48, 49, 50, 57, 59, 67, 72, 73, 74, 76], "macaqu": 33, "macaw": 33, "machin": [2, 5, 38, 39, 40, 44, 50, 51, 54, 55, 82, 84, 91, 95, 131, 156, 157, 158, 161, 162], "macro": 43, "macroeconom": 39, "mad": [15, 43], "madagascar_cat": 33, "made": [3, 9, 10, 12, 14, 15, 17, 39, 43, 50, 59], "madelein": 43, "madr": 15, "mae": 47, "magic": 62, "magicdmgdealt": 62, "magicdmgtaken": 62, "magicdmgtochamp": 62, "magnetic_compass": 33, "magnific": 43, "magnitud": [10, 36, 38, 44, 52, 53, 54, 55, 62, 130, 141], "magpi": 33, "mahalanobi": 119, "mai": [3, 11, 14, 15, 26, 27, 32, 39, 40, 43, 50, 54, 55, 62, 128, 138], "mailbag": 33, "mailbox": 33, "maillot": 33, "main": [8, 11, 39, 52, 63, 84, 91, 142], "main_effect": [78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 142], "main_effect_shap_valu": 52, "mainli": 153, "maintain": 43, "mainten": 3, "major": 3, "make": [5, 10, 11, 14, 15, 17, 26, 27, 32, 38, 39, 40, 43, 44, 47, 48, 51, 52, 54, 55, 56, 62, 66, 70, 75, 82, 85, 86, 87, 90, 105, 106, 107, 108, 109, 110, 125, 127, 128, 140], "make_answer_scor": 69, "make_dir": [26, 27], "make_regress": 47, "maker": 39, "makser": 88, "malamut": 33, "male": [11, 66], "malevol": 15, "malinoi": 33, "maltese_dog": 33, "man": [15, 43, 57, 63, 68, 72], "manag": [3, 39, 43], "manhole_cov": 33, "mani": [4, 6, 11, 15, 16, 20, 36, 38, 39, 41, 42, 43, 46, 53, 76, 80, 81, 82, 83, 85, 86, 87, 89, 90, 105, 106, 107, 108, 109, 110, 126, 127, 128, 131, 140], "manifest": 40, "manifold": 55, "maniplut": 47, "manipul": [4, 6, 39, 139], "manner": 157, "manti": 33, "manual": [3, 11, 39, 47], "many0": 76, "map": [10, 13, 14, 26, 27, 34, 35, 44, 51, 60, 66, 81, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110, 130, 138], "map2lay": 30, "map_loc": 27, "mapl": 110, "maraca": 33, "margin": [17, 39, 40, 48, 52, 62, 63, 84, 91], "marginal_effect": 39, "marimba": 33, "marit": [4, 6, 9, 11, 44, 51, 93], "mark": [3, 11, 130], "markdown": 3, "marker": [14, 43, 127], "marmoset": 33, "marmot": 33, "marri": 11, "mashed_potato": 33, "mask": [7, 13, 18, 21, 22, 23, 24, 26, 27, 28, 29, 33, 34, 35, 48, 69, 70, 72, 73, 74, 75, 78, 81, 82, 86, 87, 88, 89, 90, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 119, 120, 122, 123, 124, 131, 142, 149, 151], "mask_count": [26, 27], "mask_shap": [111, 112, 120], "mask_token": [68, 72, 74, 76, 120], "mask_typ": 20, "mask_val": 19, "mask_valu": [26, 27, 114], "masked_arg": [82, 86, 87, 90, 105, 106, 107, 108, 109, 110], "masked_capt": 26, "masked_fil": 26, "masked_imag": [19, 26, 27], "maskedmodel": [18, 21, 22, 23, 24], "masker": [4, 6, 9, 13, 15, 19, 20, 22, 23, 24, 28, 29, 32, 33, 34, 35, 38, 48, 51, 68, 69, 70, 73, 75, 76, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 142, 158], "masker2": 72, "masker_blur": [28, 29, 33], "masker_explain": 48, "masker_load": [78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110], "masker_sav": [78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110], "masker_winter_valu": 48, "mass": 97, "massiv": [68, 76], "massive0": 76, "master": [0, 1, 2, 3, 25, 27, 32, 71, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162], "masterpiec": 43, "match": [11, 38, 39, 42, 48, 52, 63, 80, 85, 116, 119, 120], "matchid": 62, "matchstick": 33, "materi": 48, "math": 161, "mathemat": 40, "matplotlib": [3, 10, 11, 14, 19, 20, 25, 39, 48, 51, 55, 60, 62, 63, 75, 126, 127, 128, 130, 132, 133, 138, 140, 141], "matric": [9, 11, 32, 80, 84, 89, 153], "matrix": [9, 11, 12, 14, 42, 48, 52, 63, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 96, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 126, 127, 128, 129, 130, 131, 132, 133, 136, 140, 147, 149], "matter": [6, 15, 42, 50, 52, 53, 54, 55, 57, 62], "max": [10, 12, 14, 15, 26, 27, 31, 37, 38, 39, 40, 51, 52, 56, 65, 80, 83, 85], "max_ab": [80, 85], "max_bin": [11, 54, 64], "max_column": 24, "max_colwidth": 24, "max_delta_step": [5, 59], "max_depth": [5, 12, 38, 39, 40, 45, 46, 52, 55, 56, 59, 63, 64, 65, 67], "max_displai": [9, 10, 12, 16, 17, 38, 126, 127, 131, 132, 140, 141], "max_ev": [13, 18, 19, 26, 27, 28, 29, 33, 34, 35, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110], "max_featur": 71, "max_it": 38, "max_length": [15, 24, 38, 73, 76], "max_point": 39, "max_pooling2d": 32, "max_pooling2d_1": 32, "max_row": 24, "max_sampl": [38, 116, 119], "max_swap_s": 146, "maxd": 65, "maximum": [9, 10, 12, 15, 16, 38, 40, 80, 85, 116, 119, 128, 132, 139, 141], "maxlen": 71, "maxpool2d": 37, "maxpooling2d": 32, "mayb": [15, 43], "maypol": 33, "maze": 33, "mb": 38, "md": 27, "me": [15, 43], "mean": [9, 10, 11, 12, 14, 15, 17, 28, 31, 38, 39, 40, 42, 43, 44, 45, 48, 50, 51, 52, 54, 56, 57, 59, 62, 65, 66, 67, 69, 70, 71, 72, 81, 84, 87, 88, 91, 107, 110, 115, 116, 119, 120, 127, 129, 131, 132], "meaning": [26, 27, 47, 105], "meaningless": [54, 55], "meant": [15, 38, 45, 67, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 111, 112, 115, 117, 121, 122, 123, 124, 125, 136], "measur": [4, 6, 9, 12, 14, 20, 38, 39, 42, 63, 71, 101, 102, 158, 159], "measuring_cup": 33, "meat_loaf": 33, "mechan": [39, 122, 124], "med": 44, "median": [38, 44, 46, 53, 94], "medic": 63, "medicine_chest": 33, "medinc": [38, 48, 53, 94], "medium": 39, "meerkat": 33, "meet": [15, 43], "megalith": 33, "mel": 15, "member": [15, 38], "memori": [27, 38, 86, 90], "men": [9, 40, 57], "mental": 43, "mention": [43, 66], "menu": [15, 33, 47], "mere": 39, "merg": [3, 15, 30, 31, 39, 62, 111], "messi": 43, "meta": 3, "method": [4, 6, 7, 8, 9, 11, 14, 20, 40, 46, 47, 48, 54, 55, 58, 62, 70, 71, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 128, 129, 142, 143, 147], "metric": [2, 11, 27, 32, 36, 40, 43, 47, 54, 71, 119, 131, 147, 148, 150], "metro": 74, "mexican_hairless": 33, "mi": 15, "microphon": 33, "microsoft": [26, 39, 104], "microwav": 33, "mid": [38, 39, 42], "middl": [66, 75], "middle_color": 14, "might": [11, 15, 26, 38, 40, 57, 63, 87, 98, 153], "mighti": 43, "migrat": [1, 158], "mike": 74, "mildli": 36, "mileston": 3, "military_uniform": 33, "milk_can": 33, "millionair": 15, "mimic": [11, 122, 124], "min": [26, 39, 40, 62, 80, 85], "min_child_weight": [5, 59], "min_data": [11, 54], "min_df": 43, "min_perc": 130, "min_samples_split": [45, 46], "mind": [11, 38, 43, 63], "mine": [68, 72], "mingw64": 3, "miniature_pinsch": 33, "miniature_poodl": 33, "miniature_schnauz": 33, "minibu": 33, "miniforge3": 25, "minim": [3, 4, 6, 39, 81, 120], "minimum": [80, 85, 128, 139], "minion": 62, "miniskirt": 33, "minivan": 33, "mink": 33, "minkowski": 119, "minor": [3, 84, 91], "minu": 129, "minut": [38, 55, 62, 70, 73], "miracl": 72, "misc": 27, "misclassifi": 11, "misfortun": 43, "mislead": 39, "miss": [5, 27, 43, 52, 56, 59, 63, 86, 90, 115, 160], "missil": 33, "mistak": 39, "mitig": [3, 40], "mitten": 33, "mix": 43, "mixing_bowl": 33, "ml": [39, 41, 50, 95], "mlp": 71, "mlpclassifi": 46, "mlpregressor": 45, "mnist": 157, "mnist_data": 37, "mnli": 75, "mobile_hom": 33, "mobilenet_v2": 28, "mobilenetv2": 157, "modal": [54, 55], "mode": [19, 32, 64, 80, 106], "model": [4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19, 30, 31, 32, 34, 35, 37, 42, 45, 46, 50, 53, 60, 61, 64, 66, 70, 72, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 98, 105, 106, 107, 108, 109, 110, 111, 112, 115, 116, 117, 118, 119, 128, 129, 130, 131, 133, 136, 137, 138, 141, 142, 147, 156, 157, 158, 159], "model0": 77, "model1": 77, "model2": [56, 77], "model_adult": 38, "model_adult_log_odd": 38, "model_adult_proba": 38, "model_arg": [72, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110], "model_args2": 72, "model_count": 11, "model_depth1": 59, "model_depth3": 59, "model_ebm": 38, "model_expected_valu": [38, 137], "model_fil": 64, "model_from_json": 25, "model_gener": 123, "model_i": 39, "model_ind": [54, 55], "model_infer": 122, "model_load": [78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110], "model_loss": 58, "model_output": [32, 56, 58, 84, 91], "model_outputs_": 40, "model_outputs_a": 40, "model_outputs_b": 40, "model_outputs_c": 40, "model_outputs_d": 40, "model_outputs_f": 40, "model_outputs_g": 40, "model_path": 27, "model_sav": [78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110], "model_scor": [18, 19, 22, 23, 24, 75], "model_select": [11, 20, 21, 39, 43, 44, 45, 46, 51, 54, 55, 59, 62, 63], "model_storag": 25, "model_t": 33, "model_tmp": 59, "model_train": 63, "model_typ": 123, "model_xgb": 38, "model_zoo": 27, "modelo": 77, "models0": 77, "modem": 33, "modern": [29, 33, 40, 43, 63], "modifi": [3, 60, 103], "modul": [27, 33, 37, 59, 63, 80, 85], "mod\u00e8l": 77, "molli": 15, "momentarili": 43, "momentum": 37, "monarch": 33, "monasteri": 33, "monei": [15, 39, 40, 74], "mongoos": 33, "moni": 74, "monitor": [15, 33, 58], "monkei": 43, "monopoli": 15, "monoton": 50, "monotone_constraint": 5, "month": [3, 15, 39], "monthli": 39, "monti": 43, "mope": 33, "more": [3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 26, 27, 29, 33, 34, 35, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 54, 55, 56, 57, 59, 62, 63, 66, 68, 69, 70, 73, 74, 75, 76, 77, 80, 81, 82, 86, 87, 90, 93, 97, 102, 105, 106, 107, 108, 109, 110, 116, 119, 127, 128, 147], "morri": 15, "mortal": 63, "mortar": 33, "mortarboard": 33, "mosqu": 33, "mosquito_net": 33, "most": [3, 9, 10, 11, 14, 15, 16, 19, 26, 27, 29, 32, 33, 38, 39, 40, 42, 44, 50, 53, 62, 63, 66, 71, 72, 79, 84, 86, 90, 91, 119], "mother": 15, "motif": 25, "motion": 43, "motiv": [38, 55, 57], "motor_scoot": 33, "mountain": 68, "mountain_bik": 33, "mountain_t": 33, "mous": [33, 70, 73], "mousetrap": 33, "mouth": 43, "move": [11, 15, 17, 40, 74, 141], "moveaxi": 28, "movement": 43, "movi": [15, 43, 99], "moving_van": 33, "mre": 3, "mt": [15, 23, 77], "mu": 42, "much": [3, 4, 6, 8, 9, 14, 15, 20, 29, 33, 38, 39, 40, 43, 47, 48, 54, 55, 62, 71, 91, 126, 133, 144, 152], "mud": 68, "mud_turtl": 33, "multi": [15, 20, 26, 27, 41, 71, 80, 85, 102, 126, 130, 132, 157, 161, 162], "multiclass": [2, 19, 46, 53, 73, 102, 162], "multiindex": 67, "multimod": 16, "multioutput_decision_plot": 11, "multipl": [7, 9, 11, 19, 36, 39, 42, 52, 80, 85, 86, 87, 90, 91, 126, 128, 138, 153], "multipli": [63, 107, 110], "multiply_by_input": [107, 110], "multivari": 42, "mushroom": 33, "music": 43, "must": [11, 15, 38, 43, 45, 46, 47, 50, 51, 53, 54, 55, 59, 60, 61, 62, 65, 71, 80, 85, 120, 147], "mutat": 25, "mutual": [15, 40], "muzzl": 33, "my": [15, 69, 74, 76], "my0": 76, "my_dependence_plot": 14, "mysteri": 68, "m\u00e1": 77, "n": [3, 9, 11, 14, 20, 25, 27, 37, 38, 39, 40, 47, 48, 50, 52, 53, 57, 59, 62, 67, 77, 80, 128, 154], "n0": 77, "n11": 77, "n_compon": 55, "n_estim": [5, 11, 12, 20, 21, 38, 40, 45, 46, 48, 56, 57, 59, 65], "n_eval": 28, "n_featur": 47, "n_inform": 47, "n_input": 47, "n_job": [5, 59], "n_output": 47, "n_point": [8, 9, 20, 38, 53, 60, 65, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "n_sampl": 47, "n_target": 47, "nage": 14, "nail": 33, "naiv": 11, "nal": 77, "name": [3, 8, 9, 11, 13, 14, 15, 16, 17, 20, 28, 29, 30, 31, 33, 34, 35, 38, 39, 43, 47, 48, 51, 54, 55, 60, 62, 63, 70, 73, 82, 83, 84, 86, 87, 90, 91, 105, 106, 107, 108, 109, 110, 120, 122, 124, 128, 129, 130, 131, 133, 136, 138, 140], "namespac": 1, "nan": [5, 138], "nanpercentil": 39, "narr": 11, "narrow": 62, "nasti": 43, "nateraw": [24, 70, 73], "nativ": [69, 74, 77], "natur": [39, 68, 70, 75, 81, 82, 84, 86, 87, 90, 91, 105, 106, 107, 108, 109, 110], "naux": 77, "navig": [3, 27], "nbsphinx": [3, 42], "nbviewer": [56, 65], "ncaption": 27, "nchw_to_nhwc": 28, "ncsu": 16, "ndarrai": [15, 16, 28, 38, 65, 80, 83, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 115, 116, 119, 122, 123, 124, 126, 128, 132, 133, 147, 154], "ndo": 77, "ne": 77, "ne0": 77, "ne3": 77, "ne5": 77, "nearbi": [68, 148], "nearest": 39, "nearli": 50, "necessari": [3, 15, 38, 130, 135], "necessarili": [38, 57], "neck": [29, 33], "neck_brac": 33, "necklac": 33, "need": [3, 4, 5, 9, 14, 26, 27, 33, 38, 39, 42, 43, 53, 62, 73, 74, 76, 79, 80, 81, 82, 84, 86, 87, 90, 91, 105, 106, 107, 108, 109, 110, 114], "neg": [11, 15, 16, 17, 18, 20, 21, 23, 24, 39, 40, 43, 53, 56, 60, 62, 66, 74, 76, 77, 99, 162], "neighbor": 48, "neighbour": 48, "neither": 57, "nematod": 33, "nessecarili": 62, "nest": [4, 6, 15, 38, 48, 68, 83, 88], "net": [36, 37], "network": [30, 31, 36, 38, 51, 77, 158], "network0": 77, "network1": 77, "network10": 77, "network7": 77, "networkx": 48, "neural": [38, 51, 77, 158], "neural0": 77, "neural1": 77, "neural2": 77, "neural9": 77, "neural_network": [45, 46], "neuro": 77, "neutral": [62, 75], "neutralminionskil": 62, "never": [3, 15, 43], "new": [1, 3, 5, 11, 18, 21, 22, 23, 24, 38, 39, 40, 41, 44, 48, 59, 68, 74, 82, 83, 84, 86, 87, 89, 90, 91, 105, 106, 107, 108, 109, 110, 114, 120, 122, 124, 125, 158], "new_base_valu": [11, 128], "new_self_crit": 27, "newer": 32, "newfoundland": 33, "newli": 68, "newport": 74, "newspap": 74, "newton": 46, "next": [11, 15, 20, 26, 27, 29, 33, 37, 38, 40, 63, 74, 124, 160], "next_one_port": 65, "nextx": 48, "nhane": [103, 161], "nhanesi": 63, "nhwc_to_nchw": 28, "nice": [48, 55, 88, 97, 99, 103, 125], "nicknam": 15, "night": 72, "night_snak": 33, "nip": 80, "nippl": 33, "nll_loss": 37, "nload": 26, "nloglik": 63, "nlp": [15, 19, 22, 23, 24, 77], "nlp0": 77, "nlp1": 77, "nlp6": 77, "nn": [37, 45, 46, 80, 85], "nnumber": [26, 27], "no_grad": [37, 74], "no_repeat_ngram_s": 76, "noccup": 11, "node": [39, 48, 56, 65, 80, 85, 139], "node_color": 48, "node_index": 65, "node_s": 48, "node_sample_weight": [56, 65], "node_sample_weight1": 56, "node_sample_weight2": 56, "nof": 40, "nogil": 65, "nois": [30, 31, 39, 96, 100], "noiser": 39, "nomin": 43, "non": [14, 15, 30, 31, 32, 40, 42, 48, 50, 52, 57, 63, 81, 88], "none": [5, 11, 15, 16, 24, 25, 26, 27, 32, 33, 39, 40, 43, 45, 46, 47, 48, 49, 56, 59, 64, 67, 69, 71, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 101, 102, 103, 105, 106, 107, 108, 109, 110, 114, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 133, 136, 137, 138, 139, 140, 142, 143, 144, 147, 155], "nonlinear": 15, "nopython": 65, "norfolk_terri": 33, "norm": [52, 80], "normal": [3, 28, 30, 31, 39, 42, 51, 79, 108, 116, 119, 138], "norwegian_elkhound": 33, "norwich_terri": 33, "notabl": [11, 66], "notat": [14, 42], "note": [4, 5, 6, 9, 11, 14, 15, 17, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63, 65, 66, 67, 69, 70, 71, 76, 78, 80, 83, 84, 85, 86, 87, 88, 91, 93, 94, 96, 97, 98, 99, 100, 101, 102, 104, 120, 136, 138, 142, 151, 153, 158], "notebook": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 29, 30, 31, 33, 34, 35, 38, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 135, 156, 157, 159, 161, 162], "notebook1": 3, "notebook2": 3, "notebook_tqdm": [48, 51], "notebooks_html": 88, "noth": [39, 43], "notic": [11, 39, 74], "notion": 40, "noutput": 32, "now": [4, 6, 8, 9, 11, 14, 16, 39, 40, 41, 43, 48, 50, 52, 57, 58, 63, 64, 68, 69, 74, 76, 78, 84, 87, 91, 98], "now0": 74, "now1": 74, "np": [11, 15, 18, 19, 20, 24, 25, 26, 27, 28, 30, 31, 32, 33, 37, 38, 39, 40, 43, 45, 46, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 62, 63, 64, 65, 67, 69, 71, 72, 73, 74, 75, 79, 80, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 114, 124, 126, 133, 147, 151], "npermut": 89, "npoint": 137, "nrelationship": 11, "nsampl": [31, 36, 47, 51, 85, 86, 87, 90, 153], "nskip": 26, "ntest": 37, "nthread": 59, "nudg": 39, "num": [11, 14, 44, 51, 93, 134], "num2word": 71, "num_boost_round": [39, 62, 64], "num_channel": 25, "num_class": [32, 38], "num_epoch": 37, "num_featur": [86, 90], "num_feature_data": 64, "num_imag": 27, "num_it": 64, "num_leav": [11, 54, 64], "num_of_output": [18, 19], "num_output": [80, 85, 86, 87, 90, 91], "num_parallel_tre": 5, "num_pass": 146, "num_plot_row": 20, "num_sampl": [39, 80, 85, 86, 87, 90, 91], "num_shuf": 25, "num_starting_label": 139, "num_word": 71, "numba": 47, "number": [3, 4, 6, 9, 10, 14, 15, 16, 26, 27, 28, 29, 30, 31, 33, 36, 38, 39, 42, 44, 45, 46, 47, 48, 58, 66, 69, 71, 80, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 116, 119, 127, 128, 130, 132, 133, 139, 140, 141, 153], "number_pati": 63, "numer": [53, 62, 93, 128], "numpi": [3, 8, 11, 15, 16, 18, 19, 20, 24, 25, 26, 27, 28, 30, 31, 32, 33, 37, 38, 39, 40, 43, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 62, 63, 64, 65, 67, 69, 71, 72, 73, 74, 75, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 101, 104, 105, 106, 107, 108, 109, 110, 115, 116, 119, 122, 123, 124, 126, 128, 129, 130, 131, 132, 133, 134, 136, 139, 140, 147], "nvcc": 5, "nvida": 5, "nvidia": [5, 38], "nx": 48, "o": [4, 26, 27, 33, 48, 64], "obelisk": 33, "obj": [53, 143], "object": [0, 1, 8, 9, 11, 14, 15, 17, 32, 38, 39, 54, 55, 56, 59, 62, 64, 70, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 113, 118, 121, 122, 123, 124, 125, 126, 127, 128, 130, 132, 133, 138, 140, 141, 142, 143], "obo": 33, "obscur": 40, "observ": [11, 14, 15, 38, 40, 43, 53, 59, 62, 63, 70, 86, 90, 115, 128], "obtain": [11, 57], "obvious": 74, "ocarina": 33, "occup": [11, 44, 51, 93, 94], "occur": [39, 40], "ocp": 26, "octet": 26, "octob": 74, "odd": [11, 14, 17, 38, 40, 43, 44, 55, 62, 63, 68, 74, 81, 82, 84, 86, 87, 90, 91, 105, 106, 107, 108, 109, 110, 122, 124, 128, 130], "odomet": 33, "of0": [68, 77], "of1": 68, "of13": 77, "of5": 77, "off": [14, 15, 20, 38, 39, 40, 50, 52, 55, 63, 67, 74, 84, 91], "offer": [16, 39], "offici": 74, "offset": 40, "offset_map": [73, 120], "offset_rang": 73, "often": [4, 6, 7, 9, 11, 14, 15, 26, 27, 39, 40, 41, 43, 50, 57, 59, 86, 136], "oil_filt": 33, "old": [5, 14, 48, 63], "old_english_sheepdog": 33, "old_stderr": 27, "old_stdout": 27, "older": [53, 77], "older0": 77, "older1": 77, "older11": 77, "older6": 77, "omit": [11, 43, 45, 46, 47, 50, 51, 53, 54, 55, 59, 60, 61, 62, 71], "onc": [5, 9, 15, 26, 27, 39, 42, 58, 62, 70, 89], "one": [3, 6, 9, 11, 13, 15, 16, 20, 25, 27, 34, 35, 36, 38, 39, 40, 43, 48, 53, 57, 60, 65, 67, 69, 71, 72, 73, 74, 80, 84, 85, 86, 87, 89, 90, 91, 97, 120, 126, 138, 141, 147], "one_fract": 65, "one_hot_axi": 25, "one_hot_encode_along_channel_axi": 25, "oneapi": 38, "onednn": 38, "onehot_data": 25, "ones": [7, 16, 57, 65, 66, 67, 74], "onli": [4, 6, 9, 11, 15, 17, 27, 28, 38, 39, 40, 46, 47, 50, 52, 58, 62, 63, 64, 66, 67, 69, 71, 72, 74, 75, 78, 80, 84, 85, 87, 88, 90, 91, 98, 105, 108, 109, 120, 122, 126, 127, 130, 135, 138, 142], "onto": [25, 39, 63, 126, 127, 132, 138], "op": [80, 86, 143], "opac": 40, "opaqu": 40, "opchain": [83, 126, 132], "open": [3, 11, 13, 18, 19, 25, 26, 28, 29, 30, 31, 33, 34, 35, 38, 72, 157, 162], "openaigpt": [26, 27], "oper": [26, 37, 38, 83, 143], "opportun": 40, "oppos": 90, "opt": 27, "optim": [4, 6, 9, 32, 36, 37, 38, 47, 51, 71, 81, 149, 158], "option": [3, 14, 26, 27, 38, 39, 47, 58, 66, 82, 84, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 116, 119, 120, 128, 133, 138, 144, 152], "opu": [15, 23, 77], "or_model": 67, "orang": 33, "orangutan": 33, "order": [3, 4, 5, 9, 19, 20, 26, 32, 37, 38, 50, 55, 63, 66, 67, 70, 72, 73, 78, 80, 81, 85, 88, 89, 91, 126, 127, 128, 129, 132, 139, 144, 148, 152], "ordering_kei": 130, "ordering_keys_time_format": 130, "ordin": 3, "org": [3, 16, 47, 56, 65, 99], "organ": 33, "organis": 3, "orid": 60, "orient": 55, "orig_model": 56, "orig_model2": 56, "origin": [5, 6, 10, 11, 14, 15, 26, 27, 29, 30, 31, 33, 39, 40, 43, 51, 56, 63, 70, 73, 84, 91, 93, 98, 101, 113, 120, 124, 132], "orign": 15, "orn": 68, "oscar": 43, "oscilloscop": 33, "osmodel": 27, "osprei": 74, "ostrich": 33, "other": [3, 4, 5, 6, 9, 11, 15, 16, 20, 21, 26, 27, 36, 37, 38, 39, 40, 43, 44, 48, 50, 52, 53, 54, 55, 57, 59, 62, 66, 69, 83, 144, 152, 158], "otherwis": [14, 39, 84, 86, 90, 91, 93, 126, 127, 128, 132, 147], "otter": 33, "otterhound": 33, "ouput": 15, "our": [3, 9, 11, 14, 16, 36, 38, 39, 40, 42, 47, 57, 59, 65, 71, 72, 74, 80, 84, 91, 141, 143], "ourselv": 59, "out": [7, 11, 13, 14, 15, 20, 26, 27, 28, 29, 33, 34, 35, 36, 38, 39, 40, 43, 45, 46, 51, 55, 58, 66, 67, 69, 70, 72, 73, 74, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 114, 116, 119, 120, 142], "out_fil": [56, 67, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "out_nam": [69, 130], "outcom": [9, 38, 39, 40, 52, 54, 55, 63, 76], "outlier": [16, 19, 66, 140], "outlin": [14, 38, 42, 55], "output": [4, 6, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 44, 46, 50, 51, 52, 53, 54, 55, 56, 57, 62, 63, 67, 68, 69, 71, 72, 74, 75, 77, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 113, 118, 122, 123, 124, 125, 129, 130, 131, 133, 134, 139, 140, 141, 151, 158, 161], "output_dim": 33, "output_id": 122, "output_index": [83, 88], "output_margin": [9, 20, 52], "output_nam": [13, 18, 19, 24, 26, 27, 28, 29, 33, 34, 35, 69, 73, 75, 82, 83, 86, 87, 88, 90, 105, 106, 107, 108, 109, 110], "output_rank_ord": [80, 85], "output_token": 139, "output_typ": [69, 120], "outsid": 66, "oval": 39, "over": [3, 5, 6, 7, 9, 10, 11, 12, 14, 15, 17, 20, 29, 32, 33, 38, 39, 44, 48, 53, 54, 55, 59, 63, 67, 68, 70, 71, 73, 74, 80, 82, 83, 85, 86, 87, 89, 90, 105, 106, 107, 108, 109, 110, 116, 119, 129, 136, 153], "overal": [11, 12, 15, 16, 38, 39, 66], "overcom": 72, "overfit": 39, "overlai": [15, 39, 138], "overlaid": 38, "overrid": 128, "overridden": [82, 86, 87, 90, 105, 106, 107, 108, 109, 110, 111, 112, 115, 117, 121, 122, 123, 124, 125], "oversea": 74, "overskirt": 33, "overview": [15, 53, 63, 81, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110, 158], "owen": [48, 81, 82, 86, 87, 88, 90, 105, 106, 107, 108, 109, 110], "owen3": 88, "own": [14, 26, 27, 29, 33, 39, 43, 62, 80], "ownjunglekil": 62, "ox": 33, "oxcart": 33, "oxygen_mask": 33, "oystercatch": 33, "p": [11, 38, 39], "p11": 99, "p_": 42, "packag": [3, 11, 15, 25, 27, 38, 39, 43, 47, 48, 51, 59, 63, 73, 91, 97, 99, 101, 102, 103], "packet": 33, "pad": [15, 24, 38, 71, 73, 74, 122, 123, 124, 133], "pad_sequ": 71, "pad_token_id": 76, "padding_sid": [122, 123, 124], "paddl": 33, "paddlewheel": 33, "padlock": 33, "padr": 15, "page": [0, 3, 56, 65, 157, 161], "pai": 33, "paid": 26, "paintbrush": 33, "pair": [9, 16, 39, 76, 80, 84, 85, 87, 91, 113, 127, 138, 140], "pairwis": 63, "pajama": 33, "pal": 15, "palac": 33, "panda": [24, 39, 40, 41, 47, 50, 57, 62, 64, 65, 67, 70, 73, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 115, 116, 119, 128, 136, 140], "pandoc": 3, "panpip": 33, "paper": [43, 54, 55, 63, 65, 99, 158], "paper_towel": 33, "papillon": 33, "para": 77, "parachut": 33, "parallel": [1, 10, 14, 83], "parallel_bar": 33, "param": [11, 26, 32, 54, 55, 62, 63, 64, 76], "paramat": [26, 27], "paramet": [3, 6, 9, 10, 11, 12, 14, 16, 26, 27, 29, 30, 31, 32, 33, 36, 37, 43, 60, 70, 76, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 113, 114, 115, 116, 118, 119, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 138, 139, 140, 141, 147, 151, 153, 160], "parent": 48, "parent_dict": 48, "parent_feature_index": 65, "parent_nam": 48, "parent_one_fract": 65, "parent_pweight": 65, "parent_zero_fract": 65, "pari": 74, "pariti": 40, "park": 68, "park_bench": 33, "parking_met": 33, "pars": [48, 87], "parse_prefix_suffix_for_model_generate_output": 123, "part": [4, 6, 9, 15, 20, 26, 27, 38, 39, 43, 68, 114, 126], "parti": 3, "partial": [9, 39, 54, 55, 62, 137, 138], "partial_depend": 14, "partial_dependence_plot": 38, "particip": 62, "particular": [3, 15, 16, 44, 68, 76, 79, 82], "particularli": [11, 27, 39, 40, 62, 88], "partit": [9, 13, 18, 19, 20, 22, 23, 24, 34, 35, 38, 48, 51, 66, 69, 70, 72, 73, 74, 77, 82, 86, 87, 88, 89, 90, 105, 106, 107, 108, 109, 110, 114, 115, 126, 139, 151, 157], "partition_explain": [48, 88], "partition_explainer_f": 48, "partition_explainer_nb": 48, "partition_explainer_nb2": 48, "partition_mask": [48, 51], "partition_tre": [48, 51, 88, 151], "partition_winter_values_b": 48, "partition_winter_values_f": 48, "partition_winter_values_nb": 48, "partition_winter_values_nb2": 48, "partitionexplain": [20, 48, 51], "partner": 39, "partridg": 33, "pass": [3, 4, 6, 9, 10, 11, 12, 14, 15, 16, 32, 36, 38, 39, 46, 48, 53, 56, 58, 60, 63, 69, 70, 73, 74, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 116, 118, 119, 120, 122, 123, 124, 126, 127, 130, 138, 140], "passenger_car": 33, "past": [43, 98], "pastur": 68, "pata": 33, "patch": [3, 68], "path": [3, 26, 27, 62, 64, 65, 84, 91], "path_index": 65, "path_to_imag": [26, 27], "pathet": 15, "pathlib": 62, "patient": [43, 63], "patio": 33, "patrick": [84, 91], "pattern": [4, 14, 39, 59, 63, 71], "paul": 43, "paxton": 72, "payload": 26, "pca": [41, 55, 129], "pci": 38, "pd": [24, 39, 40, 47, 50, 57, 61, 62, 64, 65, 67, 70, 73, 93, 94, 95, 96, 97, 100, 101, 102, 103], "pd_linewidth": 137, "pd_opac": 137, "pdf": 14, "pdist": [119, 147], "peacock": 33, "peak": 63, "pedest": 33, "pekines": 33, "pelican": 33, "pembrok": 33, "penalti": 43, "pencil_box": 33, "pencil_sharpen": 33, "penta": 62, "pentakil": 62, "peopl": [9, 10, 12, 14, 15, 17, 27, 40, 43, 55, 56, 63, 76], "people0": 76, "pep": 3, "pepto": 15, "per": [11, 16, 30, 31, 38, 39, 40, 51, 62, 80, 81, 93, 95], "perceiv": 39, "percent": [19, 39], "percentil": [14, 40, 66, 137, 138], "perfect": [38, 40, 46, 63], "perfectli": [9, 14, 39, 52], "perform": [3, 6, 9, 18, 19, 21, 22, 23, 24, 25, 37, 38, 43, 48, 84, 86, 91, 122, 123, 136, 153], "perfrom": 48, "perfum": 33, "perhap": 74, "period": [3, 39, 74], "permuat": 65, "permut": [1, 5, 20, 28, 38, 42, 44, 82, 86, 87, 89, 90, 105, 106, 107, 108, 109, 110, 157], "permutationexplain": 20, "perplex": 55, "persian_cat": 33, "person": [15, 17, 43, 57, 63], "persona": 15, "perspect": [12, 38], "perterb": 51, "perturb": [7, 9, 15, 19, 68, 69, 75, 88, 161], "petal": 101, "petri_dish": 33, "petti": 15, "phase": 80, "phi": [42, 49, 65, 86], "phi_0": 65, "phi_i": [42, 43], "phi_m": 65, "phi_symbol": 32, "phillip": 74, "phone": 33, "photocopi": 33, "physdmgtaken": 62, "physdmgtochamp": 62, "physic": 62, "physicaldmgdealt": 62, "physiolog": 102, "pick": [14, 33, 39, 40, 148], "pickelhaub": 33, "picker": 74, "picket_f": 33, "pickl": 11, "pickle_load": 27, "pickup": 33, "pictur": [15, 39, 43], "piec": [15, 39, 43], "pier": 33, "piggy_bank": 33, "pile": [10, 54, 55, 62, 66], "pill_bottl": 33, "pillow": [25, 33], "pin": 3, "pineappl": 33, "ping": 33, "pink": 62, "pinksbought": 62, "pinwheel": 33, "pip": [3, 25, 27, 47, 53, 158], "pipelin": [28, 39, 41, 69, 125, 161], "pirat": 33, "pitcher": 33, "piti": 15, "pitt": 43, "pitter": 32, "pivot_t": 64, "pixel": [26, 27, 29, 33, 133], "pixel_s": [26, 27], "pixel_valu": [28, 33, 133], "pizza": 33, "pkl": 27, "pkyg": 60, "pl": [55, 62, 63], "place": [3, 10, 26, 27, 40, 62, 68, 91, 138], "plai": [15, 27, 43, 62, 66, 67, 72], "plain_text": [38, 72, 75], "plan": [15, 39], "plane": 33, "planet": 43, "planetarium": 33, "plastic_bag": 33, "plate": 33, "plate_rack": 33, "platform": [37, 38], "platformid": 62, "platypu": 33, "player": [26, 38, 74, 85], "pleas": [3, 19, 20, 26, 27, 38, 48, 51, 56, 65, 84, 91], "plot": [3, 7, 8, 19, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 36, 37, 39, 40, 41, 43, 44, 51, 52, 53, 57, 61, 62, 68, 69, 71, 73, 74, 75, 76, 77, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110, 158, 161], "plot_cmap": [60, 130], "plot_color": 128, "plot_effect": 39, "plot_import": 55, "plot_siz": [16, 127, 140], "plot_typ": [16, 55, 59, 66, 140], "plot_weight": 25, "plot_width": 132, "plow": 33, "plt": [10, 11, 14, 19, 20, 39, 48, 51, 75, 141], "plu": [39, 67], "plunger": 33, "plural": 130, "pmasker": 20, "pmlr": [84, 91], "pmodel": [69, 72], "png": [26, 27, 48], "po": [25, 48, 73], "pod": 68, "point": [11, 16, 38, 39, 40, 45, 46, 54, 55, 57, 62, 63, 66, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 115, 128, 129, 132, 138, 140], "point_estim": 39, "point_pr": 39, "pointless": 38, "poisson": 39, "polar": 11, "polaroid_camera": 33, "pole": 33, "polecat": 33, "police_van": 33, "polici": 39, "pomegran": 33, "pomeranian": 33, "pomp": 15, "poncho": 33, "pond": 68, "pong_bal": 33, "pool": [64, 84, 91], "pool_siz": 32, "pool_tabl": 33, "pop_bottl": 33, "popul": [38, 43, 44, 48, 93, 94, 95, 132], "popular": [3, 40], "porcupin": 33, "portion": [15, 69, 70, 73, 120], "posit": [4, 5, 6, 7, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 39, 40, 43, 53, 60, 62, 66, 71, 75, 76, 80, 85, 99, 120, 162], "possibl": [3, 4, 14, 15, 39, 52, 54, 55, 74, 76, 86, 90, 91, 128], "possible0": 76, "post": [26, 58, 70, 73, 153], "post1": 47, "poster": 33, "pot": [33, 74], "potenti": [4, 6, 14, 39, 40, 55, 63, 83, 84, 91], "potential_interact": 14, "potpi": 33, "potter": 33, "pour": 77, "power": [4, 6, 39, 50, 63], "power_dril": 33, "powerset": 49, "pprint": 11, "pr": 32, "practic": [11, 38, 39, 40], "practition": 9, "prairie_chicken": 33, "prais": 43, "prayer_rug": 33, "pre": [3, 13, 27, 29, 30, 33, 34, 35, 63, 153], "prealloc": 65, "preced": 74, "precis": [40, 43], "precomput": [42, 48], "pred": [37, 39, 52, 63, 64, 70], "pred_contrib": [11, 64, 65], "pred_interact": 63, "pred_stderr": 39, "pred_x": 39, "predicit": [30, 31], "prediciton": 44, "predict": [4, 5, 6, 9, 10, 12, 14, 15, 16, 17, 20, 21, 25, 27, 28, 30, 31, 32, 37, 38, 40, 41, 48, 52, 53, 56, 60, 61, 64, 65, 66, 68, 69, 70, 72, 73, 80, 84, 86, 87, 90, 91, 94, 95, 97, 128, 141, 158, 159, 161, 162], "predict_log_proba": 38, "predict_proba": [4, 6, 7, 20, 38, 39, 44, 46, 53, 56, 58, 84, 91], "predict_shap": 64, "prediction_typ": 53, "predictor": [17, 39], "prefer": [3, 38, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110], "prefix": [27, 62, 123], "prehistor": 68, "preliminari": 136, "premis": 75, "prepar": 28, "preprocess": [15, 41, 71], "preprocess_data": 64, "preprocess_input": [13, 18, 19, 29, 30, 33, 34, 35], "preprocessing_delta": 64, "preprocessing_tim": 64, "presenc": 39, "present": [11, 14, 15, 25, 38, 40, 43, 52, 54, 55, 63, 80, 82, 84, 85, 86, 90, 91, 98, 105, 106, 107, 109, 110, 123], "preserv": 69, "pressur": [15, 63, 97], "pretrain": [27, 28, 30, 31, 68, 74, 76, 77, 122, 123, 124], "pretrainedtoken": [122, 123, 124], "pretrainedtokenizerbas": 120, "pretrainedtokenizerfast": [122, 123, 124], "pretti": [16, 43, 66], "pretzel": 33, "prevent": [11, 14, 87, 128], "previou": [3, 40, 48, 65], "previous": [39, 91], "price": [26, 38, 53], "primari": [11, 20, 63, 82, 112], "primarili": 139, "prime": 43, "princip": 39, "principl": [39, 40], "print": [11, 25, 26, 27, 28, 29, 32, 33, 36, 37, 38, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 59, 60, 64, 65, 71, 75, 128], "print_accuraci": [45, 46], "printer": 33, "prior": [15, 38, 42, 141], "prioriti": 57, "prioritis": 3, "prison": 33, "prob": [20, 75], "probabili": 17, "probabilist": 44, "probabilit": 72, "probabl": [11, 14, 17, 26, 27, 29, 33, 37, 38, 39, 40, 43, 46, 53, 54, 55, 56, 62, 72, 74, 75, 81, 82, 84, 86, 87, 90, 91, 105, 106, 107, 108, 109, 110, 128, 130], "problem": [3, 11, 26, 27, 39, 40, 44, 46, 54, 55, 77, 84, 86, 87, 91], "problema": 77, "problems0": 77, "problems1": 77, "problems2": 77, "problems3": 77, "probl\u00e8m": 77, "proboscis_monkei": 33, "procedur": [42, 86, 90], "proceed": 39, "process": [3, 9, 15, 17, 26, 27, 39, 40, 44, 51, 63, 69, 74, 76, 88, 93, 94, 95, 97, 98, 99], "produc": [3, 4, 5, 6, 11, 15, 26, 27, 39, 44, 69, 82, 86, 87, 88, 90, 105, 106, 107, 108, 109, 110, 128, 133, 140, 142, 157], "product": [39, 40], "profess": 15, "profession": 72, "profil": 40, "program": [3, 15, 32, 48, 51], "progress": [1, 28, 38, 45, 46, 86, 90, 97], "project": [3, 15, 25, 33, 39, 42, 63, 129, 160], "projectil": 33, "projector": 33, "promin": 11, "promis": 72, "promontori": 33, "promot": 40, "proof": 63, "proper": 39, "properli": 3, "properti": [38, 39, 41, 56, 69, 79, 83, 88], "propoerti": 14, "proport": 63, "propos": [3, 90, 91], "protect": 59, "protract": 74, "provid": [3, 5, 7, 11, 14, 15, 16, 27, 36, 39, 40, 43, 44, 49, 54, 55, 62, 63, 68, 73, 74, 76, 84, 87, 91, 93, 94, 95, 97, 99, 101, 102, 114, 120, 127, 128, 130, 140, 141, 147], "provoc": 43, "psychiatrist": 43, "pt": [74, 75, 122, 123, 124], "ptarmigan": 33, "pth": 27, "public": 0, "puck": 33, "puffer": 33, "pug": 33, "pull": [5, 6, 7, 9, 10, 12, 13, 14, 15, 16, 17, 20, 25, 29, 33, 34, 35, 38, 41, 44, 68, 69, 70, 71, 73, 74, 76, 77], "puls": 102, "pulse_pressur": 63, "punching_bag": 33, "purchas": 40, "pure": 43, "purpl": 48, "purpos": [11, 43], "purs": 33, "push": [15, 53], "put": [9, 39, 43, 74], "puzzl": 43, "pweight": 65, "py": [3, 5, 27, 32, 33, 47, 48, 51, 59, 71], "py3": 47, "py_util": 37, "pylab": [55, 63], "pypars": 25, "pypi": [3, 158], "pyplot": [10, 11, 14, 19, 20, 39, 48, 51, 62, 75, 126, 127, 128, 130, 132, 133, 138, 140, 141], "pyproject": 3, "pypsa": 3, "pyspark": [84, 91], "python": [5, 25, 27, 29, 33, 36, 38, 43, 47, 60, 73, 78, 81, 82, 87, 89, 161], "python3": [25, 47, 59], "pythonhost": 47, "pytorch": [15, 27, 32, 74, 77, 80, 85, 122, 123, 124, 157], "pytorchdeep": 32, "pytz": 47, "q": 69, "q_": 42, "q_test": 104, "q_train": 104, "quadra": 62, "quadrakil": 62, "quadrat": 88, "quail": 33, "qualif": 39, "qualiti": [3, 40], "quantif": [84, 91], "quantifi": 17, "quantit": [15, 39, 131, 158, 159], "quarter": [26, 27], "queri": 104, "question": [3, 43, 74, 76, 158], "quicker": 63, "quickli": [26, 40, 62], "quill": 33, "quilt": 33, "quit": [3, 15, 71], "r": [11, 27, 42, 48, 49, 73, 128], "r2": [4, 6], "r_": 42, "race": [11, 51, 74, 93], "racer": 33, "racism": 15, "racket": 33, "radiat": 33, "radio": [33, 74], "radio_telescop": 33, "rag": [15, 38], "railli": 43, "rain_barrel": 33, "rainbow": 14, "rais": [3, 25, 33, 62, 64, 84, 91, 127], "ram": 33, "ran": 15, "rand": [40, 49], "randal": 72, "randint": 40, "randn": [40, 49, 50, 59], "random": [4, 25, 32, 37, 39, 40, 42, 43, 48, 49, 50, 57, 59, 79, 80, 84, 85, 89, 91, 96, 98, 100, 138, 147, 153], "random_se": 53, "random_st": [5, 11, 20, 21, 39, 43, 44, 45, 46, 47, 51, 54, 55, 57, 59, 62, 63, 64, 147, 153], "randomforestclassifi": 46, "randomforestregressor": [45, 65], "randomforestregressorrandomforestregressor": 65, "randomli": [39, 40, 57, 93, 94, 95, 97, 98, 99, 101, 102, 151], "randomst": 147, "rang": [9, 14, 15, 16, 19, 20, 23, 26, 27, 32, 33, 36, 37, 38, 39, 47, 48, 49, 51, 52, 53, 59, 62, 63, 65, 69, 71, 128], "range1": 128, "range2": 128, "rank": [14, 62, 71, 80, 85, 129], "ranked_output": [30, 31, 80, 85], "rapese": 33, "rapid": 77, "rapidli": 77, "rapidly0": 77, "rapidly1": 77, "rapidly2": 77, "rapidly3": 77, "rapidly4": 77, "rapidly5": 77, "rare": [10, 50], "raster": 14, "rate": [26, 62], "rate_featur": 62, "rather": [8, 14, 39, 40, 42, 43, 45, 46, 54, 55, 63, 74, 112, 139], "ratio": [26, 44, 62, 84, 91, 97], "raw": [4, 6, 11, 25, 53, 84, 87, 91, 93, 128], "raw_data": 93, "raw_scor": 11, "raw_shap_explan": 25, "rawformulav": 53, "rb": [11, 25, 26, 27], "rbf": 46, "rcond": 49, "rdbu": [60, 130], "re": [3, 15, 16, 39, 66, 73, 74, 86, 89, 90, 116, 119], "reach": [15, 38], "read": [25, 26, 43, 62, 65, 66], "read_csv": [62, 64], "read_simdata_fil": 25, "readabl": [14, 16, 48, 63, 138], "reader": 3, "readi": 3, "readthedoc": [3, 48, 51], "real": [39, 40, 43, 59], "realis": 43, "realist": [4, 6, 15, 40, 43], "realiti": [15, 62], "realiz": 43, "realli": [39, 43, 59, 62, 63], "reason": [12, 20, 26, 27, 38, 39, 43, 74, 75, 116, 119], "rebuild": [37, 38], "recal": [15, 43], "receiv": 40, "recent": [3, 5, 32, 33, 72, 74], "recolor": 63, "recommend": [9, 26, 27, 29, 33, 43, 130], "record": [11, 84, 91, 93], "recreat": 48, "recreational_vehicl": 33, "recurr": 77, "recurrent": 77, "recurrent0": 77, "recurrent1": 77, "recurrent12": 77, "recurrent3": 77, "recurrent5": 77, "recurrent_dropout": 71, "recurs": [4, 6, 48, 65, 88], "red": [10, 14, 15, 16, 17, 29, 33, 43, 48, 53, 55, 60, 66, 75, 76, 77], "red_blood_cel": 63, "red_blu": 10, "red_blue_solid": 55, "red_fox": 33, "red_win": 33, "red_wolf": 33, "redblu": 55, "redbon": 33, "redo": 65, "redshank": 33, "reduc": [4, 17, 39, 40, 48, 70, 129], "redud": 9, "redund": [4, 6, 9, 93, 147], "redundani": 9, "reel": 33, "reemplaza": 77, "refactor": 3, "refer": [11, 19, 25, 26, 27, 38, 42, 48, 49, 84, 85, 86, 90, 91, 94, 128, 130], "reflect": [3, 25, 43, 54, 55], "reflex_camera": 33, "reformul": 85, "refrain": 40, "refriger": 33, "reg": [39, 59], "reg_alpha": [5, 59], "reg_lambda": [5, 59], "regard": 16, "regardless": [40, 54, 55], "region": [15, 29, 30, 31, 33, 39, 54, 55, 59, 66, 68, 74, 114], "regist": 128, "regress": [2, 39, 51, 52, 62, 81, 84, 86, 91, 94, 95, 97, 102, 106, 161], "regressionwrapp": 39, "regressor": 39, "regular": [6, 39, 86, 90], "rel": [3, 11, 16, 20, 26, 27, 39, 44, 128, 147], "relat": [3, 11, 39, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110, 158], "relationship": [4, 6, 9, 11, 14, 38, 39, 47, 51, 53, 54, 55, 93], "relax": 38, "releas": [38, 59, 87, 158], "relev": [25, 55, 67, 84, 91], "reli": [40, 46, 84, 91], "reliabl": 3, "relu": [32, 36, 37, 47, 51], "reluct": 72, "remain": [39, 70, 73, 74, 81, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110, 127], "rememb": [38, 39, 40, 43, 59], "remind": 15, "remot": [43, 68], "remote_control": 33, "remov": [3, 4, 6, 20, 26, 27, 32, 38, 39, 48, 59, 61, 65, 74, 77, 84, 87, 91], "rempla\u00e7": 77, "render": [3, 56, 60, 65, 130], "renew": 39, "rent": 43, "repeat": [11, 40, 51], "repeatedli": 15, "replac": [3, 29, 32, 33, 42, 47, 63, 64, 77, 82, 86, 87, 90, 98, 105, 106, 107, 108, 109, 110, 120, 153], "replacing0": 77, "replacing1": 77, "replacing2": 77, "replacing5": 77, "replacing6": 77, "replacing7": 77, "replic": [26, 27], "replica": 38, "repo": [3, 5, 25, 27], "report": [39, 74], "reported_incom": 40, "reported_income_sex_impact": 40, "repositori": [44, 95, 104], "repres": [4, 6, 8, 9, 10, 11, 14, 16, 38, 39, 42, 45, 46, 51, 52, 53, 54, 55, 62, 66, 71, 80, 82, 83, 84, 85, 86, 88, 90, 91, 93, 94, 98, 101, 103, 105, 106, 107, 109, 110, 126, 127, 129, 131, 138, 141, 143], "represent": [8, 16, 56, 65, 66, 93], "reproduc": [3, 82, 86, 87, 89, 90, 105, 106, 107, 108, 109, 110, 153], "request": [5, 6, 7, 9, 10, 12, 13, 14, 15, 16, 17, 20, 26, 29, 33, 34, 35, 38, 41, 44, 68, 69, 70, 73, 74, 76, 77], "requir": [3, 6, 17, 25, 38, 39, 42, 47, 51, 58, 69, 71, 72, 75, 84, 85, 91, 142], "rerun": [56, 65], "resampl": [17, 59], "rescal": 20, "rescale_to_logit": [70, 72, 125], "reset_index": 11, "reshap": [7, 18, 19, 26, 36, 44, 49, 56, 69], "reshaped_fil": 26, "reshaped_imag": 26, "residu": 39, "resiz": 26, "resize_imag": 26, "resnet": 27, "resnet101": 27, "resnet152": 27, "resnet50": [13, 18, 19, 157], "resolut": 98, "respect": [16, 30, 31, 38, 48, 76, 81, 87, 119, 147], "respons": [26, 40, 53, 68], "rest": [15, 38], "restart": [3, 27], "restaur": 33, "restraint": 40, "restrict": 98, "result": [3, 4, 6, 9, 12, 19, 20, 26, 27, 38, 39, 40, 42, 48, 49, 63, 64, 69, 74, 77, 84, 88, 91], "result_df": 64, "retain": [26, 39, 69, 74, 81], "retina": 40, "retrain": [44, 59], "retri": 3, "retriev": [11, 79], "return": [7, 9, 11, 13, 15, 18, 19, 20, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 44, 47, 48, 49, 50, 51, 63, 64, 65, 69, 73, 74, 75, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 130, 132, 133, 138, 139, 140, 141, 147], "return_all_scor": [70, 72], "return_object": [11, 128], "return_offsets_map": 73, "return_tensor": [74, 75], "return_vari": [36, 85], "reus": [38, 70, 72, 73, 74, 75, 89, 98], "reveal": [11, 14, 39, 53, 63], "revenu": 39, "revers": [6, 89], "review": [3, 15, 38, 71, 99], "revil": 15, "revolv": 33, "rf": 11, "rforest": [45, 46], "rg": 11, "rgb": [26, 27], "rhinoceros_beetl": 33, "rhodesian_ridgeback": 33, "ri": 65, "rich": 15, "richer": [8, 10, 138], "ride": 43, "rifl": 33, "right": [3, 9, 11, 12, 15, 32, 37, 38, 39, 42, 48, 63, 75, 78, 80, 84, 91, 98, 122, 123, 124, 128], "right_on": 62, "right_weight": 65, "ringlet": 33, "ringneck_snak": 33, "rise": 72, "risk": [40, 63], "rita": 43, "rival": 15, "river": 68, "rmdir": 26, "rng": 57, "rnn": 71, "robert": 74, "robin": 33, "robust": [14, 39], "rock": 68, "rock_beauti": 33, "rock_crab": 33, "rock_python": 33, "rocking_chair": 33, "rogerstanimoto": 119, "role": [43, 62, 74], "roll": 31, "romanc": 43, "room": [38, 68, 94], "root": [40, 45, 47, 48], "root_cluster_id": 48, "root_nam": [48, 143], "rotat": [53, 63], "roth": 39, "rotisseri": 33, "rottweil": 33, "rough": 98, "roughli": [9, 57, 80, 91, 107, 110], "round": [11, 19, 38, 39, 40, 52, 56, 57, 59, 67, 74, 77, 86, 90], "rounding_mod": [74, 77], "row": [7, 9, 10, 14, 15, 16, 17, 32, 37, 38, 42, 48, 62, 63, 75, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 122, 123, 124, 126, 127, 132, 140], "row_arg": [78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110], "row_expected_valu": [78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 109, 110], "row_index": 11, "row_mask_shap": [78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 109, 110], "row_to_explain": 51, "row_valu": [78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 109, 110], "rseed": 85, "rst": 3, "rstrip": 25, "rt": 38, "rtx": 38, "rubber_eras": 33, "ruddy_turnston": 33, "ruff": 3, "ruffed_grous": 33, "rugbi": 74, "rugby_bal": 33, "rule": [4, 6, 33, 38, 39, 80, 82, 84, 86, 87, 90, 91, 105, 106, 107, 108, 109, 110], "run": [3, 5, 25, 26, 30, 31, 38, 39, 43, 45, 46, 47, 50, 51, 53, 54, 55, 59, 60, 61, 62, 63, 71, 74, 83, 84, 86, 90, 91, 135, 143], "run_credit_experi": 40, "run_mask": [26, 27], "running_sho": 33, "runtim": [4, 6, 20, 48, 84, 88, 91, 116, 119], "runtimeerror": [25, 64], "runtimewarn": 59, "ruotianluo": 27, "rural": 68, "russellrao": 119, "russian": 76, "russian0": 76, "rv": 39, "r\u00e1pidament": 77, "r\u00e9current": 77, "r\u00e9seaux": 77, "s1": 97, "s2": 97, "s3": [13, 18, 19, 28, 29, 30, 31, 33, 34, 35, 97], "s4": 97, "s5": [16, 66, 97], "s6": [16, 66, 97], "s_i": 42, "s_kit": 33, "s_slipper": 33, "s_wheel": 33, "saaba": 91, "sabu": 43, "sack": 15, "sad": [43, 70, 73], "saddl": 15, "safe": 33, "safer": 39, "safety_pin": 33, "sai": [15, 38, 39, 40, 50, 53, 74], "said": 74, "sailor": 15, "saint_bernard": 33, "sake": [9, 14, 20], "salari": 74, "sale": 39, "sales_calls_model": 39, "sales_calls_shap_valu": 39, "salienc": [15, 75], "saltshak": 33, "saluki": 33, "same": [3, 9, 11, 12, 14, 15, 20, 39, 40, 43, 48, 53, 54, 55, 56, 57, 59, 60, 61, 67, 69, 70, 73, 80, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 120, 128, 130, 133, 138, 140], "samoi": 33, "sampel": 47, "sampl": [4, 7, 9, 12, 14, 17, 20, 26, 30, 31, 32, 37, 38, 39, 40, 42, 44, 46, 47, 49, 50, 51, 53, 54, 55, 57, 62, 65, 66, 71, 72, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 101, 102, 103, 105, 106, 107, 108, 109, 110, 116, 119, 120, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 139, 140, 142, 148], "sample_ind": 38, "samplingexplain": [88, 89], "sandal": 33, "sandbar": 33, "sander": 15, "sarong": 33, "satir": 15, "satisfi": [6, 25, 47], "save": [14, 15, 26, 27, 48, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "save_imag": [26, 27], "save_model": 64, "savefig": [14, 48], "saw": [15, 43, 69, 72], "sax": 33, "sca": 48, "scabbard": 33, "scalar": 42, "scale": [9, 12, 15, 16, 31, 32, 33, 38, 40, 44, 79, 80, 84, 91, 127, 128, 133, 139, 140], "scale_pos_weight": [5, 59], "scaler": 41, "scarlet": 74, "scatter": [1, 3, 5, 16, 17, 38, 39, 41, 44, 54, 55, 60, 61, 127, 140, 161], "scatter_doclink": 3, "scenario": [11, 26, 27, 39, 70, 73, 74, 77, 122, 130], "scene": [15, 43], "scheme": 3, "schipperk": 33, "school": 15, "school_bu": 33, "schooner": 33, "sci": [43, 44], "scienc": 43, "scientist": [43, 68, 76], "scientists0": 68, "scikit": [16, 47, 56, 61, 84, 91, 97, 153, 161], "scipi": [15, 24, 25, 38, 39, 47, 48, 49, 50, 56, 73, 75, 86, 87, 88, 89, 90, 92, 104, 119, 147, 153], "scm": 3, "scope": 3, "score": [11, 15, 26, 27, 32, 38, 40, 43, 69, 71, 72, 73, 75, 76, 112, 122, 124], "scoreboard": 33, "scorpion": 33, "scotch_terri": 33, "scott": 39, "scottish_deerhound": 33, "scrambl": 15, "scrappi": 72, "screen": 33, "screenplai": 43, "screw": 33, "screwdriv": 33, "scroll": 67, "scrum": 74, "scuba_div": 33, "se": 77, "sea_anemon": 33, "sea_cucumb": 33, "sea_lion": 33, "sea_slug": 33, "sea_snak": 33, "sea_urchin": 33, "sealyham_terri": 33, "search": [98, 158, 159], "seashor": 33, "season": 74, "seat_belt": 33, "second": [14, 15, 29, 33, 36, 38, 39, 48, 51, 57, 60, 74, 78, 89, 131], "section": [3, 11, 26, 27, 66], "secur": [43, 45, 46, 47, 50, 51, 53, 54, 55, 59, 60, 61, 62, 71], "sedimentation_r": 63, "see": [3, 9, 10, 11, 14, 15, 16, 17, 19, 20, 29, 32, 33, 36, 38, 39, 40, 43, 44, 47, 48, 51, 52, 53, 56, 59, 62, 63, 65, 66, 67, 68, 71, 72, 74, 80, 81, 82, 84, 85, 86, 87, 88, 90, 91, 105, 106, 107, 108, 109, 110, 126, 127, 128, 132, 133, 138, 139, 140, 141, 144, 147, 152, 158, 160], "seed": [25, 39, 40, 43, 48, 49, 59, 82, 85, 86, 87, 89, 90, 105, 106, 107, 108, 109, 110], "seek": 40, "seem": [39, 59, 138, 144, 152], "seemingli": 59, "seen": [15, 43, 59], "segment": [26, 27], "select": [16, 32, 42, 47, 51, 53, 80, 86, 90], "self": [3, 27, 32, 37, 39, 65], "sell": 15, "semant": [3, 26, 27], "semi": 68, "send": 39, "sens": [11, 16, 43, 50, 70, 86, 87, 88], "sensibl": [43, 48], "sensit": [14, 40], "sent": 43, "sentenc": [15, 38, 69, 70, 74, 75, 76, 77, 122, 123, 124], "sentim": 72, "sentiment": [15, 38, 99, 158, 161], "sep": [27, 69], "sep_test_data": 64, "sep_test_target": 64, "sep_token_id": 69, "sepal": 101, "separ": [3, 9, 63, 68, 75, 139], "seper": [9, 40], "septemb": 74, "seq": 25, "seq_to_one_hot_fill_in_arrai": 25, "seqs_to_explain": 25, "sequenc": [15, 38, 71], "sequenti": [32, 37, 47, 71, 81, 89], "sequential_perturb": [18, 19, 24], "sequentialmask": 20, "sequentialperturb": [18, 19, 21, 22, 23, 24, 75], "seri": [65, 91, 120, 128], "serializ": [78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 111, 112, 115, 117, 121, 122, 123, 124, 125], "serious": 39, "serum": 97, "serum_protein": 63, "serv": [38, 74], "server": 5, "servic": [40, 157], "session": [32, 80, 85], "set": [4, 5, 6, 9, 11, 12, 14, 15, 20, 24, 25, 26, 30, 31, 32, 36, 37, 38, 39, 40, 41, 42, 47, 51, 53, 55, 59, 60, 61, 63, 68, 70, 76, 78, 81, 83, 84, 86, 87, 88, 89, 90, 91, 98, 122, 123, 124, 126, 127, 128, 130, 132, 133, 138, 139, 140, 141, 142, 143], "set_alpha": 55, "set_facecolor": 48, "set_label": 14, "set_label_posit": 55, "set_linewidth": 55, "set_opt": 24, "set_output": 41, "set_size_inch": 48, "set_ticks_posit": 39, "set_titl": [14, 19, 48], "set_vis": [14, 39], "set_xlabel": 14, "set_ylabel": 14, "set_ylim": 19, "setosa": 101, "setup": [5, 27, 47, 51], "setuptool": [3, 47], "seuclidean": 119, "sever": [15, 20, 39, 43, 45, 66, 83, 91, 111, 120, 138], "sewing_machin": 33, "sex": [9, 11, 40, 51, 63, 66, 93, 97], "sex_": 40, "sex_a": 40, "sex_b": 40, "sex_c": 40, "sex_d": 40, "sex_f": 40, "sex_g": 40, "sex_isfemal": 63, "sgd": 37, "sh": 11, "sha256": 47, "shadow": 48, "shal": 74, "shallow": 68, "shap": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19, 20, 25, 28, 30, 31, 32, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 50, 51, 53, 57, 58, 59, 60, 61, 62, 66, 69, 71, 72, 157, 161], "shap_benchmark_": 64, "shap_benchmark_128_max_bin_with_test_s": 64, "shap_embed": 55, "shap_exp": 33, "shap_interaction_valu": [11, 52, 59, 63, 84, 91, 128], "shap_interaction_values3": 59, "shap_numpi": 37, "shap_pca50": 55, "shap_r": [10, 38], "shap_sum": 56, "shap_valu": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 80, 84, 85, 86, 87, 89, 90, 91, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 137, 138, 139, 140, 141, 144, 145], "shap_value_singl": 47, "shap_values2": [4, 6, 72], "shap_values3": 59, "shap_values50": 51, "shap_values_": 40, "shap_values_a": 40, "shap_values_adult": 38, "shap_values_adult_log_odd": 38, "shap_values_answ": 69, "shap_values_b": 40, "shap_values_c": 40, "shap_values_column": 152, "shap_values_d": 40, "shap_values_ebm": 38, "shap_values_end": 69, "shap_values_f": [40, 50], "shap_values_f_logist": 50, "shap_values_fin": [29, 33], "shap_values_g": 40, "shap_values_ind": [54, 55], "shap_values_list": [26, 27], "shap_values_matrix": 152, "shap_values_model_agnost": 74, "shap_values_norm": 44, "shap_values_object": 27, "shap_values_partit": 9, "shap_values_start": 69, "shap_values_var": 36, "shap_values_xgb": 38, "shape": [9, 11, 13, 15, 16, 18, 19, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 38, 44, 47, 49, 51, 53, 56, 59, 63, 64, 65, 66, 67, 71, 72, 80, 82, 83, 84, 85, 86, 87, 90, 91, 105, 106, 107, 109, 110, 111, 112, 114, 120, 128, 130, 133], "shaplei": [41, 42, 47, 48, 80, 81, 82, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 144, 152, 158, 159], "shapley_kernel": 49, "shapvalu": 64, "share": [4, 6, 15, 39, 87], "sharp": 39, "she": 43, "shetland_sheepdog": 33, "shield": 33, "shift": [11, 128], "shih": 33, "shock": 68, "shocking0": 68, "shoe_shop": 33, "shoji": 33, "shop": 40, "shopping_basket": 33, "shopping_cart": 33, "short": 11, "short_data": 72, "shortcut": [78, 81, 82, 86, 87, 88, 89, 90, 105, 106, 107, 108, 109, 110], "shorten": 72, "shorthand": 140, "should": [3, 15, 17, 39, 40, 43, 48, 57, 59, 63, 74, 80, 84, 91, 122, 123, 124, 129, 130, 133, 151], "shouldn": [39, 43], "shovel": 33, "show": [3, 7, 9, 10, 12, 14, 15, 17, 19, 25, 26, 32, 33, 37, 38, 39, 40, 41, 44, 48, 50, 51, 52, 53, 54, 55, 56, 61, 62, 63, 65, 75, 76, 80, 126, 127, 128, 129, 130, 131, 132, 133, 136, 137, 138, 140, 141], "show_data": 126, "show_grid_plot": 26, "show_idx": 11, "showcas": [18, 21, 22, 23, 24, 48, 51, 76, 77], "shower_cap": 33, "shower_curtain": 33, "shown": [10, 11, 12, 16, 26, 27, 38, 39, 47, 53, 60, 126, 128], "shrikumar": 80, "shrug": 15, "shuffl": [25, 37, 51, 151, 153], "shuffle_several_tim": 25, "siamang": 33, "siamese_cat": 33, "siberian_huski": 33, "sibl": 48, "side": [12, 15, 39], "sidewalk": [15, 75], "sidewind": 33, "sigma": 42, "sigmoid": [11, 53, 71], "sign": 72, "signal": 59, "signatur": [70, 73], "signifi": 15, "signific": [11, 40, 74], "significantli": [14, 26, 40, 50], "silent": [59, 64, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 155], "silky_terri": 33, "simdata": 25, "simdna": 25, "similar": [4, 6, 11, 12, 15, 26, 27, 39, 54, 55, 62, 63, 74, 79, 80, 98, 148], "similarity_model": [26, 27, 74, 122], "similarity_model_typ": [122, 124], "similarity_token": [26, 27, 74, 122], "similarli": [8, 15, 16], "simluat": 59, "simpl": [4, 5, 6, 7, 8, 11, 30, 31, 32, 33, 36, 37, 38, 39, 40, 43, 44, 50, 52, 58, 71, 86, 90, 153, 161], "simplefilt": 11, "simpler": 71, "simplest": [11, 38, 39], "simpli": [66, 105, 106, 107, 108, 109, 110], "simplic": 93, "simplifi": [42, 128], "simul": [25, 39, 52, 57, 86, 90, 161], "simultain": 9, "simultan": 40, "sin": 52, "sinc": [3, 4, 6, 10, 15, 17, 20, 36, 37, 38, 39, 40, 43, 47, 51, 53, 54, 55, 57, 59, 62, 63, 66, 67, 70, 73, 74, 75, 80, 82, 84, 85, 86, 90, 91, 105, 106, 107, 109, 110, 111, 112, 115, 117, 121, 122, 123, 124, 125, 139, 149], "singer": 15, "singl": [7, 10, 11, 14, 16, 17, 20, 30, 31, 38, 39, 40, 47, 48, 52, 53, 54, 58, 61, 63, 65, 66, 68, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 111, 120, 126, 127, 128, 130, 138, 139, 140, 141, 147], "single_split_model": 67, "sissi": 15, "sister": 15, "sit": [27, 38], "site": [15, 25, 48, 51, 59], "situat": [15, 39, 40, 50, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110], "situp": 102, "six": [25, 47, 70, 74], "sixth": 43, "size": [26, 27, 28, 39, 47, 48, 52, 57, 62, 64, 71, 79, 84, 91, 122, 124, 127, 128, 130, 140], "size_test": 64, "sk": 75, "skate": 75, "skateboard": 75, "skew": 16, "skf": 11, "ski": 33, "ski_mask": 33, "skip": 3, "skip_special_token": 74, "sklearn": [9, 11, 20, 21, 38, 39, 41, 43, 44, 45, 46, 47, 51, 52, 54, 55, 56, 59, 62, 63, 64, 67, 86, 87, 90, 92, 94, 97, 102], "skunk": 33, "skyblu": 48, "slabel": 40, "slapstick": 15, "sleep": [45, 46], "sleeping_bag": 33, "slice": [11, 14, 15, 29, 33, 43, 70, 74, 128], "sliceabl": [70, 83], "sliced_index": [18, 19], "sliced_label": 19, "slicer": [47, 83], "slide_rul": 33, "sliding_door": 33, "slight": 67, "slightli": 3, "slope": 39, "slot": 33, "sloth_bear": 33, "slow": [26, 75, 128], "slower": [26, 27, 46, 50], "slug": 33, "slundberg": [38, 59, 70, 72, 73, 74], "small": [3, 11, 14, 15, 16, 39, 45, 46, 49, 59, 66, 67, 68, 71, 84, 86, 91], "smaller": [20, 50, 54, 55], "smallest": 141, "smart": 142, "smasker": 20, "smoke": 43, "smooth": [59, 66, 85], "smoother": [30, 31, 59], "smoothgrad": [30, 31], "snail": 33, "sneakier": 39, "snippet": 11, "snli": 75, "snli_label_map": 75, "snorkel": 33, "snow_leopard": 33, "snowmobil": 33, "snowplow": [29, 33], "so": [3, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 29, 31, 32, 33, 34, 35, 38, 39, 40, 41, 43, 44, 46, 47, 48, 50, 51, 55, 57, 58, 62, 63, 65, 66, 67, 69, 70, 72, 73, 74, 75, 80, 81, 82, 84, 86, 87, 90, 91, 105, 106, 107, 108, 109, 110, 120, 136], "soap_dispens": 33, "soccer": 27, "soccer_bal": 33, "societi": [15, 43], "sock": 33, "soft": 33, "softmax": [32, 36, 37, 75, 122, 124], "sokalmichen": 119, "sokalsneath": 119, "solar_dish": 33, "sold": 72, "solicit": 3, "solid": [38, 39], "solut": 43, "solv": [39, 52], "solver": [45, 46], "sombrero": 33, "some": [4, 5, 6, 8, 9, 11, 15, 20, 32, 39, 40, 43, 50, 52, 59, 62, 63, 71, 72, 74, 75, 87], "somehow": 43, "someon": [15, 39, 57, 70, 73], "someth": [5, 15, 30, 31, 43, 66, 80, 89], "sometim": [3, 10, 14, 15, 39, 40, 43, 46, 48, 70, 86, 90, 112], "somewhat": 43, "somewher": 43, "son": 43, "sont": 77, "sooner": 74, "sorrel": 33, "sort": [9, 10, 14, 20, 39, 44, 53, 54, 55, 62, 64, 70, 73, 74, 81, 126, 131, 132, 139, 140, 141], "sort_ord": [18, 19, 21, 22, 23, 24, 75], "sorted_ia_matrix": 63, "sorted_index": [18, 19], "soup_bowl": 33, "sourc": [1, 16, 39, 40, 56, 67, 84, 92, 104, 122, 123, 124, 157], "sp": [15, 21, 22, 23, 24, 38, 48, 73, 75], "sp_result": 21, "space": [4, 38, 43, 44, 49, 54, 55, 65, 70, 72, 84, 86, 90, 91], "space_bar": 33, "space_heat": 33, "space_shuttl": 33, "spacebal": 15, "spaghetti_squash": 33, "span": [73, 138, 139], "spanish": 76, "spanish0": 76, "spare": 74, "spark": 61, "spars": [14, 43, 86, 87, 89, 90, 92, 104, 149, 153], "sparse_categorical_crossentropi": 36, "sparsedtyp": [61, 65], "sparser": 39, "spatial": [119, 147], "spatula": 33, "speak": 74, "spec": 3, "speci": [46, 101], "special": [15, 24, 38, 39, 49, 50, 56, 68, 73, 75, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110, 123], "special_charact": [56, 67], "specif": [5, 11, 14, 16, 26, 38, 39, 40, 47, 54, 62, 66, 69, 80, 82, 86, 87, 88, 90, 105, 106, 107, 108, 109, 110, 153], "specifi": [3, 11, 15, 38, 39, 40, 48, 64, 73, 79, 80, 85, 93, 94, 95, 97, 99, 101, 102, 128, 129, 138], "spectrum": [11, 128], "speed": [26, 42, 48, 65, 161], "speedboat": [28, 29, 33], "speeden": 27, "spend": [38, 39, 40, 74], "spending_restraint": 40, "spent": [39, 62, 74], "sper": 75, "sphinx": 3, "sphinx_github_changelog_token": 160, "spider_monkei": 33, "spider_web": 33, "spindl": 33, "spine": 39, "spiny_lobst": 33, "split": [11, 15, 16, 19, 22, 23, 24, 32, 39, 52, 54, 55, 62, 63, 65, 66, 69, 70, 72, 73, 74, 83, 91, 114], "split_index": 65, "split_predict": 27, "spoonbil": 33, "sport": 72, "sports_car": 33, "spot": 11, "spotlight": 33, "spotted_salamand": 33, "spous": 11, "spread": [39, 52, 54, 55, 62], "spree": 62, "sqeuclidean": [119, 148], "sqrt": [45, 49, 80], "squah": 50, "squar": [39, 45], "squash": [3, 161], "squeez": 25, "squirrel_monkei": 33, "src": [51, 74, 77], "sshleifer": [19, 22, 26, 27, 74], "ssp": [92, 104], "sst": [15, 38], "stabil": 40, "stabl": [16, 39, 43, 48, 51], "stack": [16, 53, 66, 71, 83, 130], "staffordshire_bullterri": 33, "stage": 33, "stagger": 39, "stai": [39, 87], "stakehold": 39, "stale": 3, "stanc": 74, "stand": [3, 11, 26, 27], "standard": [10, 11, 16, 30, 31, 38, 39, 40, 44, 54, 55, 62, 66, 78, 81, 82, 84, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 125, 161], "standard_norm": 57, "standard_poodl": 33, "standard_schnauz": 33, "standardscal": 41, "stanford": 99, "star": [15, 74], "stare": 38, "starfish": 33, "start": [3, 5, 11, 17, 38, 39, 43, 52, 62, 65, 73, 74, 75, 128, 130], "start_color": 14, "start_delai": 155, "start_logit": 69, "start_test_preproc": 64, "start_tim": [48, 64], "start_train": 64, "startpo": 25, "stat": [16, 39, 62], "state": [3, 11, 13, 15, 18, 19, 22, 23, 24, 34, 35, 39, 40, 54, 55, 67, 68, 75, 147], "static": [32, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110], "statist": [38, 39, 40, 62, 63, 84, 91], "stats1": 62, "stats2": 62, "statu": [3, 4, 6, 9, 11, 44, 51, 93], "std": [28, 31, 44, 51], "stddev": 59, "stderr": [27, 39], "stdout": 27, "steam_locomot": 33, "steel_arch_bridg": 33, "steel_drum": 33, "step": [5, 11, 15, 27, 32, 37, 39, 41, 47, 51, 59, 71, 89, 128], "stethoscop": 33, "still": [3, 5, 9, 13, 15, 16, 18, 19, 22, 23, 24, 34, 35, 39, 40, 43, 50, 57, 66, 75, 81], "stingrai": 33, "stink": 15, "stinkhorn": 33, "stock": 43, "stole": 33, "stone_wal": 33, "stop": [11, 39, 43, 59, 65], "stopwatch": 33, "store": [14, 27, 47, 69, 79, 84, 86, 87, 89, 90, 91], "stori": [15, 38, 43], "stove": 33, "stow": 43, "str": [25, 30, 31, 39, 44, 51, 64, 65, 79, 99, 101, 122, 123, 124, 126, 127, 128, 130, 133, 138, 143, 147], "straight": [38, 52], "strainer": 33, "strang": [43, 68], "stratifiedkfold": 11, "strawberri": 33, "stream": [26, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "street": [15, 43], "street_sign": 33, "streetcar": 33, "strength": 76, "stretcher": 33, "strike": 11, "string": [14, 15, 20, 27, 38, 55, 62, 70, 72, 73, 75, 77, 82, 86, 87, 90, 99, 101, 105, 106, 107, 108, 109, 110, 119, 120, 129, 130, 138, 139], "strip": [43, 45, 46, 47, 50, 51, 53, 54, 55, 59, 60, 61, 62, 71], "strong": [4, 6, 15, 38, 39, 40, 53, 63], "stronger": 40, "strongest": [14, 138], "strongli": 39, "structur": [1, 4, 6, 9, 11, 15, 38, 39, 48, 59, 78, 81, 87, 88, 89, 93, 119, 126], "strumbelj": 90, "student": 15, "studi": 63, "studio_couch": 33, "stupa": 33, "stupid": 15, "sturgeon": 33, "sturm": 43, "style": [11, 39, 54, 55, 128], "sub": [9, 68, 111, 120], "subclass": [78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 111, 112, 115, 117, 121, 122, 123, 124, 125, 153], "subgroup": 44, "subhead": 3, "subject": [39, 136], "submarin": 33, "submit": 3, "subplot": [14, 19, 20, 48, 51, 138], "subsampl": [5, 20, 21, 39, 40, 48, 55, 59, 63, 116, 119], "subscript": [26, 39], "subsequ": 11, "subset": [38, 42, 63, 73, 97, 102, 120], "subset_featur": 102, "subset_target": 102, "substr": [120, 139], "substructur": 132, "subter": 68, "subticks_frequ": 25, "subtract": [39, 50, 70], "succe": 15, "succeed": 74, "succes": 27, "success": [4, 27, 39], "successfulli": 47, "sudo": [3, 5], "sue": 43, "suffer": 39, "suffici": [3, 29, 33, 39, 40], "suffix": [62, 123], "sugar": 97, "suggest": [3, 14, 63, 119], "suit": [3, 31, 33, 62], "suitabl": 3, "sulphur": 33, "sulphur_butterfli": 33, "sum": [6, 11, 12, 15, 16, 20, 24, 25, 37, 38, 40, 44, 46, 49, 52, 53, 54, 55, 56, 57, 58, 62, 63, 73, 75, 80, 84, 85, 86, 87, 89, 90, 91, 111, 127, 129, 130, 151], "sum_r": 42, "summar": [2, 38, 39, 45, 46, 50, 53, 61, 86, 158], "summari": [1, 9, 15, 23, 32, 38, 44, 47, 53, 62, 70, 71, 132, 140], "summaris": 8, "summary_plot": [8, 44, 45, 47, 54, 55, 59, 62, 63, 66, 71], "summiz": 15, "sundararajan": 85, "sundial": 33, "sunglass": 33, "sunscreen": 33, "super": [26, 27, 29, 32, 33, 37, 39, 111, 112, 115, 117, 121, 122, 123, 124, 125], "superb": [15, 43], "superclass": [117, 121], "supervis": 132, "suppli": [82, 86, 87, 88, 90, 105, 106, 107, 108, 109, 110, 128], "support": [5, 8, 9, 11, 16, 32, 33, 40, 43, 54, 55, 58, 60, 70, 75, 84, 87, 91, 98, 108, 120, 122, 128, 130, 138], "supports_model_with_mask": [78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110], "suppos": 39, "suppress": 27, "suppress_stdout": 27, "suptitl": 19, "sure": [3, 5, 15, 32, 43, 52, 56, 76], "surpris": [39, 40, 43, 70, 73], "surprise0": 70, "surrog": [26, 27], "surviv": [15, 43, 57, 103, 161], "survival_tim": 103, "survivor": 15, "suspension_bridg": 33, "sussex_spaniel": 33, "svc": 46, "svc_linear": 46, "svm": 46, "sw": 68, "swab": 33, "swamp": 68, "swapax": [31, 37], "sweatshirt": 33, "swimming_trunk": 33, "swing": 33, "switch": [33, 66], "sy": 27, "symmetr": [84, 91], "symmetri": 16, "sympathet": 43, "syntax": [3, 61], "synthet": [11, 25, 96, 100], "syrgkani": 39, "syring": 33, "system": [5, 29, 33, 122, 123, 124], "systol": 63, "systolic_blood_pressur": 63, "t": [3, 5, 9, 11, 14, 15, 16, 17, 24, 25, 27, 38, 39, 40, 42, 43, 44, 46, 50, 51, 52, 53, 54, 55, 57, 59, 62, 64, 65, 66, 70, 71, 73, 74, 75, 86, 90, 112], "tabbi": 33, "tabl": [11, 69], "table0": 69, "table1": 69, "table_lamp": 33, "tabular": [9, 54, 55, 78, 87, 89, 94, 106, 116, 119, 158], "tabularmask": [82, 86, 87, 90, 105, 106, 107, 108, 109, 110], "tabularpartit": [9, 81], "tackl": 39, "tag": 3, "tail": 59, "tailed_frog": 33, "take": [4, 6, 7, 11, 15, 16, 26, 27, 29, 32, 33, 38, 39, 47, 50, 51, 52, 53, 55, 63, 70, 73, 74, 75, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 124, 126], "taken": [9, 30, 31, 43, 57, 62, 86], "tal1_known1": 25, "talk": 39, "tambor": 15, "tan_coonhound": 33, "tank": 33, "tape_play": 33, "tar": [47, 99], "tarantula": 33, "target": [37, 39, 47, 67, 76, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 122, 123, 147], "target_sent": 123, "task": [9, 10, 11, 12, 14, 17, 25, 38, 55, 71, 75, 93, 94, 95, 97, 99, 103, 104, 128], "task_specific_param": 76, "task_typ": 64, "taylor": 5, "teach": 15, "teacher": [15, 26, 27, 76, 122], "teacher_forcing_model": [74, 76], "teacherforc": [74, 76], "teacherforcinglogit": [26, 27, 74], "team": [32, 39, 62, 71], "teapot": 33, "tech": 11, "techniqu": [26, 29, 33, 39, 122], "technologi": 15, "technqiu": [26, 27], "teddi": [15, 33], "telea": 18, "televis": 33, "tell": [38, 39, 43, 59, 63, 85], "temperatur": 76, "templat": 3, "tempt": [39, 74], "ten": [9, 10], "tench": 33, "tend": [39, 40, 53], "tendenc": 40, "tender": 15, "tennis_bal": 33, "tensor": [15, 24, 28, 31, 32, 38, 69, 72, 73, 75, 80, 84, 85, 91, 122, 123, 124, 125], "tensorflow": [3, 13, 18, 19, 29, 30, 32, 33, 36, 37, 38, 47, 71, 80, 85, 122, 123, 157], "tensorrt": 37, "tensowflow": 85, "term": [11, 17, 30, 31, 38, 42, 48, 52, 62, 63, 65, 67, 88], "termin": [5, 27], "terrapin": 33, "terri": 43, "terrif": 43, "test": [11, 24, 25, 32, 36, 37, 39, 40, 48, 54, 55, 63, 64, 71, 72, 75, 86, 90, 104, 134], "test_data": 64, "test_df": 53, "test_ids_fh": 25, "test_imag": 37, "test_load": 37, "test_loss": 37, "test_numpi": 37, "test_object": 53, "test_preprocess": 64, "test_siz": [11, 21, 43, 44, 45, 46, 51, 54, 55, 62, 63, 64], "test_target": 64, "text": [1, 17, 38, 43, 63, 69, 70, 71, 73, 77, 82, 86, 87, 88, 90, 99, 105, 106, 107, 108, 109, 110, 113, 118, 122, 123, 124, 157, 158], "text2text": [26, 27], "text_data": 99, "text_rot": 130, "textual": 162, "tf": [36, 37, 43, 71, 80, 85, 122, 123, 124], "tf2tensorrt": 37, "tfdeep": 32, "tfidfvector": 43, "than": [3, 6, 8, 9, 10, 11, 14, 15, 17, 20, 26, 27, 29, 30, 31, 32, 33, 38, 39, 40, 42, 44, 45, 46, 48, 50, 53, 54, 55, 57, 59, 62, 63, 66, 74, 81, 86, 90, 93, 116, 119, 127, 130, 139], "thank": [3, 43], "thatch": 33, "the0": [76, 77], "the1": 77, "the2": 77, "the3": 77, "the5": 77, "the8": 77, "theater": 72, "theater_curtain": 33, "thei": [2, 9, 11, 14, 15, 16, 17, 31, 38, 39, 40, 43, 45, 46, 52, 54, 55, 62, 66, 67, 70, 73, 74, 76, 80, 88, 127, 140, 144, 152, 156, 157, 161, 162], "them": [10, 11, 15, 27, 38, 39, 40, 43, 47, 48, 53, 63, 67, 68, 71, 74, 75, 80, 83, 85, 86, 112, 116, 119, 125, 143], "themselv": [38, 43], "theoret": [48, 50, 158], "theori": [38, 40, 86, 88, 90, 158], "therebi": 68, "therefor": [11, 16, 39], "thi": [0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 95, 98, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 138, 139, 140, 141, 142, 144, 148, 149, 152, 153], "thimbl": 33, "thin": 14, "thing": [15, 36, 43, 57, 65, 112], "think": [15, 39, 48, 50], "third": [48, 78], "thirti": 15, "those": [3, 9, 14, 15, 39, 43, 52, 53, 54, 55, 57, 60, 78, 82, 86, 87, 88, 90, 105, 106, 107, 108, 109, 110], "though": [4, 6, 11, 14, 39, 40, 43, 50, 59], "thought": 43, "thousand": [55, 62], "three": [11, 14, 15, 17, 25, 32, 33, 36, 39, 43, 62, 70, 101, 102, 138], "thresher": 33, "threshold": [9, 11, 56, 65], "thresholds1": 56, "thresholds2": 56, "thrill": 43, "thriller": 43, "throne": 33, "through": [9, 15, 38, 39, 40, 43, 54, 55, 57, 76, 83, 88, 89, 114, 122, 124], "throw": 43, "thrown": 15, "thru": 38, "thu": 16, "thunder_snak": 33, "ti": 38, "tibetan_mastiff": 33, "tibetan_terri": 33, "tick": [33, 126, 130, 138], "tick_param": [14, 55], "tick_top": 63, "tiger": 33, "tiger_beetl": 33, "tiger_cat": 33, "tiger_shark": 33, "tight": 96, "tight_layout": [14, 20, 48], "tightli": 88, "tile": 33, "tile_roof": 33, "till": 43, "timber_wolf": 33, "time": [3, 4, 6, 15, 20, 26, 27, 29, 33, 38, 39, 42, 43, 44, 45, 46, 47, 48, 50, 62, 63, 64, 67, 71, 84, 86, 89, 90, 91, 103, 128, 136], "timecc": 62, "tini": 68, "tip": 11, "tipur": 74, "titan": [15, 57], "titi": 33, "titl": [3, 48, 51, 55, 62, 128, 138, 140], "tloss": 37, "tmp": [13, 18, 19, 29, 33, 34, 35, 65], "tmp_valu": 59, "to0": 76, "to_categor": 32, "to_csv": 64, "to_explain": [30, 31], "to_list": [11, 47], "to_numpi": 57, "to_return": 25, "toarrai": 43, "toaster": 33, "tobacco_shop": 33, "tobia": 32, "todai": 69, "todens": 64, "todo": 3, "toed_sloth": 33, "togeth": [4, 6, 12, 15, 38, 39, 62, 88, 111, 128, 141], "toggl": [26, 139], "toi": [16, 72], "toilet_seat": 33, "toilet_tissu": 33, "token": [15, 19, 22, 23, 24, 38, 69, 70, 77, 82, 86, 87, 88, 90, 105, 106, 107, 108, 109, 110, 120, 122, 123, 124, 134, 139, 162], "token_id": 120, "token_seg": 120, "tokenize_data": 69, "tokenized_data": 69, "tokenized_q": 69, "tokenmask": [82, 86, 87, 90, 105, 106, 107, 108, 109, 110], "tolist": [28, 74], "toml": 3, "tonight": 43, "too": [15, 43, 71, 91, 128], "tool": [2, 27, 39, 40], "toolkit": 5, "tooltip": 15, "top": [3, 9, 10, 11, 14, 15, 20, 27, 29, 30, 33, 39, 55, 66, 71, 75, 80, 85, 86, 90, 124, 126, 127, 140], "top_class": 19, "top_ind": 62, "top_k": [76, 133], "topic": [3, 40, 158], "topk": [28, 69, 124], "topklm": 68, "torch": [15, 24, 27, 28, 31, 33, 37, 38, 69, 73, 74, 75, 77, 80, 85], "torchvis": [28, 31, 37], "total": [15, 32, 52, 54, 55, 62, 63, 65, 74, 88, 95, 97, 155], "total_second": 64, "totcctimedealt": 62, "totdmgdealt": 62, "totdmgtaken": 62, "totdmgtochamp": 62, "totem_pol": 33, "totensor": 37, "totheal": 62, "totminionskil": 62, "totunitsh": 62, "toucan": 33, "touch": 38, "tout": 74, "tow_truck": 33, "toward": [39, 59, 70, 74, 77], "toy_dataset": 16, "toy_poodl": 33, "toy_terri": 33, "toyshop": 33, "tqdm": [47, 48, 51, 64, 86, 90], "tqdmwarn": [48, 51], "trace": 38, "traceback": [32, 33], "track": [3, 26, 27], "tracker": 3, "tractor": 33, "trade": 40, "tradeoff": [40, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110], "tradit": [54, 55], "tradition": [15, 63], "traffic_light": 33, "trai": 33, "trailer_truck": 33, "train": [4, 5, 6, 7, 9, 10, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 45, 46, 52, 53, 60, 61, 64, 66, 67, 70, 71, 73, 74, 75, 80, 84, 86, 90, 91, 98, 99, 104], "train_data": 64, "train_df": 53, "train_load": 37, "train_preprocess": 64, "train_set": 64, "train_target": 64, "train_test_split": [11, 20, 21, 39, 43, 44, 45, 46, 51, 54, 55, 59, 62, 63], "trainabl": 32, "trait": 39, "tran": 77, "trans0": 77, "trans5": 77, "transform": [11, 15, 19, 22, 23, 24, 26, 27, 28, 37, 41, 42, 43, 50, 61, 62, 68, 71, 72, 73, 74, 75, 76, 77, 84, 86, 87, 91, 111, 120, 122, 123, 124, 125, 126, 128, 130, 162], "transform0": 77, "transform1": 77, "transform4": 77, "transform5": 77, "transformador": 77, "transformateur": 77, "transformerspipelin": 70, "translat": [2, 158], "transpar": [3, 14, 39, 129, 138], "transpos": 37, "treasur": 15, "treat": [4, 6, 15, 39, 40, 43, 48, 68, 83, 88], "treatment": 39, "tree": [4, 5, 6, 9, 11, 16, 20, 21, 26, 27, 52, 53, 59, 62, 63, 66, 68, 82, 83, 84, 86, 87, 88, 89, 90, 91, 104, 105, 106, 107, 108, 109, 110, 126, 149, 151, 158], "tree_": [56, 65], "tree_dict": 56, "tree_explain": 48, "tree_frog": 33, "tree_limit": [84, 91], "tree_method": [5, 64], "tree_output": 56, "tree_path_depend": [5, 84, 91], "tree_shap": 65, "tree_shap_recurs": 65, "tree_shap_valu": 48, "tree_tmp": 56, "treeensembl": 56, "treeexplain": [3, 8, 11, 16, 20, 21, 40, 45, 48, 52, 53, 54, 55, 56, 57, 59, 60, 62, 63, 66, 67, 84], "trench_coat": 33, "trend": 63, "tri": [15, 39, 43], "triceratop": 33, "trick": 41, "tricki": 71, "tricycl": 33, "trifl": 33, "trigger": [3, 40, 74, 77], "triglycerid": 97, "trilobit": 33, "trimaran": 33, "tripl": [39, 62], "triplekil": 62, "tripod": 33, "triumphal_arch": 33, "trivial": 3, "trolleybu": 33, "trombon": 33, "tropic": 68, "troubl": 52, "trt": 37, "true": [5, 9, 11, 14, 15, 19, 20, 24, 26, 28, 30, 31, 36, 37, 38, 39, 40, 43, 44, 46, 48, 51, 52, 54, 55, 56, 57, 59, 62, 63, 64, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 93, 99, 101, 103, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 136, 137, 138, 139, 140, 141, 144, 152], "true_divid": 59, "true_i": 39, "true_label": [28, 75, 133], "truedmgdealt": 62, "truedmgtaken": 62, "truedmgtochamp": 62, "truli": 15, "trunc": [74, 77], "truncat": [15, 24, 38, 73, 79], "trust": [39, 43, 45, 46, 47, 50, 51, 53, 54, 55, 56, 59, 60, 61, 62, 65, 71], "truth": 25, "try": [3, 27, 43, 55, 56, 65, 71], "tsne": 55, "tub": 33, "tuesdai": 74, "tune": [6, 70], "tupl": [15, 32, 38, 47, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 110, 113, 114, 118, 127, 128], "tuple_of_label": 47, "turn": [38, 39, 40, 43, 48, 72], "turncoat": 15, "turnstil": 33, "turret": 62, "turretkil": 62, "tusker": 33, "tutori": [38, 161], "tv": [15, 24, 38, 73], "twelv": 43, "two": [3, 11, 13, 15, 16, 28, 29, 30, 33, 34, 35, 36, 38, 39, 40, 43, 48, 52, 57, 60, 63, 66, 69, 72, 74, 77, 83, 87, 88, 128, 131], "txt": [3, 25], "type": [2, 4, 5, 6, 7, 9, 15, 16, 24, 26, 27, 32, 38, 39, 40, 43, 46, 50, 54, 55, 56, 65, 73, 75, 80, 82, 85, 86, 87, 90, 91, 93, 105, 106, 107, 108, 109, 110, 126, 138, 140], "typewriter_keyboard": 33, "typic": [3, 9, 51, 54, 55, 57, 63, 79, 138], "typo": 3, "tzu": 33, "u": [3, 11, 16, 26, 38, 39, 40, 47, 56, 63, 65, 69, 72, 73, 120], "u15": 72, "u17": 33, "u19": 72, "u23": 72, "u8": 75, "ubuntu": 5, "uci": [9, 10, 11, 12, 14, 17, 44, 54, 55, 95], "umath_test": 59, "umbrella": 33, "un": 15, "unabl": [56, 65], "unattract": 43, "unbeliev": 43, "unbound": 50, "unbroken": 139, "uncas": [15, 24, 38, 70, 73], "uncertain": 39, "uncertainti": [17, 40], "unchang": [16, 112, 127, 140], "uncom": 39, "unconfounded": 39, "uncov": [44, 87, 139], "und": 43, "under": [3, 27, 42, 57, 68, 76, 90, 91, 141, 148], "underdog": 72, "underestim": 39, "underli": [13, 26, 27, 28, 29, 33, 34, 35, 40, 74, 83, 113, 118], "underlin": 15, "underr": 15, "understand": [26, 38, 39, 40, 43, 53, 54, 55, 57, 68, 161], "underwrit": 40, "undo": 65, "unexpectedli": 11, "unforeseen": [84, 91], "unfortun": 39, "unic": 68, "unic0": 68, "unic1": 68, "unic2": 68, "unicorn": 68, "unicycl": 33, "uniform": [26, 39, 79], "unintellig": 128, "unintend": 40, "unintuit": 39, "union": 74, "uniqu": [15, 39, 65, 66], "unique_depth": 65, "unit": [11, 14, 15, 17, 38, 40, 43, 50, 62, 81, 82, 86, 87, 90, 93, 96, 100, 105, 106, 107, 108, 109, 110], "univari": [39, 41], "unknown": [64, 65], "unless": [38, 39, 80, 82, 84, 85, 86, 90, 91, 105, 106, 107, 109, 110], "unlik": [3, 15, 39, 90, 115, 119], "unlow": 139, "unmask": [4, 6, 19, 48, 70, 73], "unmeasur": 39, "unnorm": 95, "unobserv": 39, "unrealist": [9, 39], "unreason": 80, "unsupervis": 9, "unsupport": 25, "until": [3, 11, 15, 38, 39, 43, 59, 70, 73], "untouch": 40, "untrained_model": 21, "unus": [67, 75], "unwind_path": 65, "unwound": 65, "unwound_path_sum": 65, "unwrap": 85, "uou": 38, "up": [6, 10, 11, 14, 15, 20, 25, 37, 38, 39, 40, 42, 43, 48, 50, 51, 52, 54, 55, 56, 58, 62, 63, 65, 66, 72, 77, 80, 84, 86, 89, 91, 138], "updat": [3, 47, 48, 51, 65, 122, 124, 138], "update_cache_x": 124, "update_output_nam": 122, "upgrad": [3, 39], "upon": [11, 39], "upper": [11, 48, 128], "upper_bound": 83, "upright": 33, "upstream": 39, "ural": 77, "urgent": 43, "url": [3, 13, 16, 18, 19, 28, 29, 30, 31, 33, 34, 35], "us": [0, 1, 3, 4, 5, 6, 8, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 31, 32, 34, 35, 37, 39, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 97, 98, 99, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 118, 119, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 132, 133, 138, 139, 147, 153, 157, 158, 161, 162], "usag": [1, 39, 103], "use_fast": [24, 68, 70, 73, 75, 76], "use_label_encod": 38, "use_log_scal": 140, "user": [3, 5, 11, 18, 21, 22, 23, 24, 32, 39, 43, 45, 46, 47, 48, 50, 51, 53, 54, 55, 59, 60, 61, 62, 71, 75, 82, 86, 87, 88, 90, 105, 106, 107, 108, 109, 110], "user_instal": [48, 51], "user_retention_dataset": 39, "userwarn": 32, "usr": [5, 47], "usual": [3, 11, 15, 19, 38, 50, 80, 85, 86, 87, 90, 91, 128, 143], "utf": 25, "util": [4, 6, 9, 14, 18, 21, 22, 23, 24, 26, 27, 32, 37, 38, 39, 48, 59, 116, 119, 126, 132, 138, 158], "uv": 3, "v": [9, 11, 13, 14, 15, 18, 19, 20, 24, 28, 29, 33, 34, 35, 38, 39, 40, 49, 53, 54, 55, 56, 58, 65, 73, 74, 75, 161, 162], "v0": [0, 1, 2, 3, 8, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162], "v3": 26, "vacuum": 33, "vagrant": 15, "val": [15, 24, 28, 38, 39, 73, 75], "val_acc": 71, "val_accuraci": 32, "val_loss": [32, 51, 71], "valid": [4, 6, 9, 11, 20, 26, 40, 54, 55, 62, 71, 84, 89, 91, 119], "valid_0": 11, "valid_set": [11, 54], "validate_paramet": 5, "validation_0": 59, "validation_data": [51, 71], "validation_split": 32, "vallei": [33, 68], "valu": [3, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 34, 35, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 53, 54, 55, 56, 57, 59, 60, 62, 65, 66, 67, 69, 71, 72, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 94, 98, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 117, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 136, 138, 139, 140, 141, 144, 152, 158, 159, 161], "valuabl": 15, "value0": [69, 70, 74, 76, 77], "value1": [69, 74, 76, 77], "value2": [69, 74, 77], "value3": [69, 74, 77], "value4": [70, 73], "value5": [69, 70, 73], "value6": [69, 76], "value7": 69, "valueerror": 127, "values1": 56, "values2": 56, "var": [16, 27], "vari": [11, 25, 63, 81, 84, 91], "variabl": [5, 11, 16, 26, 27, 39, 40, 42, 52, 59, 62, 66, 69, 84, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 120, 140, 147], "varianc": [36, 54, 55, 62, 80, 86, 90, 96, 100], "variat": [20, 39, 41, 44, 67], "varieti": [2, 40, 79], "variou": [3, 20, 26, 27, 45, 62, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110, 128], "various": 40, "vase": 33, "vasili": 39, "vast": 68, "vaul": 47, "vault": 33, "ve": [39, 43, 53, 74], "vector": [7, 13, 30, 31, 32, 34, 35, 42, 43, 84, 86, 89, 90, 91, 106, 107, 110, 131], "velvet": 33, "vending_machin": 33, "venv": [48, 51], "verbos": [5, 11, 20, 27, 32, 47, 53, 54, 59], "verbose_ev": [11, 39, 55, 62, 63], "verbose_loss": 27, "veri": [3, 11, 15, 38, 39, 43, 46, 50, 52, 58, 62, 67, 68, 72, 80, 128, 149], "verifi": [27, 40], "versa": [16, 66], "versicolor": 101, "version": [5, 7, 8, 14, 25, 32, 38, 39, 41, 49, 61, 62, 63, 74, 75, 77, 80, 84, 85, 86, 87, 90, 91, 103, 153, 161], "vert_gap": 48, "vert_loc": 48, "vertic": [11, 14, 38, 52, 53, 54, 55, 59, 62, 63, 138], "vestment": 33, "vgg16": 157, "vh": 43, "vi": 38, "via": [3, 11, 16, 43, 79, 81, 127, 141], "viaduct": 33, "vice": [16, 66], "view": [15, 37, 38, 43, 44, 45, 46, 47, 50, 51, 53, 54, 55, 59, 60, 61, 62, 71, 76, 139], "view_a": 37, "viewer": [38, 43], "villag": 68, "vine_snak": 33, "violat": 40, "violenc": 43, "violent": 95, "violin": [1, 33, 161], "virginica": 101, "virtual": 68, "viru": 43, "visibl": [16, 48], "vision": [26, 43], "visit": [51, 54, 55], "visual": [9, 16, 38, 41, 43, 45, 46, 47, 50, 51, 53, 57, 60, 61, 62, 63, 128, 129, 130, 132, 139, 141], "visualfeatur": 26, "visualis": 48, "viz_sequ": 25, "vizsla": 33, "vmax": [43, 133], "vmin": 43, "vocab": 27, "vocabulari": 27, "vodka": 76, "void": 65, "voila": 76, "volcano": 33, "volleybal": 33, "vote": [15, 74], "vultur": 33, "w": [27, 37, 39, 49, 65, 71, 73], "wa": [11, 15, 25, 27, 38, 39, 40, 43, 45, 46, 47, 50, 51, 53, 54, 55, 59, 60, 61, 62, 63, 64, 71, 72, 74, 82, 84, 88, 91, 98, 138, 153, 160], "waffle_iron": 33, "wai": [3, 4, 6, 7, 9, 11, 12, 15, 38, 39, 40, 42, 43, 44, 48, 69, 70, 73, 79, 87, 105, 143, 151], "waist": 102, "wait": 3, "wake": 74, "wale": 74, "walk": 76, "walker_hound": 33, "walking0": 76, "walking_stick": 33, "wall": 15, "wall_clock": 33, "wallabi": 33, "wallet": 33, "wander": 38, "want": [9, 10, 14, 15, 16, 29, 33, 39, 43, 46, 60, 62, 68, 70, 71, 74, 77, 84, 87, 90, 91, 112, 132, 138, 151], "war": 15, "ward": 62, "wardrob": 33, "wardsbought": 62, "wardskil": 62, "wardsplac": 62, "warehous": 15, "warm": 20, "warn": [3, 11, 20, 32, 37, 38], "warplan": 33, "warren": [15, 74], "warthog": 33, "washbasin": 33, "washer": 33, "wasn": [3, 15], "watch": 43, "water": 68, "water_bottl": 33, "water_buffalo": 33, "water_jug": 33, "water_ouzel": 33, "water_snak": 33, "water_tow": 33, "waterfal": [1, 4, 5, 6, 38, 44, 48, 51, 57, 61], "waterfall_plot": [38, 48], "we": [3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 80, 81, 83, 84, 85, 86, 87, 89, 90, 91, 111, 112, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 129, 132, 139, 151], "weak": [43, 59], "weaker": 59, "wear": 26, "weasel": 33, "web_sit": 33, "week": [11, 51, 74, 93], "weevil": 33, "weight": [13, 18, 19, 27, 29, 30, 33, 34, 35, 43, 45, 46, 49, 50, 65, 75, 86, 91, 93, 102], "weight_boost": 59, "weighted_n_node_sampl": [56, 65], "weimaran": 33, "weird": 43, "welcom": [3, 15], "well": [8, 38, 39, 40, 43, 46, 47, 48, 57, 63, 68, 72, 74, 81, 122], "welsh": 74, "welsh_springer_spaniel": 33, "went": [47, 72, 84, 91], "were": [3, 8, 14, 15, 25, 36, 38, 39, 40, 43, 57, 64, 74, 75, 80, 85, 138, 139], "west_highland_white_terri": 33, "westcentralu": 26, "wget": 25, "what": [4, 5, 6, 11, 15, 25, 27, 38, 39, 43, 46, 47, 53, 54, 55, 56, 57, 59, 63, 65, 69, 70, 71, 72, 73, 76, 82, 84, 86, 87, 90, 91, 105, 106, 107, 108, 109, 110, 120, 127, 140], "wheel": [3, 47], "when": [3, 4, 6, 9, 14, 15, 20, 26, 27, 36, 38, 40, 41, 42, 43, 44, 48, 50, 52, 54, 55, 57, 59, 62, 63, 66, 67, 69, 70, 73, 75, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 99, 105, 106, 107, 108, 109, 110, 111, 112, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 133, 138, 139, 140, 141, 142, 153, 158, 159], "whenev": [3, 15], "where": [3, 7, 9, 15, 25, 36, 38, 39, 40, 42, 43, 48, 50, 54, 55, 57, 59, 62, 63, 66, 67, 70, 72, 73, 80, 82, 84, 85, 86, 90, 91, 93, 99, 105, 106, 107, 109, 110, 112, 128, 130, 131, 138], "wherea": 39, "whether": [11, 39, 93, 126, 127, 128, 130, 132, 133, 138, 139, 140, 141], "which": [3, 5, 9, 10, 11, 12, 14, 15, 16, 17, 26, 27, 29, 30, 31, 33, 38, 39, 40, 43, 47, 48, 50, 53, 55, 57, 59, 60, 62, 63, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 80, 82, 84, 85, 86, 87, 89, 90, 91, 105, 106, 107, 108, 109, 110, 116, 119, 122, 123, 124, 128, 129, 138, 151], "whichev": 40, "while": [4, 6, 9, 11, 15, 16, 20, 29, 33, 38, 39, 40, 43, 46, 50, 52, 54, 55, 57, 62, 63, 65, 66, 67, 70, 73, 74, 76, 81, 82, 86, 87, 90, 105, 106, 107, 108, 109, 110], "whippet": 33, "whiptail": 33, "whiskey_jug": 33, "whistl": 33, "white": [11, 63], "white_blood_cel": 63, "white_stork": 33, "white_wolf": 33, "whitesmok": 48, "whitespac": 73, "whl": 47, "who": [15, 39, 40, 43, 57, 70, 73, 74, 76], "who0": 76, "whole": [14, 15, 16, 38, 40, 43, 45, 46, 53, 54, 55, 61, 66, 80, 86, 90], "why": [11, 17, 39, 43, 44, 47, 48, 50, 51, 57, 59, 62, 66, 71], "wide": 38, "wider": [3, 16], "widget": 47, "width": [33, 48, 101, 132, 133, 134], "wig": 33, "wild": 68, "wild_boar": 33, "wildli": 43, "will0": 76, "will1": 76, "will2": 76, "willi": 43, "william": 74, "willing": 38, "wilson": 15, "win": 161, "window": [3, 38], "window_screen": 33, "window_shad": 33, "windsor_ti": 33, "wine_bottl": 33, "wing": 33, "winter": 48, "winter_valu": [48, 51], "winter_values50": 51, "wipe": 43, "wire": 33, "wise": 83, "wish": 66, "with0": 76, "with1": 76, "with_label": 48, "with_stat": 52, "within": [3, 54], "without": [3, 4, 9, 11, 15, 38, 39, 44, 47, 54, 55, 59, 66, 67, 83, 84, 91, 93, 143, 153], "witti": 43, "wok": 33, "wolf_spid": 33, "woman": [15, 26, 27, 43], "wombat": 33, "women": 9, "won": 71, "wood": [33, 68], "wood_rabbit": 33, "wooden_spoon": 33, "wool": 33, "word": [15, 26, 27, 43, 54, 55, 57, 62, 71, 73, 76, 124], "work": [1, 3, 4, 5, 6, 9, 15, 26, 28, 38, 39, 40, 43, 48, 52, 58, 61, 62, 70, 73, 78, 80, 81, 82, 86, 87, 90, 93, 98, 105, 106, 107, 108, 109, 110], "workclass": [11, 14, 51, 93], "workflow": 3, "world": [15, 39, 40, 68, 74], "worm_fenc": 33, "worri": [15, 39, 46], "wors": 20, "worst": 76, "worst0": 76, "worth": [11, 17, 43], "would": [3, 4, 5, 6, 9, 14, 17, 38, 39, 40, 42, 43, 44, 46, 47, 50, 52, 63, 65, 70, 74, 76, 81, 82, 86, 87, 88, 90, 105, 106, 107, 108, 109, 110, 116, 119, 138], "wrap": [9, 68, 70, 75, 76, 106, 107, 121, 125], "wrapped_model": [26, 27, 68], "wrapper": [18, 21, 22, 23, 24, 27, 51, 75, 153], "wreck": 33, "wrestl": 40, "write": [39, 42, 58, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 113, 114, 116, 118, 119], "writer": [15, 43], "written": [15, 43, 46, 47, 50, 51, 53, 54, 55, 59, 60, 61, 62, 65, 71], "wrong": [39, 43, 70, 72, 73], "wru": 74, "wsq": 49, "www": 99, "www4": 16, "x": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 71, 72, 73, 74, 75, 76, 80, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 107, 110, 112, 114, 116, 119, 122, 123, 124, 127, 128, 129, 130, 131, 133, 134, 136, 138, 139, 140, 144, 147, 148, 150, 153], "x0": 67, "x1": [52, 67], "x100": 38, "x2": [52, 56, 67], "x3": 67, "x_": [38, 42, 67], "x_0": 67, "x_1": 67, "x_2": 67, "x_3": 67, "x_a": 40, "x_adult": 38, "x_b": 40, "x_c": 40, "x_d": 40, "x_displai": [11, 14, 44, 51, 54, 55, 63], "x_e": 40, "x_eval": 20, "x_f": 40, "x_full": 39, "x_g": 40, "x_i": [38, 43], "x_idx": 47, "x_jitter": [14, 138], "x_miss": 65, "x_std": 41, "x_strain": 59, "x_strain_tmp": 59, "x_test": [11, 20, 21, 32, 36, 39, 43, 45, 46, 54, 55, 59, 63, 71, 104], "x_test_tmp": 59, "x_test_word": 71, "x_tmp": 59, "x_train": [11, 20, 21, 32, 36, 39, 43, 44, 45, 46, 51, 54, 55, 59, 63, 71, 104], "x_train_norm": 44, "x_train_summari": [45, 46], "x_valid": [44, 51, 59], "x_valid_norm": 44, "x_valid_tmp": 59, "xaxi": [39, 55, 63], "xcenter": 48, "xd": 52, "xgb": [62, 64], "xgb_full": 63, "xgb_model": 39, "xgb_test": 63, "xgb_train": 63, "xgbclassifi": [4, 5, 6, 7, 8, 9, 10, 12, 14, 17, 20, 38, 39, 40, 58], "xgboost": [2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 17, 38, 39, 40, 48, 60, 64, 66, 84, 91, 144, 152, 161], "xgboost_distances_r2": 147, "xgbregressor": [21, 38, 48, 57, 59, 61], "xiao": 25, "xlabel": [19, 39, 40, 48, 62, 131], "xlim": [11, 63, 128], "xmax": [14, 40, 131, 137, 138, 139], "xmin": [14, 40, 131, 137, 138, 139], "xnew": 39, "xor_model": 67, "xsum": [19, 22, 23, 26, 27, 74], "xt": 62, "xtick": 63, "xtr": 28, "xv": 62, "xvalu": 138, "y": [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 33, 34, 35, 38, 39, 40, 41, 43, 44, 45, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 75, 76, 84, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 122, 126, 128, 138, 147], "y2": 56, "y_adult": 38, "y_demarc_color": 128, "y_displai": [11, 44, 51, 54, 55, 63], "y_eval": 20, "y_margin": 59, "y_pred": 11, "y_strain": 59, "y_strain_tmp": 59, "y_test": [11, 20, 21, 32, 36, 39, 43, 45, 46, 54, 55, 59, 63, 71, 104], "y_test_tmp": 59, "y_train": [11, 20, 21, 32, 36, 39, 43, 44, 45, 46, 51, 54, 55, 59, 63, 71, 104], "y_valid": [44, 51, 59], "y_valid_tmp": 59, "yawl": 33, "yaxi": 39, "ye": [43, 52, 74], "year": [3, 11, 14, 15, 38, 43, 44, 54, 55, 74, 93, 97], "yellow": 48, "yellow_ladi": 33, "yet": [38, 43, 46, 47, 50, 51, 53, 54, 55, 59, 60, 61, 62, 63, 71, 84, 91, 111], "yield": 27, "ylabel": [14, 19, 39, 48, 62, 137, 138], "yldp": 60, "ylim": 39, "ymax": [14, 138], "ymin": [14, 138], "yml": 3, "yorkshire_terri": 33, "you": [3, 5, 7, 9, 10, 14, 15, 16, 29, 30, 31, 33, 36, 38, 39, 40, 43, 45, 46, 47, 50, 51, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 66, 67, 70, 71, 73, 74, 75, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 105, 106, 107, 108, 109, 110, 138, 139], "young": [10, 15, 72, 74], "your": [3, 5, 7, 11, 14, 15, 26, 27, 29, 32, 33, 36, 38, 39, 40, 44, 48, 51, 57, 62, 64, 70, 73, 74, 80], "yourself": [14, 62], "yt": 62, "ytick": 63, "yule": 119, "yurt": 33, "yv": 62, "yvalu": 138, "z": [68, 75], "zebra": 33, "zero": [7, 11, 25, 30, 31, 39, 40, 49, 52, 57, 65, 67, 86, 90], "zero_fract": 65, "zero_grad": 37, "zeros_arrai": 25, "zip": [25, 30, 39, 44, 47, 48, 51], "zoo": 68, "zorder": 14, "zucchini": 33, "\u0121": [26, 27, 75]}, "titles": ["API Reference", "API Examples", "Benchmarks", "Contributing guidelines", "<code class=\"docutils literal notranslate\"><span class=\"pre\">Exact</span></code> explainer", "<code class=\"docutils literal notranslate\"><span class=\"pre\">GPUTree</span></code> explainer", "<code class=\"docutils literal notranslate\"><span class=\"pre\">Permutation</span></code> explainer", "Using a custom masker", "Migrating to the new \u201cExplanation\u201d API", "<code class=\"docutils literal notranslate\"><span class=\"pre\">bar</span></code> plot", "<code class=\"docutils literal notranslate\"><span class=\"pre\">beeswarm</span></code> plot", "<code class=\"docutils literal notranslate\"><span class=\"pre\">decision</span></code> plot", "<code class=\"docutils literal notranslate\"><span class=\"pre\">heatmap</span></code> plot", "<code class=\"docutils literal notranslate\"><span class=\"pre\">image</span></code> plot", "<code class=\"docutils literal notranslate\"><span class=\"pre\">scatter</span></code> plot", "<code class=\"docutils literal notranslate\"><span class=\"pre\">text</span></code> plot", "<code class=\"docutils literal notranslate\"><span class=\"pre\">violin</span></code> summary plot", "<code class=\"docutils literal notranslate\"><span class=\"pre\">waterfall</span></code> plot", "Image Data Explanation Benchmarking: Image Multiclass Classification", "General Benchmarking Debugging Tool", "Benchmark XGBoost explanations", "Tabular Data Explanation Benchmarking: Xgboost Regression", "Text Data Explanation Benchmarking: Abstractive Summarization", "Text Data Explanation Benchmarking: Machine Translation", "Text Data Explanation Benchmarking: Emotion Multiclass Classification", "DeepExplainer Genomics Example", "Explaining Image Captioning (Image to Text) using Azure Cognitive Services and Partition Explainer", "Explaining Image Captioning (Image to Text) using Open Source Image Captioning Model and Partition Explainer", "Explain PyTorch MobileNetV2 using the <code class=\"docutils literal notranslate\"><span class=\"pre\">Partition</span></code> explainer", "Explain ResNet50 using the <code class=\"docutils literal notranslate\"><span class=\"pre\">Partition</span></code> explainer", "Explain an Intermediate Layer of VGG16 on ImageNet", "Explain an Intermediate Layer of VGG16 on ImageNet (PyTorch)", "Front Page DeepExplainer MNIST Example", "Explain ResNet50 ImageNet classification using <code class=\"docutils literal notranslate\"><span class=\"pre\">Partition</span></code> explainer", "Multi-class ResNet50 on ImageNet (TensorFlow)", "Multi-class ResNet50 on ImageNet (TensorFlow)", "Multi-input Gradient Explainer MNIST Example", "PyTorch Deep Explainer MNIST example", "An introduction to explainable AI with Shapley values", "Be careful when interpreting predictive models in search of causal\u00a0insights", "Explaining quantitative measures of fairness", "Explaining a model that uses standardized features", "Math behind LinearExplainer with correlation feature perturbation", "Sentiment Analysis with Logistic Regression", "Census income classification with scikit-learn", "Diabetes regression with scikit-learn", "Iris classification with scikit-learn", "SHAP Values for Multi-Output Regression Models", "Simple California Demo 2.0", "Simple Kernel SHAP", "How a squashing function can effect feature importance", "Census income classification with Keras", "Basic SHAP Interaction Value Example in XGBoost", "Catboost tutorial", "Census income classification with LightGBM", "Census income classification with XGBoost", "Example of loading a custom tree model into SHAP", "Explaining a simple OR function", "Explaining the Loss of a Tree Model", "Fitting a Linear Simulation with XGBoost", "Force Plot Colors", "Front page example (XGBoost)", "League of Legends Win Prediction with XGBoost", "NHANES I Survival Model", "Speed comparison of gradient boosting libraries for shap values calculations", "Python Version of Tree SHAP", "Scatter Density vs. Violin Plot", "Understanding Tree SHAP for Simple Models", "Text to Multiclass Explanation: Language Modeling Example", "Explaining a Question Answering Transformers Model", "Emotion classification multiclass example", "Keras LSTM for IMDB Sentiment Classification", "Positive vs. Negative Sentiment Classification", "Using custom functions and tokenizers", "Text to Text Explanation: Abstractive Summarization Example", "Multi-Input Text Explanation: Textual Entailment with Facebook BART", "Open Ended GPT2 Text Generation Explanations", "Machine Translation Explanations", "shap.AdditiveExplainer", "shap.Cohorts", "shap.DeepExplainer", "shap.ExactExplainer", "shap.Explainer", "shap.Explanation", "shap.GPUTreeExplainer", "shap.GradientExplainer", "shap.KernelExplainer", "shap.LinearExplainer", "shap.PartitionExplainer", "shap.PermutationExplainer", "shap.SamplingExplainer", "shap.TreeExplainer", "shap.datasets.a1a", "shap.datasets.adult", "shap.datasets.california", "shap.datasets.communitiesandcrime", "shap.datasets.corrgroups60", "shap.datasets.diabetes", "shap.datasets.imagenet50", "shap.datasets.imdb", "shap.datasets.independentlinear60", "shap.datasets.iris", "shap.datasets.linnerud", "shap.datasets.nhanesi", "shap.datasets.rank", "shap.explainers.other.Coefficient", "shap.explainers.other.LimeTabular", "shap.explainers.other.Maple", "shap.explainers.other.Random", "shap.explainers.other.TreeGain", "shap.explainers.other.TreeMaple", "shap.maskers.Composite", "shap.maskers.Fixed", "shap.maskers.FixedComposite", "shap.maskers.Image", "shap.maskers.Impute", "shap.maskers.Independent", "shap.maskers.Masker", "shap.maskers.OutputComposite", "shap.maskers.Partition", "shap.maskers.Text", "shap.models.Model", "shap.models.TeacherForcing", "shap.models.TextGeneration", "shap.models.TopKLM", "shap.models.TransformersPipeline", "shap.plots.bar", "shap.plots.beeswarm", "shap.plots.decision", "shap.plots.embedding", "shap.plots.force", "shap.plots.group_difference", "shap.plots.heatmap", "shap.plots.image", "shap.plots.image_to_text", "shap.plots.initjs", "shap.plots.monitoring", "shap.plots.partial_dependence", "shap.plots.scatter", "shap.plots.text", "shap.plots.violin", "shap.plots.waterfall", "shap.utils.MaskedModel", "shap.utils.OpChain", "shap.utils.approximate_interactions", "shap.utils.convert_name", "shap.utils.delta_minimization_order", "shap.utils.hclust", "shap.utils.hclust_ordering", "shap.utils.make_masks", "shap.utils.partition_tree", "shap.utils.partition_tree_shuffle", "shap.utils.potential_interactions", "shap.utils.sample", "shap.utils.shapley_coefficients", "shap.utils.show_progress", "Genomic examples", "Image examples", "Welcome to the SHAP documentation", "Topical Overviews", "Release notes", "Tabular examples", "Text examples"], "titleterms": {"": [40, 43, 62, 63, 77], "0": 48, "1": 59, "2": [40, 48, 56], "3": 59, "A": [10, 16, 29, 33, 38, 39, 40], "AND": 67, "Be": 39, "It": 27, "No": 40, "OR": [57, 67], "The": [16, 38, 39, 59], "To": 15, "a1a": 92, "about": 65, "abstract": [22, 74], "across": [20, 68], "add": [14, 26, 27], "addit": 38, "additiveexplain": 78, "adult": 93, "again": 20, "agnost": 161, "ai": 38, "all": [20, 43, 45, 46, 62, 70, 73], "an": [20, 26, 27, 30, 31, 38, 40, 57, 58, 59, 70, 73, 74, 76], "analysi": [43, 72, 162], "anoth": 76, "answer": [39, 69, 162], "apart": 40, "api": [0, 1, 8, 26, 74], "approximate_interact": 144, "area": 20, "attribut": 55, "azur": 26, "b": 40, "background": 57, "bar": [9, 55, 59, 72, 126], "bart": 75, "base": [11, 161], "basi": 46, "basic": [11, 52], "bee": 59, "beeswarm": [10, 127], "befor": 44, "behind": 42, "below": 27, "benchmark": [2, 18, 19, 20, 21, 22, 23, 24, 75], "between": [11, 40, 54, 55], "bia": 40, "bias": [40, 76], "binari": 59, "boi": 57, "boost": [38, 64, 67], "brute": 49, "bug": 3, "build": [3, 20, 41, 59, 70, 72], "c": 40, "calcul": [8, 11, 64], "california": [20, 48, 65, 94], "can": [39, 40, 50], "cannot": 39, "caption": [26, 27, 157], "captur": 59, "care": 39, "catboost": 53, "causal": 39, "censu": [20, 44, 51, 54, 55], "challeng": 39, "chanc": 62, "chang": [3, 11, 12, 14, 62], "chart": [55, 72], "check": [3, 63], "checklist": 3, "class": [18, 19, 24, 34, 35, 70, 73], "classic": 55, "classif": [18, 20, 24, 33, 44, 46, 51, 54, 55, 56, 70, 71, 72, 157], "classifi": [44, 58], "clearli": 11, "cluster": [9, 48, 55], "code": 3, "coeffici": [38, 105], "cog": 26, "cognit": 26, "cohort": [9, 79], "color": [10, 14, 60], "colormap": 14, "communitiesandcrim": 95, "compar": [11, 48, 65], "comparison": 64, "complet": 38, "composit": 111, "comput": [25, 48, 63, 68, 70, 73, 74, 76], "conclus": 40, "confound": 39, "contrast": 11, "contribut": 3, "control": 14, "convert": 41, "convert_nam": 145, "correl": [38, 42], "corrgroups60": 96, "creat": [3, 18, 21, 22, 23, 24, 26, 27, 47, 56, 57, 63, 68, 70, 72, 73, 74, 76], "cross": 3, "cumul": 11, "curv": 20, "custom": [7, 10, 14, 56, 73, 76], "cv": 26, "d": 40, "data": [4, 5, 6, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 44, 45, 46, 47, 63, 68, 74], "dataset": [0, 11, 43, 51, 54, 55, 57, 59, 62, 63, 65, 72, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104], "deal": 38, "debug": [19, 76], "decis": [11, 45, 46, 128], "deep": 37, "deepexplain": [25, 32, 71, 80], "default": 40, "defin": [18, 21, 22, 23, 24, 68, 73, 76], "delta_minimization_ord": 146, "demo": 48, "dendrogram": 75, "densiti": 66, "depend": [3, 14, 38, 54, 55, 59, 63], "depth": 59, "detail": [20, 26], "develop": [3, 158], "diabet": [45, 97], "differ": 14, "displai": 11, "distinguish": 40, "distribut": [57, 59], "doc": 3, "document": [3, 158], "dot": 66, "e": 40, "each": [20, 59], "effect": [11, 14, 39, 43, 50, 59], "embed": 129, "emot": [24, 70], "end": [69, 76], "english": 77, "ensur": 27, "entail": [75, 162], "entir": [62, 63], "environ": 3, "error": [36, 40], "estim": [36, 39], "etiquett": 3, "evalu": [29, 33], "even": 65, "exact": 4, "exactexplain": 81, "exactli": 27, "examin": [38, 62], "exampl": [1, 19, 25, 32, 36, 37, 39, 52, 56, 57, 61, 67, 68, 70, 74, 76, 156, 157, 158, 161, 162], "explain": [0, 1, 4, 5, 6, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 36, 37, 38, 40, 41, 43, 44, 45, 46, 48, 50, 51, 52, 54, 55, 56, 57, 58, 59, 62, 63, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 82, 105, 106, 107, 108, 109, 110], "explan": [0, 8, 15, 18, 20, 21, 22, 23, 24, 26, 27, 29, 33, 40, 41, 68, 74, 75, 76, 77, 83], "explicitli": 72, "explor": [11, 14, 72], "f": 40, "facebook": 75, "fair": 40, "featur": [9, 10, 11, 12, 14, 38, 40, 41, 42, 43, 48, 50, 54, 55, 59, 62, 67], "few": [29, 33], "figur": 14, "first": [43, 56, 71], "fit": [43, 59], "fix": 112, "fixedcomposit": 113, "folder": [26, 27], "follow": [27, 57], "forc": [49, 60, 130], "forest": [45, 46, 65], "fork": 3, "format": 3, "french": 77, "from": [3, 38, 45, 46], "front": [32, 61], "function": [18, 24, 46, 50, 52, 57, 69, 73], "gbm": 56, "gener": [3, 19, 76, 162], "genom": [25, 156], "get": [18, 27, 47], "given": 27, "global": [4, 5, 6, 9, 12, 14, 59], "gpt2": 76, "gputre": 5, "gputreeexplain": 84, "gradient": [36, 64], "gradientexplain": [36, 85], "group_differ": 131, "guid": 3, "guidelin": 3, "hclust": 147, "hclust_ord": 148, "heatmap": [12, 132], "help": [3, 11, 39, 40], "henc": [54, 55], "hierarch": 48, "highlight": 14, "hous": 20, "how": [40, 50, 62, 72], "hundr": 65, "i": [11, 27, 63], "identifi": 11, "imag": [2, 13, 18, 19, 26, 27, 28, 29, 33, 114, 133, 157], "image_to_text": 134, "imagenet": [30, 31, 33, 34, 35], "imagenet50": 98, "imdb": [43, 71, 72, 99], "impact": [62, 70, 73], "import": [12, 14, 25, 27, 50, 55, 59], "imput": 115, "incom": [20, 40, 44, 51, 54, 55], "independ": [4, 5, 6, 116], "independentlinear60": 100, "indic": 18, "individu": 25, "infer": 39, "info": 56, "initi": 76, "initj": 135, "input": [36, 48, 68, 75], "insight": 39, "instal": [3, 158], "instanc": [4, 5, 6, 15, 48], "instead": 70, "instruct": 27, "interact": [5, 11, 14, 52, 54, 55, 63], "intermedi": [30, 31], "interpret": [29, 33, 39], "introduc": 40, "introduct": [3, 38, 158], "iri": [46, 101], "issu": 3, "jitter": 14, "jupyt": 3, "k": [44, 46, 68], "kera": [25, 51, 71], "kernel": [46, 49], "kernelexplain": [49, 86], "label": [3, 14, 18, 24, 40, 59], "languag": [26, 27, 68, 162], "larg": 11, "late": 40, "latest": 3, "layer": [16, 30, 31, 66], "leagu": 62, "learn": [44, 45, 46], "leav": [54, 55], "legend": 62, "librari": 64, "lightgbm": 54, "like": [26, 27, 40], "limetabular": 106, "limit": [26, 27], "linear": [38, 41, 43, 45, 46, 52, 59, 161], "linearexplain": [42, 87], "link": 3, "linnerud": 102, "lint": 3, "list": 56, "load": [11, 18, 21, 22, 23, 24, 26, 27, 28, 29, 33, 43, 44, 45, 46, 51, 54, 55, 56, 62, 65, 68, 72, 74, 75, 76], "local": [3, 9, 30, 31], "log": [58, 70], "logist": [38, 43, 46], "longer": [29, 33], "look": 40, "loss": 58, "lstm": 71, "machin": [23, 46, 77], "made": 36, "maintain": 3, "make": 3, "make_mask": 149, "mani": [29, 33, 51, 54, 55], "manual": 72, "map": [18, 24], "mapl": 107, "margin": 50, "mask": [4, 5, 6], "maskedmodel": 142, "masker": [0, 1, 7, 18, 21, 26, 27, 72, 74, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120], "match": [62, 69], "math": 42, "mean": 55, "measur": 40, "method": [18, 21, 22, 23, 24, 39], "metric": [18, 20, 21, 22, 23, 24], "migrat": 8, "mimic": 57, "minimum": 3, "mnist": [32, 36, 37], "mobilenetv2": 28, "model": [0, 1, 11, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 36, 38, 39, 40, 41, 43, 44, 47, 48, 51, 52, 54, 55, 56, 57, 58, 59, 62, 63, 65, 67, 68, 69, 71, 73, 74, 75, 76, 77, 121, 122, 123, 124, 125, 161, 162], "monitor": 136, "more": 38, "most": 59, "movi": 72, "multi": [19, 34, 35, 36, 47, 75], "multiclass": [18, 24, 68, 70], "multioutput": 11, "multipl": [15, 28, 40], "natur": 38, "nearest": [44, 46], "neg": [57, 72], "neighbor": [44, 46], "neither": 39, "network": [45, 46, 161], "neural": [45, 46, 161], "new": 8, "next": 68, "nhane": 63, "nhanesi": 103, "nlp": 38, "non": [38, 39], "nor": 39, "normal": 44, "note": [3, 26, 27, 160], "notebook": [3, 27], "numba": 65, "number": 11, "object": [18, 21, 22, 23, 24, 26, 27, 63, 68, 72, 74, 76], "observ": 39, "obtain": 25, "odd": 70, "old": 8, "one": [28, 52, 54], "onli": [54, 55, 57], "opac": 14, "opchain": 143, "open": [27, 76], "option": [29, 33], "order": [10, 11, 12, 14, 18, 21, 22, 23, 24], "origin": 41, "other": [2, 14, 105, 106, 107, 108, 109, 110], "our": 73, "outlier": [11, 14], "output": [18, 29, 33, 47, 70, 73, 76], "outputcomposit": 118, "over": 62, "overal": 20, "overview": 159, "owen": [4, 6], "page": [32, 61], "paramet": 64, "partial": 38, "partial_depend": 137, "particular": 62, "partit": [4, 6, 26, 27, 28, 29, 33, 75, 119], "partition_tre": 150, "partition_tree_shuffl": 151, "partitionexplain": 88, "pass": 72, "path": 11, "payment": 40, "per": [54, 55], "perform": [20, 63], "permut": 6, "permutationexplain": 89, "perturb": [18, 21, 22, 23, 24, 42], "pictur": 38, "pipelin": [70, 72], "piplin": 70, "player": 62, "plot": [0, 1, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 38, 47, 48, 54, 55, 59, 60, 63, 66, 70, 72, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141], "point": 14, "posit": [57, 69, 72], "potential_interact": 152, "pr": 3, "precommit": 3, "predict": [11, 36, 39, 43, 44, 45, 46, 47, 51, 54, 55, 57, 59, 62, 63, 71, 77], "preserv": 11, "preview": 3, "probabl": [50, 70], "properti": 14, "protect": 40, "publish": 3, "pull": [3, 56], "pytest": 3, "python": [3, 65], "pytorch": [28, 31, 37], "quantit": 40, "question": [39, 69, 162], "quick": [29, 33], "radial": 46, "random": [20, 45, 46, 65, 108], "rang": 11, "rank": 104, "rate": 40, "read": 38, "redund": 39, "refer": [0, 3, 47, 158], "regress": [20, 21, 38, 43, 45, 46, 47, 56], "regressor": [45, 59], "relationship": 59, "releas": [3, 160], "replac": [26, 27], "report": [3, 20, 40], "repositori": 3, "request": 3, "requir": 26, "resnet50": [29, 33, 34, 35], "retent": 39, "review": [43, 72], "run": [18, 20, 21, 22, 23, 24, 27, 29, 33, 72, 75], "runtim": 65, "sampl": [27, 36, 153], "samplingexplain": 90, "scale": 11, "scatter": [14, 66, 138], "scenario": 40, "scikit": [44, 45, 46], "score": [18, 20, 24, 25], "search": 39, "second": [43, 56], "select": 11, "sentenc": 68, "sentiment": [43, 71, 72, 162], "sequenc": 25, "servic": 26, "set": [3, 27, 45, 46, 57], "sever": 11, "shap": [11, 18, 21, 22, 23, 24, 26, 27, 29, 33, 38, 40, 47, 48, 49, 52, 54, 55, 56, 63, 64, 65, 67, 68, 70, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158], "shaplei": [4, 5, 6, 38], "shapley_coeffici": 154, "show": [11, 20, 59], "show_progress": 155, "simpl": [10, 14, 16, 48, 49, 55, 56, 57, 67], "simul": [40, 59], "singl": [4, 5, 6, 15, 45, 46, 51, 55, 59, 62, 67, 70], "size": [14, 16, 59], "sklearn": 65, "slower": 65, "smooth": [30, 31], "sort": [12, 18, 21, 22, 23, 24], "sourc": [3, 27], "space": [41, 50], "spanish": 77, "specif": 70, "speed": 64, "split": 67, "squash": 50, "standard": 41, "start": 69, "statist": 72, "style": [3, 8], "subscrib": 39, "summar": [15, 19, 22, 43, 62, 74, 162], "summari": [4, 5, 6, 10, 16, 39, 54, 55, 59, 63, 72], "supervis": 55, "support": [3, 46], "surviv": 63, "swarm": 59, "tabular": [2, 4, 5, 6, 21, 161], "take": 40, "task": 39, "teacherforc": 122, "teas": 40, "tensorflow": [34, 35], "term": [54, 55], "test": [3, 26, 27, 45, 46], "test_imag": [26, 27], "text": [2, 15, 19, 22, 23, 24, 26, 27, 68, 72, 74, 75, 76, 120, 139, 162], "textgener": 123, "textual": 75, "thi": 57, "third": 43, "tick": 14, "time": 65, "titl": 14, "token": [26, 27, 68, 72, 73, 74, 75, 76], "tool": 19, "top": [59, 68, 70], "topic": 159, "topklm": 124, "train": [11, 44, 47, 48, 51, 54, 55, 57, 58, 59, 62, 63, 65], "transform": [10, 38, 69, 70], "transformerspipelin": [72, 125], "translat": [23, 77, 162], "tree": [38, 45, 46, 48, 54, 55, 56, 58, 65, 67, 75, 161], "treeexplain": [58, 65, 91], "treegain": 109, "treemapl": 110, "triag": 3, "tutori": 53, "two": [54, 55, 67], "type": 20, "typic": 11, "unconfound": 39, "under": [20, 40], "understand": 67, "unit": 3, "up": [3, 27], "us": [7, 9, 10, 14, 26, 27, 28, 29, 33, 36, 38, 40, 41, 49, 57, 73, 74], "util": [0, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155], "v": [66, 72], "valu": [4, 5, 6, 11, 12, 29, 33, 38, 47, 52, 63, 64, 68, 70, 73, 74, 75, 76], "variou": 40, "vector": 46, "version": [3, 65], "versu": [39, 65], "vgg16": [30, 31], "violin": [16, 66, 140], "visual": [11, 15, 25, 29, 33, 54, 55, 59, 68, 70, 71, 73, 74, 75, 76, 77], "waterfal": [17, 141], "welcom": 158, "what": 40, "when": [11, 39], "win": 62, "without": 20, "women": [40, 57], "word": [68, 70], "work": 72, "would": [26, 27], "wrap": [26, 27, 72, 74], "wrapper": 72, "write": 3, "x": 14, "xgboost": [20, 21, 52, 55, 57, 58, 59, 61, 62, 63, 65], "xor": 67, "you": [26, 27], "young": 57}})